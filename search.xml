<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Elasticsearch Term Match]]></title>
    <url>%2F2019%2F10%2F31%2F2019-10-31-elasticsearch-term%2F</url>
    <content type="text"><![CDATA[Termterm query会去倒排索引中寻找确切的term，它并不知道分词器的存在，这种查询适合keyword、numeric、date等明确值的 term：查询某个字段里含有某个关键词的文档 request12345678GET test_search_index/_search&#123; "query": &#123; "term": &#123; "username": "alfred" &#125; &#125;&#125; 返回结果1234567891011121314151617181920212223242526272829303132333435363738394041"hits" : [ &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "2", "_score" : 0.636667, "_source" : &#123; "username" : "alfred", "job" : "java senior engineer and java specialist", "age" : 28, "birth" : "1980-05-07", "isMarried" : true &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "1", "_score" : 0.48898652, "_source" : &#123; "username" : "alfred way", "job" : "java engineer", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "4", "_score" : 0.39691794, "_source" : &#123; "username" : "alfred junior way", "job" : "ruby engineer", "age" : 23, "birth" : "1989-08-07", "isMarried" : false &#125; &#125; ] 发现，username里有关alfred的关键字都查出来了，但是我只想精确匹配alfred way这个，按照下面的写法看看能不能查出来： request12345678GET test_search_index/_search&#123; "query": &#123; "term": &#123; "username": "alfred way" &#125; &#125;&#125; 执行发现无数据，从概念上看，term属于精确匹配，只能查单个词。我想用term匹配多个词怎么做？可以使用terms来： request12345678GET test_search_index/_search&#123; "query": &#123; "terms": &#123; "username": ["alfred", "way"] &#125; &#125;&#125; 发现全部查询出来，为什么？因为terms里的[ ]多个是或者的关系，只要满足其中一个词就可以。想要通知满足两个词的话，就得使用在search api那篇中提到的bool查询来做了 match查询： match query 知道分词器的存在，会对field进行分词操作，然后再查询request12345678GET test_search_index/_search&#123; "query": &#123; "match": &#123; "username": "alfred" &#125; &#125;&#125; match_all：查询所有文档{ “match_all”: {}} 匹配所有的， 当不给查询条件时，默认。request12345678GET test_search_index/_search&#123; "query": &#123; "match_all": &#123; "boost": 1.2 &#125; &#125;&#125; _score随boost值改变而改变: multi_match：可以指定多个字段request12345678910GET test_search_index/_search&#123; "profile": "true", "query": &#123; "multi_match": &#123; "query" : "alfred java", "fields": ["username","job"] &#125; &#125;&#125; 返回结果：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354"hits" : [ &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "1", "_score" : 0.636667, "_source" : &#123; "username" : "alfred way", "job" : "java engineer", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "2", "_score" : 0.636667, "_source" : &#123; "username" : "alfred", "job" : "java senior engineer and java specialist", "age" : 28, "birth" : "1980-05-07", "isMarried" : true &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "3", "_score" : 0.48898652, "_source" : &#123; "username" : "lee", "job" : "java and ruby engineer", "age" : 22, "birth" : "1985-08-07", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "4", "_score" : 0.39691794, "_source" : &#123; "username" : "alfred junior way", "job" : "ruby engineer", "age" : 23, "birth" : "1989-08-07", "isMarried" : false &#125; &#125;]]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 部署小记]]></title>
    <url>%2F2019%2F10%2F25%2F2019-10-25-hexo-deploy%2F</url>
    <content type="text"><![CDATA[hexo部署流程 开启本地web服务: 1hexo s 生成静态文件: 1hexo g 文件压缩: 1gulp 文件部署到远程服务器: 1hexo d gulp安装：安装 gulp使用 npm install xxx –save命令分别安装如下工具123456"gulp": "^3.9.1","gulp-htmlclean": "^2.7.6","gulp-htmlmin": "^1.3.0","gulp-imagemin": "^2.4.0","gulp-minify-css": "^1.2.4","gulp-uglify": "^1.5.3", 建立 gulpfile.js 文件在 Hexo 的根目录建立 gulpfile.js123456789101112131415161718192021222324252627282930313233343536373839404142434445464748var gulp = require('gulp');var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');var imagemin = require('gulp-imagemin');// 压缩htmlgulp.task('minify-html', function() &#123; return gulp.src('./public/**/*.html') .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest('./public'))&#125;);// 压缩cssgulp.task('minify-css', function() &#123; return gulp.src('./public/**/*.css') .pipe(minifycss(&#123; compatibility: 'ie8' &#125;)) .pipe(gulp.dest('./public'));&#125;);// 压缩jsgulp.task('minify-js', function() &#123; return gulp.src('./public/js/**/*.js') .pipe(uglify()) .pipe(gulp.dest('./public'));&#125;);// 压缩图片gulp.task('minify-images', function() &#123; return gulp.src('./public/images/**/*.*') .pipe(imagemin( [imagemin.gifsicle(&#123;'optimizationLevel': 3&#125;), imagemin.jpegtran(&#123;'progressive': true&#125;), imagemin.optipng(&#123;'optimizationLevel': 7&#125;), imagemin.svgo()], &#123;'verbose': true&#125;)) .pipe(gulp.dest('./public/images'))&#125;);// 默认任务gulp.task('default', [ 'minify-html','minify-css','minify-js','minify-images']);]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch Index API]]></title>
    <url>%2F2019%2F09%2F22%2F2019-09-22-elastic%2F</url>
    <content type="text"><![CDATA[文档什么是文档程序中大多的实体或对象能够被序列化为包含键值对的JSON对象，键(key)是字段(field)或属性(property)的名字，值(value)可以是字符串、数字、布尔类型、另一个对象、值数组或者其他特殊类型，比如表示日期的字符串或者表示地理位置的对象1234567891011121314151617181920&#123; "name": "John Smith", "age": 42, "confirmed": true, "join_date": "2014-06-01", "home": &#123; "lat": 51.5, "lon": 0.1 &#125;, "accounts": [ &#123; "type": "facebook", "id": "johnsmith" &#125;, &#123; "type": "twitter", "id": "johnsmith" &#125; ]&#125; 通常，我们可以认为对象(object)和文档(document)是等价相通的。不过，他们还是有所差别：对象(Object)是一个JSON结构体——类似于哈希、hashmap、字典或者关联数组；对象(Object)中还可能包含其他对象(Object)。 在Elasticsearch中，文档(document)这个术语有着特殊含义。它特指最顶层结构或者根对象(root object)序列化成的JSON数据（以唯一ID标识并存储于Elasticsearch中）。 归结 Json Object,由字段组成： 字符串：text, keyword 数值型：long,integer,short,byte,double,float,half_float,scled_float 布尔：boolean 日期：date 二进制：binary 范围类型：integer_range,float_range,long_range,double_range,date_range 每个文档有唯一的id标识 自行指定 es生成 元数据，用于标注文档的相关信息 _index：文档所在的索引名 _type：文档所在的类型名 _id：文档唯一id _uid：组合id,由_type和_id组成(6.x_type不再起作用，同_id一样) _source：文档的原始Json数据，可以从这里获取每个字段的内容 _all：整合所有字段内容到该字段，默认禁用 文档元数据一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是： 节点 说明 _index 文档存储的地方 _type 文档代表的对象的类 _id 文档的唯一标识 _index 索引(index)类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。 事实上，我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。然而，这只是一些内部细节——我们的程序完全不用关心分片。对于我们的程序而言，文档存储在索引(index)中。剩下的细节由Elasticsearch关心既可。 _type在应用中，我们使用对象表示一些“事物”，例如一个用户、一篇博客、一个评论，或者一封邮件。每个对象都属于一个类(class)，这个类定义了属性或与对象关联的数据。user类的对象可能包含姓名、性别、年龄和Email地址。在关系型数据库中，我们经常将相同类的对象存储在一个表里，因为它们有着相同的结构。同理，在Elasticsearch中，我们使用相同类型(type)的文档表示相同的“事物”，因为他们的数据结构也是相同的。每个类型(type)都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的映射(mapping)会告诉Elasticsearch不同的文档如何被索引。 在7.0前，一个index可以设置多个type,在7.0后type统一为_doc _id id仅仅是一个字符串，它与_index和_type组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文档，你可以自定义_id，也可以让Elasticsearch帮你自动生成。 Index Api以下操作均在es7.2版本操作 Index(createorupdate)PUT {_index}/{_type}/{_id}POST {_index}/{_type}/{_id}(id可不指定) 创建一个索引1PUT test_index 创建一个索引并指定文档内容和id12345PUT /test_index/_doc/1&#123; &quot;username&quot;:&quot;alfred&quot;, &quot;age&quot;:1&#125; 创建一个索引指定文档内容自动生成id12345POST /test_index/_doc&#123; &quot;username&quot;:&quot;lili&quot;, &quot;age&quot;:22&#125; 文档不存在执行的是创建操作，存在的话回变为更新操作，并且_version会增加1 Create有两种方式: 第一种方法使用op_type查询参数：12345PUT /test_index/_doc/1?op_type=create&#123; &quot;username&quot;:&quot;alfred&quot;, &quot;age&quot;:1&#125; 或者第二种方法是在URL后加/_create做为端点：12345PUT /test_index/_doc/1/_create&#123; &quot;username&quot;:&quot;alfred&quot;, &quot;age&quot;:1&#125; 如果请求成功的创建了一个新文档，Elasticsearch将返回正常的元数据且响应状态码是201 Created。另一方面，如果包含相同的_index、_type和_id的文档已经存在，Elasticsearch将返回409 Conflict响应状态码，错误信息类似如下：12345678910111213141516171819&#123; "error": &#123; "root_cause": [ &#123; "type": "version_conflict_engine_exception", "reason": "[1]: version conflict, document already exists (current version [6])", "index_uuid": "vENoH2YDQRiFHvu_pfzDcg", "shard": "0", "index": "test_index" &#125; ], "type": "version_conflict_engine_exception", "reason": "[1]: version conflict, document already exists (current version [6])", "index_uuid": "vENoH2YDQRiFHvu_pfzDcg", "shard": "0", "index": "test_index" &#125;, "status": 409&#125; POST和PUT的区别是POST不用加具体的id，它是作用在一个集合资源之上的（/uri），而PUT操作是作用在一个具体资源之上的（/uri/xxx）。在ES中，如果不确定document的ID（documents具体含义见下），那么直接POST对应uri（ “POST /website/blog” ），ES可以自己生成不会发生碰撞的UUID；如果确定document的ID，比如 “PUT /website/blog/123”，那么执行创建或修改（修改时_version版本号提高1） Update123456PUT /test_index/_update/1&#123; &quot;doc&quot;: &#123; &quot;hobby&quot;: &quot;hit&quot; &#125;&#125; Delete1DELETE test_index Get获取所有1GET /test_index/_search 指定id1GET /test_index/_doc/1 归结 操作 请求 Create PUT /test_index/_doc/1/_create{“username”:”alfred”,”age”:1}POST /test_index/_doc/{“username”:”alfred”,”age”:1}(不指定id自动生成) Index PUT Or POST /test_index/_doc/1/{“username”:”alfred”,”age”:1} Read GET /test_index/_doc/1 Update POST /test_index/_update/1{“doc”: {“sex”: “女”}} Delete DELETE test_index2 Index和UpdateIndex实际上是文档不存在会创建一个文档，存在则会删除原来的文档，新的文档被索引，并且version加1Update不会删除原来的文档，实现真正的更新，POST方法的payload需包含在”doc”里 Bulk123456POST _bulk&#123;&quot;index&quot;:&#123;&quot;_index&quot;:&quot;test_index&quot;,&quot;_id&quot;:&quot;3&quot;&#125;&#125;&#123;&quot;username&quot;:&quot;alfred&quot;,&quot;age&quot;:20&#125;&#123;&quot;delete&quot;:&#123;&quot;_index&quot;:&quot;test_index&quot;,&quot;_id&quot;:&quot;1&quot;&#125;&#125;&#123;&quot;update&quot;:&#123;&quot;_id&quot;:&quot;2&quot;,&quot;_index&quot;:&quot;test_index&quot;&#125;&#125;&#123;&quot;doc&quot;:&#123;&quot;age&quot;:&quot;20&quot;&#125;&#125; 批量查询apies允许一次查询多个文档，如果你需要从Elasticsearch中检索多个文档，相对于一个一个的检索，更快的方式是在一个请求中使用multi-get或者mget API。 mget API参数是一个docs数组，数组的每个节点定义一个文档的_index、_type、_id元数据。如果你只想检索一个或几个确定的字段，也可以定义一个_source参数： 12345678910111213POST _mget&#123; &quot;docs&quot;: [ &#123; &quot;_id&quot;: 1, &quot;_index&quot;:&quot;test_index&quot; &#125;, &#123; &quot;_id&quot;: 2, &quot;_index&quot;:&quot;test_index&quot; &#125; ]&#125; 响应体也包含一个docs数组，每个文档还包含一个响应，它们按照请求定义的顺序排列。每个这样的响应与单独使用get request响应体相同： 123456789101112131415161718192021222324252627282930&#123; "docs" : [ &#123; "_index" : "test_index", "_type" : "_doc", "_id" : "1", "_version" : 1, "_seq_no" : 17, "_primary_term" : 2, "found" : true, "_source" : &#123; "name" : "lili", "age" : "10" &#125; &#125;, &#123; "_index" : "test_index", "_type" : "_doc", "_id" : "2", "_version" : 1, "_seq_no" : 16, "_primary_term" : 2, "found" : true, "_source" : &#123; "name" : "john", "age" : "40" &#125; &#125; ]&#125; 如果你想检索的文档在同一个_index中，你就可以在URL中定义一个默认的/_index。你依旧可以在单独的请求中使用这些值： 1234567POST /test_index/_doc/_mget&#123; &quot;docs&quot; : [ &#123; &quot;_id&quot; : 2 &#125;, &#123; &quot;_id&quot; : 1 &#125; ]&#125; 在7.0以上版本后，_doc在mget中可以省略，不省略会提示#! Deprecation: [types removal] Specifying types in multi get requests is deprecated. 事实上，如果所有文档具有相同_index，你可以通过简单的ids数组来代替完整的docs数组：1234POST /test_index/_mget&#123; &quot;ids&quot; : [ &quot;4&quot;, &quot;1&quot; ]&#125; 不存在的文档会显示found:false1234567891011121314151617181920212223&#123; "docs" : [ &#123; "_index" : "test_index", "_type" : "_doc", "_id" : "4", "found" : false &#125;, &#123; "_index" : "test_index", "_type" : "_doc", "_id" : "1", "_version" : 1, "_seq_no" : 17, "_primary_term" : 2, "found" : true, "_source" : &#123; "name" : "lili", "age" : "10" &#125; &#125; ]&#125; 尽管前面提到有一个文档没有被找到，但HTTP请求状态码还是200。事实上，就算所有文档都找不到，请求也还是返回200，原因是mget请求本身成功了。如果想知道每个文档是否都成功了，你需要检查found标志。]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kubectl命令行管理工具]]></title>
    <url>%2F2019%2F09%2F14%2F2019-09-14-kubectl%2F</url>
    <content type="text"><![CDATA[kubectl命令行管理工具 管理周期1.创建 kubectl run nginx –replicas=3 –image=nginx:1.14 –port=80 kubectl get deploy,pods 2.发布 kubectl expose deployment nginx –port=80 –type=NodePort –target-port=80 –name=nginx-service kubectl get service 3.更新 kubectl set image deployment/nginx nginx=nginx:1.15 4.回滚 kubectl rollout history deployment/nginx kubectl rollout undo deployment/nginx 5.删除 kubectl delete deploy/nginx kubectl delete svc/nginx-service 命令123456#创建kubectl run &lt;deployment&gt; --replicas=&lt;副本数&gt; --image=&lt;image&gt; --port=&lt;port&gt;#获取所有deploykubectl get deploy#获取某个deploykubectl get deploy/nginx kubectl远程连接k8s集群创建sh脚本 1234567891011121314151617181920212223242526APISERVER=$1SSL_DIR=$2# 创建kubelet bootstrapping kubeconfigexport KUBE_APISERVER="https://$APISERVER:6443"# 设置集群参数kubectl config set-cluster kubernetes \ --certificate-authority=$SSL_DIR/ca.pem \ --embed-certs=true \ --server=$&#123;KUBE_APISERVER&#125; \ --kubeconfig=config#设置用户项中cluster-admin用户证书认证字段kubectl config set-credentials cluster-admin \--certificate-authority=$SSL_DIR/ca.pem \--client-key=$SSL_DIR/admin-key.pem \--client-certificate=$SSL_DIR/admin.pem \--kubeconfig=config#设置默认上下文kubectl config set-context default --cluster=kubernetes --user=cluster-admin --kubeconfig=config#设置当前环境的defaultkubectl config use-context default --kubeconfig=config 执行脚本文件生成config文件eg:config.sh ```1234```bashmkdir ~/.kubecp config ~/.kube 证书文件需与master节点生成的证书一致 执行kubectl get node 即可看到集群信息 YAML配置文件YAML 是一种简洁的非标记语言。 语法格式: 缩进表示层级关系 不支持制表符“tab”缩进，使用空格缩进 • 通常开头缩进 2 个空格 字符后缩进 1 个空格，如冒号、逗号等 “—” 表示YAML格式，一个文件的开始 “#” 注释 YAML配置文件管理资源 用run命令生成kubectl run –image=nginx nginx -o yaml –dry-run &gt; my-deploy.yaml 用get命令导出kubectl get my-deploy/nginx -o=yaml –export &gt; my-deploy.yaml Pod容器的字段拼写忘记了kubectl explain pods.spec.containers]]></content>
      <tags>
        <tag>Kubenetets</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubenetets 安装]]></title>
    <url>%2F2019%2F08%2F31%2F2019-08-31-k8s%2F</url>
    <content type="text"><![CDATA[几种部署方式 minikube安装 Minikube是一个工具，可以在本地快速运行一个单点的Kubernetes，仅用于尝试Kubernetes或日常开发的用户使用。 部署地址:https://kubernetes.io/docs/setup/minikube/ kubeadm Kubeadm也是一个工具，提供kubeadm init和kubeadm join，用于快速部署Kubernetes集群。 部署地址:https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/ 二进制包 推荐，从官方下载发行版的二进制包，手动部署每个组件，组成Kubernetes集群。 下载地址:https://github.com/kubernetes/kubernetes/releases 环境概要本次部署采用二进制包部署方式 软件环境 软件 版本 操作系统 CentOS7.2_x64 Docker 18-ce Kubernetes 1.12 服务器角色 角色 IP 组件 k8s-master 192.168.31.63 kube-apiserver，kube-controller-manager，kube-scheduler，etcd k8s-node1 192.168.31.65 kubelet，kube-proxy，docker，flannel，etcd k8s-node2 192.168.31.66 kubelet，kube-proxy，docker，flannel，etcd 部署Etcd集群使用cfssl来生成自签证书，先下载cfssl工具1234567wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64mv cfssl_linux-amd64 /usr/local/bin/cfsslmv cfssljson_linux-amd64 /usr/local/bin/cfssljsonmv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo ssl证书介绍 组件 使用的证书 etcd ca.pem，server.pem，server-key.pem flannel ca.pem，server.pem，server-key.pem kube-apiserver ca.pem，server.pem，server-key.pem kubelet ca.pem，ca-key.pem kube-proxy ca.pem，kube-proxy.pem，kube-proxy-key.pem kubectl ca.pem，admin.pem，admin-key.pem 生成证书创建三个证书文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859cat &gt; ca-config.json &lt;&lt;EOF&#123; "signing": &#123; "default": &#123; "expiry": "87600h" &#125;, "profiles": &#123; "www": &#123; "expiry": "87600h", "usages": [ "signing", "key encipherment", "server auth", "client auth" ] &#125; &#125; &#125;&#125;EOFcat &gt; ca-csr.json &lt;&lt;EOF&#123; "CN": "etcd CA", "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "Beijing", "ST": "Beijing" &#125; ]&#125;EOFcat &gt; server-csr.json &lt;&lt;EOF&#123; "CN": "etcd", "hosts": [ "192.168.31.63", "192.168.31.65", "192.168.31.66" ], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "BeiJing", "ST": "BeiJing" &#125; ]&#125;EOF 生成证书文件1234567cfssl gencert -initca ca-csr.json | cfssljson -bare ca -2019/08/31 11:55:49 [INFO] generating a new CA key and certificate from CSR2019/08/31 11:55:49 [INFO] generate received request2019/08/31 11:55:49 [INFO] received CSR2019/08/31 11:55:49 [INFO] generating key: rsa-20482019/08/31 11:55:49 [INFO] encoded CSR2019/08/31 11:55:49 [INFO] signed certificate with serial number 582209368862156632257687895161263330996641539441 12345678910cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server2019/08/31 12:00:13 [INFO] generate received request2019/08/31 12:00:13 [INFO] received CSR2019/08/31 12:00:13 [INFO] generating key: rsa-20482019/08/31 12:00:13 [INFO] encoded CSR2019/08/31 12:00:13 [INFO] signed certificate with serial number 2222833704264065612086082250864216905534327434712019/08/31 12:00:13 [WARNING] This certificate lacks a "hosts" field. This makes it unsuitable forwebsites. For more information see the Baseline Requirements for the Issuance and Managementof Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);specifically, section 10.2.3 ("Information Requirements"). pem文件是生成好的证书 遇到这个warning可以忽略123lsca-config.json ca-csr.json ca.pem server.csr server-key.pemca.csr ca-key.pem Kubernetes-YAML server-csr.json server.pem 部署Etcd二进制包下载地址：https://github.com/coreos/etcd/releases/tag/v3.2.12 将etcd安装到opt目录下123mkdir /opt/etcd/&#123;bin,cfg,ssl&#125; -ptar zxvf etcd-v3.2.12-linux-amd64.tar.gzmv etcd-v3.2.12-linux-amd64/&#123;etcd,etcdctl&#125; /opt/etcd/bin/ 配置文件：12345678910111213cat /opt/etcd/cfg/etcd #[Member]ETCD_NAME=&quot;etcd01&quot;ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;ETCD_LISTEN_PEER_URLS=&quot;https://192.168.31.63:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.31.63:2379&quot;#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.31.63:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.31.63:2379&quot;ETCD_INITIAL_CLUSTER=&quot;etcd01=https://192.168.31.63:2380,etcd02=https://192.168.31.65:2380,etcd03=https://192.168.31.66:2380&quot;ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot; ETCD_NAME 节点名称 ETCD_DATA_DIR 数据目录 ETCD_LISTEN_PEER_URLS 集群通信监听地址 ETCD_LISTEN_CLIENT_URLS 客户端访问监听地址 ETCD_INITIAL_ADVERTISE_PEER_URLS 集群通告地址 ETCD_ADVERTISE_CLIENT_URLS 客户端通告地址 ETCD_INITIAL_CLUSTER 集群节点地址 ETCD_INITIAL_CLUSTER_TOKEN 集群Token ETCD_INITIAL_CLUSTER_STATE 加入集群的当前状态，new是新集群，existing表示加入已有集群 systemd管理etcd：12345678910111213141516171819202122232425262728293031cat /usr/lib/systemd/system/etcd.service [Unit]Description=Etcd ServerAfter=network.targetAfter=network-online.targetWants=network-online.target[Service]Type=notifyEnvironmentFile=/opt/etcd/cfg/etcdExecStart=/opt/etcd/bin/etcd \--name=$&#123;ETCD_NAME&#125; \--data-dir=$&#123;ETCD_DATA_DIR&#125; \--listen-peer-urls=$&#123;ETCD_LISTEN_PEER_URLS&#125; \--listen-client-urls=$&#123;ETCD_LISTEN_CLIENT_URLS&#125;,http://127.0.0.1:2379 \--advertise-client-urls=$&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \--initial-advertise-peer-urls=$&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \--initial-cluster=$&#123;ETCD_INITIAL_CLUSTER&#125; \--initial-cluster-token=$&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \--initial-cluster-state=new \--cert-file=/opt/etcd/ssl/server.pem \--key-file=/opt/etcd/ssl/server-key.pem \--peer-cert-file=/opt/etcd/ssl/server.pem \--peer-key-file=/opt/etcd/ssl/server-key.pem \--trusted-ca-file=/opt/etcd/ssl/ca.pem \--peer-trusted-ca-file=/opt/etcd/ssl/ca.pemRestart=on-failureLimitNOFILE=65536[Install]WantedBy=multi-user.target 把刚才生成的证书拷贝到配置文件中的位置：1cp ca*pem server*pem /opt/etcd/ssl 启动并设置开启启动:12systemctl start etcdsystemctl enable etcd 都部署完成后，检查etcd集群状态：1234/opt/etcd/bin/etcdctl \--ca-file=ca.pem --cert-file=server.pem --key-file=server-key.pem \--endpoints="https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379" \cluster-health 1234member 72130f86e474b7bb is healthy: got healthy result from https://192.168.31.66:2379member b46624837acedac9 is healthy: got healthy result from https://192.168.31.63:2379member fd9073b56d4868cb is healthy: got healthy result from https://192.168.31.65:2379cluster is healthy 如果输出上面信息，就说明集群部署成功。如果有问题第一步先看日志：/var/log/message 或 journalctl -u etcd 部署Flannel网络Falnnel要用etcd存储自身一个子网信息，所以要保证能成功连接Etcd，在master01节点写入预定义子网段：1234/opt/etcd/bin/etcdctl \--ca-file=ca.pem --cert-file=server.pem --key-file=server-key.pem \--endpoints="https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379" \set /coreos.com/network/config '&#123; "Network": "172.17.0.0/16", "Backend": &#123;"Type": "vxlan"&#125;&#125;' 以下部署步骤在规划的每个node节点都操作。123wget https://github.com/coreos/flannel/releases/download/v0.10.0/flannel-v0.10.0-linux-amd64.tar.gztar zxvf flannel-v0.9.1-linux-amd64.tar.gzmv flanneld mk-docker-opts.sh /opt/kubernetes/bin 配置部署Flannel脚本：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#!/bin/bashETCD_ENDPOINTS=$&#123;1:-"http://127.0.0.1:2379"&#125;cat &lt;&lt;EOF &gt;/opt/kubernetes/cfg/flanneldFLANNEL_OPTIONS="--etcd-endpoints=$&#123;ETCD_ENDPOINTS&#125; \-etcd-cafile=/opt/etcd/ssl/ca.pem \-etcd-certfile=/opt/etcd/ssl/server.pem \-etcd-keyfile=/opt/etcd/ssl/server-key.pem"EOFcat &lt;&lt;EOF &gt;/usr/lib/systemd/system/flanneld.service[Unit]Description=Flanneld overlay address etcd agentAfter=network-online.target network.targetBefore=docker.service[Service]Type=notifyEnvironmentFile=/opt/kubernetes/cfg/flanneldExecStart=/opt/kubernetes/bin/flanneld --ip-masq \$FLANNEL_OPTIONSExecStartPost=/opt/kubernetes/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/subnet.envRestart=on-failure[Install]WantedBy=multi-user.targetEOFcat &lt;&lt;EOF &gt;/usr/lib/systemd/system/docker.service[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target firewalld.serviceWants=network-online.target[Service]Type=notifyEnvironmentFile=/run/flannel/subnet.envExecStart=/usr/bin/dockerd \$DOCKER_NETWORK_OPTIONSExecReload=/bin/kill -s HUP \$MAINPIDLimitNOFILE=infinityLimitNPROC=infinityLimitCORE=infinityTimeoutStartSec=0Delegate=yesKillMode=processRestart=on-failureStartLimitBurst=3StartLimitInterval=60s[Install]WantedBy=multi-user.targetEOFsystemctl daemon-reloadsystemctl enable flanneldsystemctl restart flanneldsystemctl restart docker 1sh flannel.sh https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379 如果在vagrant+virtualbox环境下需要在/opt/kubernetes/cfg/flanneld配置文件追加参数–iface=本机物理网卡名称 网络验证node0112345678910111213141516171819[root@node01 vagrant]docker run -it busybox/ # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever10: eth0@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1450 qdisc noqueue link/ether 02:42:ac:11:1a:02 brd ff:ff:ff:ff:ff:ff inet 172.17.26.2/24 brd 172.17.26.255 scope global eth0 valid_lft forever preferred_lft forever/ # ping 172.17.94.2PING 172.17.94.2 (172.17.94.2): 56 data bytes64 bytes from 172.17.94.2: seq=0 ttl=62 time=0.684 ms64 bytes from 172.17.94.2: seq=1 ttl=62 time=0.735 ms^C--- 172.17.94.2 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.684/0.709/0.735 ms/ # node02123456789101112131415161718[root@node02 ssl]docker run -it busybox/ # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever10: eth0@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1450 qdisc noqueue link/ether 02:42:ac:11:5e:02 brd ff:ff:ff:ff:ff:ff inet 172.17.94.2/24 brd 172.17.94.255 scope global eth0 valid_lft forever preferred_lft forever/ # ping 172.17.26.2PING 172.17.26.2 (172.17.26.2): 56 data bytes64 bytes from 172.17.26.2: seq=0 ttl=62 time=0.604 ms64 bytes from 172.17.26.2: seq=1 ttl=62 time=0.571 ms--- 172.17.26.2 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.571/0.587/0.604 ms/ # 在Master节点部署组件 在部署Kubernetes之前一定要确保etcd、flannel、docker是正常工作的，否则先解决问题再继续。 生成证书创建CA证书：12345678910111213141516171819202122232425262728# cat server-csr.json&#123; "CN": "kubernetes", "hosts": [ "10.0.0.1", "127.0.0.1", "192.168.31.63", "kubernetes", "kubernetes.default", "kubernetes.default.svc", "kubernetes.default.svc.cluster", "kubernetes.default.svc.cluster.local" ], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "BeiJing", "ST": "BeiJing", "O": "k8s", "OU": "System" &#125; ]&#125;cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server 生成kube_proxy证书1234567891011121314151617181920# cat kube-proxy-csr.json&#123; "CN": "system:kube-proxy", "hosts": [], "key": &#123; "algo": "rsa", "size": 2048 &#125;, "names": [ &#123; "C": "CN", "L": "BeiJing", "ST": "BeiJing", "O": "k8s", "OU": "System" &#125; ]&#125;# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 最终生成以下证书文件：12# ls *pemca-key.pem ca.pem kube-proxy-key.pem kube-proxy.pem server-key.pem server.pem 部署apiserver组件下载二进制包：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md下载这个包（kubernetes-server-linux-amd64.tar.gz）就够了，包含了所需的所有组件。 123456789mkdir /opt/kubernetes/&#123;bin,cfg,ssl&#125; -ptar zxvf kubernetes-server-linux-amd64.tar.gzcd kubernetes/server/bincp kube-apiserver kube-scheduler kube-controller-manager kubectl /opt/kubernetes/binsudo ln -s /opt/kubernetes/bin/kube-controller-manager /usr/local/bin/kube-controller-managersudo ln -s /opt/kubernetes/bin/kube-scheduler /usr/local/bin/kube-schedulersudo ln -s /opt/kubernetes/bin/kube-apiserver /usr/local/bin/kube-apiserversudo ln -s /opt/kubernetes/bin/kubectl /usr/local/bin/kubectl 配置文件生成12345678910111213141516171819202122# cat /opt/kubernetes/cfg/kube-apiserver KUBE_APISERVER_OPTS="--logtostderr=true \--v=4 \--etcd-servers=https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379 \--bind-address=192.168.31.63 \--secure-port=6443 \--advertise-address=192.168.31.63 \--allow-privileged=true \--service-cluster-ip-range=10.0.0.0/24 \--enable-admission-plugins=NamespaceLifecycle,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota,NodeRestriction \--authorization-mode=RBAC,Node \--enable-bootstrap-token-auth \--token-auth-file=/opt/kubernetes/cfg/token.csv \--service-node-port-range=30000-50000 \--tls-cert-file=/opt/kubernetes/ssl/server.pem \--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \--client-ca-file=/opt/kubernetes/ssl/ca.pem \--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \--etcd-cafile=/opt/etcd/ssl/ca.pem \--etcd-certfile=/opt/etcd/ssl/server.pem \--etcd-keyfile=/opt/etcd/ssl/server-key.pem" 配置好前面生成的证书，确保能连接etcd。 参数说明： –logtostderr 启用日志—v 日志等级–etcd-servers etcd集群地址–bind-address 监听地址–secure-port https安全端口–advertise-address 集群通告地址–allow-privileged 启用授权–service-cluster-ip-range Service虚拟IP地址段–enable-admission-plugins 准入控制模块–authorization-mode 认证授权，启用RBAC授权和节点自管理–enable-bootstrap-token-auth 启用TLS bootstrap功能，后面会讲到–token-auth-file token文件–service-node-port-range Service Node类型默认分配端口范围 创建token文件，1674c457d4dcf2eefe4920d7dbb6b0ddc,kubelet-bootstrap,10001,"system:kubelet-bootstrap" 第一列：随机字符串，自己可生成第二列：用户名第三列：UID第四列：用户组 systemd管理apiserver：123456789101112cat /usr/lib/systemd/system/kube-apiserver.service [Unit]Description=Kubernetes API ServerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=-/opt/kubernetes/cfg/kube-apiserverExecStart=/opt/kubernetes/bin/kube-apiserver $KUBE_APISERVER_OPTSRestart=on-failure[Install]WantedBy=multi-user.target 启动：123systemctl daemon-reloadsystemctl enable kube-apiserversystemctl restart kube-apiserver 部署scheduler组件配置文件：123456cat /opt/kubernetes/cfg/kube-scheduler KUBE_SCHEDULER_OPTS="--logtostderr=true \--v=4 \--master=127.0.0.1:8080 \--leader-elect" 参数说明： –master 连接本地apiserver–leader-elect 当该组件启动多个时，自动选举（HA） systemd管理schduler组件：123456789101112cat /usr/lib/systemd/system/kube-scheduler.service [Unit]Description=Kubernetes SchedulerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=-/opt/kubernetes/cfg/kube-schedulerExecStart=/opt/kubernetes/bin/kube-scheduler $KUBE_SCHEDULER_OPTSRestart=on-failure[Install]WantedBy=multi-user.target 启动123systemctl daemon-reloadsystemctl enable kube-schedulersystemctl restart kube-scheduler 部署controller-manager组件配置文件：123456789101112cat /opt/kubernetes/cfg/kube-controller-manager KUBE_CONTROLLER_MANAGER_OPTS="--logtostderr=true \--v=4 \--master=127.0.0.1:8080 \--leader-elect=true \--address=127.0.0.1 \--service-cluster-ip-range=10.0.0.0/24 \--cluster-name=kubernetes \--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \--root-ca-file=/opt/kubernetes/ssl/ca.pem \--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem" systemd管理controller-manager组件：123456789101112cat /usr/lib/systemd/system/kube-controller-manager.service [Unit]Description=Kubernetes Controller ManagerDocumentation=https://github.com/kubernetes/kubernetes[Service]EnvironmentFile=-/opt/kubernetes/cfg/kube-controller-managerExecStart=/opt/kubernetes/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_OPTSRestart=on-failure[Install]WantedBy=multi-user.target 启动：123systemctl daemon-reloadsystemctl enable kube-controller-managersystemctl restart kube-controller-manager 所有组件都已经启动成功，通过kubectl工具查看当前集群组件状态： 1234567/opt/kubernetes/bin/kubectl get csNAME STATUS MESSAGE ERRORscheduler Healthy okcontroller-manager Healthy oketcd-0 Healthy &#123;"health":"true"&#125;etcd-1 Healthy &#123;"health":"true"&#125;etcd-2 Healthy &#123;"health":"true"&#125; 如上输出说明组件都正常 在node节点部署组件Master apiserver启用TLS认证后，Node节点kubelet组件想要加入集群，必须使用CA签发的有效证书才能与apiserver通信，当Node节点很多时，签署证书是一件很繁琐的事情，因此有了TLS Bootstrapping机制，kubelet会以一个低权限用户自动向apiserver申请证书，kubelet的证书由apiserver动态签署。 认证大致工作流程如图所示： 将kubelet-bootstrap用户绑定到系统集群角色在master01节点操作123kubectl create clusterrolebinding kubelet-bootstrap \ --clusterrole=system:node-bootstrapper \ --user=kubelet-bootstrap 创建kubeconfig文件在master01节点操作在生成kubernetes证书的目录下执行以下命令生成kubeconfig文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 创建kubelet bootstrapping kubeconfig BOOTSTRAP_TOKEN=674c457d4dcf2eefe4920d7dbb6b0ddcKUBE_APISERVER="https://192.168.31.63:6443"# 设置集群参数kubectl config set-cluster kubernetes \ --certificate-authority=./ca.pem \ --embed-certs=true \ --server=$&#123;KUBE_APISERVER&#125; \ --kubeconfig=bootstrap.kubeconfig# 设置客户端认证参数kubectl config set-credentials kubelet-bootstrap \ --token=$&#123;BOOTSTRAP_TOKEN&#125; \ --kubeconfig=bootstrap.kubeconfig# 设置上下文参数kubectl config set-context default \ --cluster=kubernetes \ --user=kubelet-bootstrap \ --kubeconfig=bootstrap.kubeconfig# 设置默认上下文kubectl config use-context default --kubeconfig=bootstrap.kubeconfigkubectl config set-cluster kubernetes \ --certificate-authority=./ca.pem \ --embed-certs=true \ --server=$&#123;KUBE_APISERVER&#125; \ --kubeconfig=kube-proxy.kubeconfigkubectl config set-credentials kube-proxy \ --client-certificate=./kube-proxy.pem \ --client-key=./kube-proxy-key.pem \ --embed-certs=true \ --kubeconfig=kube-proxy.kubeconfigkubectl config set-context default \ --cluster=kubernetes \ --user=kube-proxy \ --kubeconfig=kube-proxy.kubeconfigkubectl config use-context default --kubeconfig=kube-proxy.kubeconfig 将这两个文件拷贝到Node节点/opt/kubernetes/cfg目录下。 部署kubelet组件将前面下载的二进制包中的kubelet和kube-proxy拷贝到/opt/kubernetes/bin目录下。 创建kubelet配置文件： 123456789# cat /opt/kubernetes/cfg/kubeletKUBELET_OPTS="--logtostderr=true \--v=4 \--hostname-override=192.168.31.65 \--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \--config=/opt/kubernetes/cfg/kubelet.config \--cert-dir=/opt/kubernetes/ssl \--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0" 参数说明： hostname-override 在集群中显示的主机名 kubeconfig 指定kubeconfig文件位置，会自动生成 bootstrap-kubeconfig 指定刚才生成的bootstrap.kubeconfig文件 cert-dir 颁发证书存放位置 pod-infra-container-image 管理Pod网络的镜像 其中/opt/kubernetes/cfg/kubelet.config配置文件如下： 123456789101112kind: KubeletConfigurationapiVersion: kubelet.config.k8s.io/v1beta1address: 192.168.31.65port: 10250readOnlyPort: 10255cgroupDriver: cgroupfsclusterDNS: ["10.0.0.2"]clusterDomain: cluster.local.failSwapOn: falseauthentication: anonymous: enabled: true systemd管理kubelet组件： 1234567891011121314cat /usr/lib/systemd/system/kubelet.service [Unit]Description=Kubernetes KubeletAfter=docker.serviceRequires=docker.service[Service]EnvironmentFile=/opt/kubernetes/cfg/kubeletExecStart=/opt/kubernetes/bin/kubelet $KUBELET_OPTSRestart=on-failureKillMode=process[Install]WantedBy=multi-user.target 启动: 123systemctl daemon-reloadsystemctl enable kubeletsystemctl restart kubelet 在Master审批Node加入集群： 启动后还没加入到集群中，需要手动允许该节点才可以。在Master节点查看请求签名的Node： 123kubectl get csrkubectl certificate approve XXXXIDkubectl get node 部署kube-proxy组件创建kube-proxy配置文件： 123456cat /opt/kubernetes/cfg/kube-proxyKUBE_PROXY_OPTS="--logtostderr=true \--v=4 \--hostname-override=192.168.31.65 \--cluster-cidr=10.0.0.0/24 \--kubeconfig=/opt/kubernetes/cfg/kube-proxy.kubeconfig" systemd管理kube-proxy组件： 123456789101112cat /usr/lib/systemd/system/kube-proxy.service [Unit]Description=Kubernetes ProxyAfter=network.target[Service]EnvironmentFile=/opt/kubernetes/cfg/kube-proxyExecStart=/opt/kubernetes/bin/kube-proxy $KUBE_PROXY_OPTSRestart=on-failure[Install]WantedBy=multi-user.target 启动:123systemctl daemon-reloadsystemctl enable kube-proxysystemctl restart kube-proxy Node2部署方式一样。 查看集群状态1234567891011[root@master01 system]# kubectl get nodeNAME STATUS ROLES AGE VERSION192.168.31.65 Ready &lt;none&gt; 40m v1.12.1192.168.31.66 Ready &lt;none&gt; 108s v1.12.1[root@master01 system]# kubectl get csNAME STATUS MESSAGE ERRORcontroller-manager Healthy okscheduler Healthy oketcd-2 Healthy &#123;"health":"true"&#125;etcd-1 Healthy &#123;"health":"true"&#125;etcd-0 Healthy &#123;"health":"true"&#125;]]></content>
      <tags>
        <tag>Kubenetets</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch Search API]]></title>
    <url>%2F2019%2F03%2F15%2F2019-03-15-elasticsearch-num5%2F</url>
    <content type="text"><![CDATA[官方文档实现对es中存储的数据进行查询分析，endpoint为_search，查询主要有两种形式： URI Search：操作简便，方便通过命令行测试，仅包含部分查询语法 Request Body Search：es提供完备查询语法Query DSL 示例：request123456789GET /user/_search?q=gender:MGET /user/_search&#123; "query": &#123; "match": &#123; "gender": "M" &#125; &#125;&#125; URI Search详解通过url query参数来实现搜索，常用参数如下： q: 指定查询语句，语法为 Query String Syntax df: q中不指定字段时默认查询的字段，如果不指定，es会查询所有字段 sort：排序 timeout：指定超时时间，默认不超时 from,size：用于分页 request12GET /myindex/_search?q=alfred&amp;df=user&amp;sort=age:asc&amp;from=4&amp;size=10&amp;timeout=1s#查询user字段包含alfred的文档，结果按照age升序排列，返回第5-14个文档，如果超过1s没有结束，则以超时结束 Query String Syntax语法介绍 term与phrase 12alfred way 等效于 alfred OR way"alfred way" 词语查询，要求先后顺序 泛查询 1alfred等效于在所有字段去匹配该term 指定字段 1name:alfred Group分组指定，使用括号指定匹配的规则 12(quick OR brown) AND foxstatus:(active OR pending) title:(full text search) q=&lt;…&gt;内容如果有空格会当作or处理 加括号和不加括号的区别：加括号表示status是active或status是pengding结果，不加括号表示status是active或者结果中包含pending 布尔操作符AND(&amp;&amp;),OR(||),NOT(!) 1name:(tom NOT lee) 注意大写，不能小写 “+ -“分别对应must和must_not 123name:(tom +lee -alfred)等价于name:((lee &amp;&amp; !alfred)||(tom &amp;&amp; lee &amp;&amp; !alfred)) +在url中会被解析为空格，要使用encode后的结果才可以，为%2B 范围查询，支持数值和日志 区间写法，闭区间用[],开区间用{} 1234age: [1 TO 10]意为 1&lt;=age&lt;=10age: [1 TO 10&#125;意为 1&lt;=age&lt;10age: [1 TO ]意为 age&gt;=1age: [* TO 10]意为 age&lt;=10 算数符号写法 12age:&gt;=1age:(&gt;=1&amp;&amp;&lt;=10)或者age:(+&gt;=1 +&lt;=10) 通配符查询：？代表一个字符，*代表0或多个字符 12345name:t?mname:tom*通配符匹配执行效率低，且占用较多内存，不建议使用如无特殊需求，不要将?/*放在最前面 正则表达式 1name:/[mb]oat/ 模糊匹配 fuzzy query 12name:roam~1匹配与roam差一个character的词，比如foam roams等 近似度查询 proximity search 123"fox quick"~5允许fox 和quick 之间差5个词语以term为单位进行差异比较，比如"quick fox" "quick brown fox"都会被匹配 查询示例添加一些数据request1234567891011121314151617181920DELETE test_search_indexPUT test_search_index&#123; "settings": &#123; "index":&#123; "number_of_shards": "1" &#125; &#125;&#125;POST test_search_index/_bulk&#123;"index":&#123;"_id":"1"&#125;&#125;&#123;"username":"alfred way","job":"java engineer","age":18,"birth":"1990-01-02","isMarried":false&#125;&#123;"index":&#123;"_id":"2"&#125;&#125;&#123;"username":"alfred","job":"java senior engineer and java specialist","age":28,"birth":"1980-05-07","isMarried":true&#125;&#123;"index":&#123;"_id":"3"&#125;&#125;&#123;"username":"lee","job":"java and ruby engineer","age":22,"birth":"1985-08-07","isMarried":false&#125;&#123;"index":&#123;"_id":"4"&#125;&#125;&#123;"username":"alfred junior way","job":"ruby engineer","age":23,"birth":"1989-08-07","isMarried":false&#125; 查询所有关键词中有alfred的request123456GET test_search_index/_search?q=alfred#profile设置为true可以分析elasticsearch的具体过程GET test_search_index/_search?q=alfred&#123; "profile":true&#125; 查询所有关键词中有alfred的并指定为username字段request1GET test_search_index/_search?q=username:alfred 查询所有关键词中有alfred或者way的并指定为username字段request1GET test_search_index/_search?q=username:alfred way 如果加上””则表示关键词中必须包含alfred wayrequest1GET test_search_index/_search?q=username:"alfred way" username字段中必须包含alfred和其它字段包含way的request1GET test_search_index/_search?q=username:alfred AND way username字段中必须包含alfred和way的request1GET test_search_index/_search?q=username:(alfred AND way) 为了便于区别()的作用，在加入一条数据 request123POST test_search_index/doc/_bulk/&#123;"index":&#123;"_id":"7"&#125;&#125;&#123;"username":"alfred","job":"java engineer way","age":18,"birth":"1990-01-02","isMarried":false&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#q=username:alfred AND wayd的结果&#123; "took" : 3, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 3, "max_score" : 2.329832, "hits" : [ &#123; "_index" : "test_search_index", "_type" : "doc", "_id" : "7", "_score" : 2.329832, "_source" : &#123; "username" : "alfred", "job" : "java engineer way", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "doc", "_id" : "1", "_score" : 1.2048805, "_source" : &#123; "username" : "alfred way", "job" : "java engineer", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "doc", "_id" : "4", "_score" : 0.966926, "_source" : &#123; "username" : "alfred junior way", "job" : "ruby engineer", "age" : 23, "birth" : "1989-08-07", "isMarried" : false &#125; &#125; ] &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243#q=username:(alfred AND way)的结果&#123; "took" : 2, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 2, "max_score" : 1.2048805, "hits" : [ &#123; "_index" : "test_search_index", "_type" : "doc", "_id" : "1", "_score" : 1.2048805, "_source" : &#123; "username" : "alfred way", "job" : "java engineer", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "doc", "_id" : "4", "_score" : 0.966926, "_source" : &#123; "username" : "alfred junior way", "job" : "ruby engineer", "age" : 23, "birth" : "1989-08-07", "isMarried" : false &#125; &#125; ] &#125;&#125; username字段中必须包含alfred但是没有way的request1GET test_search_index/_search?q=username:(alfred NOT way) username必须含有way的request12GET test_search_index/_search?q=username:(alfred +way) +会被识别为空格GET test_search_index/_search?q=username:(alfred %2Bway) 范围查询：request123456GET test_search_index/_search?q=username:alfred age:&gt;26#username字段包含alfred或者age大于26GET test_search_index/_search?q=username:alfred AND age:&gt;20#username字段包含alfred并且age大于20GET test_search_index/_search?q=birth:(&gt;1980 AND &lt;1990)#birth字段在1980到1990之间 正则表达式和通配符:request12GET test_search_index/_search?q=username:alf*GET test_search_index/_search?q=username:/[a]?l.*/ 模糊查询和近似度：request1234GET test_search_index/_search?q=username:alfed~1GET test_search_index/_search?q=username:alfd~2GET test_search_index/_search?q=job:"java engineer"GET test_search_index/_search?q=job:"java engineer"~1 Request Body Search将查询语句通过http request body 发送到es，主要包含如下参数： query: 符合Query DSL语法的查询语句 from,size timeout sort … Query DSLQuery DSL: 基于json定义的查询语言，主要包含如下两种类型: 字段类查询：如term、match、range等，只针对某一字段进行查询 复合查询：如bool查询等，包含一个或多个字段类查询或者复合查询语句 字段类查询字段类查询主要包括以下两类： 全文匹配：针对text类型的字段进行全文检索，会对查询语句先进行分词处理，如match,match_phrase等query类型 单词匹配：不会对查询语句做分词处理，直接去匹配字段的倒排索引，如term,terms,range等query类型 查询示例 request12345678GET test_search_index/_search&#123; "query": &#123; "match": &#123; "username": "alfred way" &#125; &#125;&#125; 查询流程如下所示： 通过operator参数可以控制单词间的匹配关系，可选项为or和and（默认为or）通过minimum_should_match参数可以控制需要匹配的单词数 request123456789101112131415161718192021222324GET test_search_index/_search&#123; "query": &#123; "match": &#123; "username": &#123; "query": "alfred way", "operator": "and" &#125; &#125; &#125;&#125;GET test_search_index/_search&#123; "query": &#123; "match": &#123; "username": &#123; "query": "alfred way", "minimum_should_match": 2 &#125; &#125; &#125;&#125;#`alfred` 和 `way`必须同时存在才能满足 相关性算分相关性算分是指文档与查询语句间的相关度，英文为relevance通过倒排索引可以获取与查询语句相匹配的文档列表，那么如何将最符合用户查询需求的文档放到前列呢？本质是一个排序问题，排序依据是相关性算分。 相关性算分的几个重要概念： Term Frequency（TF）: 词频，即单词在该文档中出现的次数。词频越高，相关度越高 Document Frequency（DF）: 文档频率，即单词出现的文档数 Inverse Document Frequency（IDF）:逆向文档频率，与文档频率相反，简单理解为1/DF。即单词出现的文档数越少，相关度越高。 Field-length Norm: 文档越短，相关性越高 ES目前主要有两个相关性算分模型： TF/IDF模型 BM25模型：5.x之后的默认模型 可以通过explain参数来查看具体的计算方法，但要注意：es的算分是按照shard进行的，即shard分数计算时互相独立的，所以在使用explain的时候注意分片数；可以通过设置索引的分片数为1来避免这个问题。 request12345678&#123; "explain": true, "query": &#123; "match": &#123; "FIELD": "TEXT" &#125; &#125;&#125; Match-Phrase-Query对字段作检索,有顺序要求，API示例：request12345678GET test_search_index/_search&#123; "query": &#123; "match_phrase": &#123; "job": "engineer java" &#125; &#125;&#125; 通过slop参数可以控制单词间的间隔,类似url search里的近似度匹配 request1234567891011GET test_search_index/_search&#123; "query": &#123; "match_phrase": &#123; "job": &#123; "query": "java engineer", "slop": 1 &#125; &#125; &#125;&#125; Query-String-Query类似于URI Search中的q参数查询 request12345678910GET test_search_index/_search&#123; "profile": "true", "query": &#123; "query_string": &#123; "default_field": "job", "query": "engineer AND java" &#125; &#125;&#125; 多字段查询request12345678910GET test_search_index/_search&#123; "profile": "true", "query": &#123; "query_string": &#123; "fields": ["username", "job"], "query": "engineer AND alfred" &#125; &#125;&#125; Simple-Query-String-Query类似Query String ,但是会忽略错误的查询语法,并且仅支持部分查询语法其常用的逻辑符号如下,不能使用AND, OR, NOT等关键词 +代指AND |代指OR -代指NOT请求 request12345678910GET test_search_index/_search&#123; "profile": "true", "query": &#123; "simple_query_string": &#123; "fields": ["username"], "query": "alfred +way" &#125; &#125;&#125; 与?q=alfred +way不同的是这里的alfred 和 way必须同时存在 Term-Terms-Query将查询语句作为整个单词进行查询,即不对查询语句做分词处理: request123456789GET test_search_index/_search&#123; "profile": "true", "query": &#123; "term": &#123; "username": "alfred way" &#125; &#125;&#125; 一次传入多个单词进行查询:request123456789101112GET test_search_index/_search&#123; "profile": "true", "query": &#123; "terms": &#123; "username": [ "alfred", "way" ] &#125; &#125;&#125; Range Query范围查询主要针对数值和日期类型: request1234567891011GET test_search_index/_search&#123; "query": &#123; "range": &#123; "age": &#123; "gt": 20, "lt": 40 &#125; &#125; &#125;&#125; range 过滤器既能包含也能排除范围，通过下面的选项： gt: &gt; 大于 lt: &lt; 小于 gte: &gt;= 大于或等于 lte: &lt;= 小于或等于 range过滤器也可以用于日期字段：123456"range":&#123; "timestamp" : &#123; "gt" : "2014-01-01 00:00:00", "lt" : "2014-01-07 00:00:00" &#125;&#125; 这个过滤器将始终能找出所有时间戳大于当前时间减 1 小时的文档，让这个过滤器像移窗一样通过你的文档。 日期计算也能用于实际的日期，而不是仅仅是一个像 now 一样的占位符。只要在日期后加上双竖线 ||，就能使用日期数学表达式了。123456"range" : &#123; "timestamp" : &#123; "gt" : "2014-01-01 00:00:00", "lt" : "2014-01-01 00:00:00||+1M" &lt;1&gt; &#125;&#125; 早于 2014 年 1 月 1 号加一个月日期计算是与日历相关的，所以它知道每个月的天数，每年的天数，等等。更详细的关于日期的信息可以在这里找到日期格式手册 range过滤器也可以用于字符串。字符串范围根据字典或字母顺序来计算。例如，这些值按照字典顺序排序：假如我们想让范围从 a 开始而不包含 b，我们可以用类似的 range 过滤器语法：123456"range" : &#123; "title" : &#123; "gte" : "a", "lt" : "b" &#125;&#125; 数字和日期字段的索引方式让他们在计算范围时十分高效。但对于字符串来说却不是这样。为了在字符串上执行范围操作，Elasticsearch 会在这个范围内的每个短语执行 term 操作。这比日期或数字的范围操作慢得多。 字符串范围适用于一个基数较小的字段，一个唯一短语个数较少的字段。你的唯一短语数越多，搜索就越慢。 复合查询复合查询是指包含字段类查询或复合查询的类型,主要包括以下几类: constant_score query bool query dis_max query function_score query boosting query Constant Score Query该查询将其内部的查询结果文档得分都设定为1或者boost的值多用于结合bool查询实现自定义得分request123456789101112GET test_search_index/_search&#123; "query": &#123; "constant_score": &#123; "filter": &#123; "match": &#123; "username": "alfred" &#125; &#125; &#125; &#125;&#125; 查询结果12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&#123; "took" : 13, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 3, "relation" : "eq" &#125;, "max_score" : 1.0, "hits" : [ &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "1", "_score" : 1.0, "_source" : &#123; "username" : "alfred way", "job" : "java engineer", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "2", "_score" : 1.0, "_source" : &#123; "username" : "alfred", "job" : "java senior engineer and java specialist", "age" : 28, "birth" : "1980-05-07", "isMarried" : true &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "4", "_score" : 1.0, "_source" : &#123; "username" : "alfred junior way", "job" : "ruby engineer", "age" : 23, "birth" : "1989-08-07", "isMarried" : false &#125; &#125; ] &#125;&#125; Bool Query布尔查询由一个或多个布尔子句组成,主要包含如下4个: 子句 含义 filter 只过滤符合条件的文档，不计算相关性算分 must 文档必须符合must中所有条件，影响相关性算分 must_not 文档必须不符合must中所有条件 should 文档可以符合should中的条件，不计算相关性算分 filterAPI:request12345678910111213141516171819GET test_search_index/_search&#123; "query": &#123; "bool": &#123; "must": [ &#123;&#125; ], "must_not": [ &#123;&#125; ], "should": [ &#123;&#125; ], "filter": [ &#123;&#125; ] &#125; &#125;&#125; Filter查询只过滤符合条件的文档,不会进行相关性算分 es针对filter会有智能缓存,因此其执行效率很高做简单匹配查询且不考虑算分时,推荐使用filter替代query等 request1234567891011121314GET test_search_index/_search&#123; "query": &#123; "bool": &#123; "filter": [ &#123; "term": &#123; "username":"alfred" &#125; &#125; ] &#125; &#125;&#125; must:request12345678910111213141516171819GET test_search_index/_search&#123; "query": &#123; "bool": &#123; "must": [ &#123; "match": &#123; "username":"alfred" &#125; &#125;, &#123; "match": &#123; "job":"java" &#125; &#125; ] &#125; &#125;&#125; 返回结果:1234567891011121314151617181920212223242526&#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "2", "_score" : 1.2314217, "_source" : &#123; "username" : "alfred", "job" : "java senior engineer and java specialist", "age" : 28, "birth" : "1980-05-07", "isMarried" : true &#125;&#125;,&#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "1", "_score" : 1.1256535, "_source" : &#123; "username" : "alfred way", "job" : "java engineer", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125;&#125; _score为两个match查询到的分数之和 must_not:request123456789101112131415161718192021GET test_search_index/_search&#123; "query": &#123; "bool": &#123; "must": [ &#123; "match": &#123; "username":"alfred" &#125; &#125; ], "must_not": [ &#123; "match": &#123; "job":"specialist" &#125; &#125; ] &#125; &#125;&#125; 匹配username包含alfred并且job不能包含specialist Should: Should使用分两种情况: bool查询中只包含should ,不包含must查询 bool查询中同时包含should和must查询 只包含should时,文档必须满足至少一个条件 minimum_should_match可以控制满足条件的个数或者百分比 request12345678910111213GET test_search_index/_search&#123; "query": &#123; "bool": &#123; "should": [ &#123;"term": &#123;"username": "alfred"&#125;&#125;, &#123;"term": &#123;"username": "way"&#125;&#125;, &#123;"term": &#123;"username": "junior"&#125;&#125; ], "minimum_should_match": 2 &#125; &#125;&#125; 1234567891011121314151617181920212223242526&#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "4", "_score" : 1.8147054, "_source" : &#123; "username" : "alfred junior way", "job" : "ruby engineer", "age" : 23, "birth" : "1989-08-07", "isMarried" : false &#125; &#125;, &#123; "_index" : "test_search_index", "_type" : "_doc", "_id" : "1", "_score" : 0.97797304, "_source" : &#123; "username" : "alfred way", "job" : "java engineer", "age" : 18, "birth" : "1990-01-02", "isMarried" : false &#125; &#125; minimum_should_match加上后只返回了两个结果 同时包含should和must时,文档不必满足should中的条件,但是如果满足条件,会增加相关性得分 request12345678910111213GET test_search_index/_search&#123; "query": &#123; "bool": &#123; "should": [ &#123;"term": &#123;"job": "ruby"&#125;&#125; ], "must": [ &#123;"term": &#123;"username": "alfred"&#125;&#125; ] &#125; &#125;&#125; job 为ruby的会增加分数排名更靠前 Query Context VS Filter Context当一个查询语句位于Query或者Filter上下文时, es执行的结果会不同,对比如下: 上下文类型 执行类型 使用方式 查找与查询语句最匹配的文档，对所有文档进行算分和排序 querybool中的must和should 查找与查询语句相匹配的文档 bool中的filter与must_notconstant_score中的filter Count And Source Filteringcount 获取符合条件的文档数, endpoint为_count source filtering过滤返回结果中source中的字段,主要有如下几种方式: uri:request1GET test_search_index/_search?_source=username 禁用source:request1234GET test_search_index/_search&#123; "_source": false&#125; 传字段名:request1234GET test_search_index/_search&#123; "_source": ["username","job"]&#125; 包括和不包括模糊匹配request1234567GET test_search_index/_search&#123; "_source": &#123; "includes": "*i*", "excludes": "birth" &#125;&#125;]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch入门(二)]]></title>
    <url>%2F2019%2F03%2F14%2F2019-03-14-elasticsearch-num-4%2F</url>
    <content type="text"><![CDATA[mappingmapping是类似于数据库中的表结构定义，主要作用如下： 定义index下的字段名 定义字段类型，比如数值型、浮点型、布尔型等 定义倒排索引相关的设置，比如是否索引、记录position等 request1234567PUT test_index/_doc/1&#123; "username": "jack", "age": 15&#125;GET test_index/_mapping 自定义mappingrequest1234567891011121314PUT my_index&#123; "mappings": &#123; "dynamic": false, "properties": &#123; "username": &#123; "type": "keyword" &#125;, "age": &#123; "type": "integer" &#125; &#125; &#125;&#125; mapping中的字段类型一旦设置，禁止直接修改，因为 lucene实现的倒排索引生成后不允许修改，应该重新建立新的索引，然后做reindex操作。 但是可以新增字段，通过 dynamic 参数来控制字段的新增，这个参数的值如下： true：默认值，表示允许选自动新增字段false：不允许自动新增字段，但是文档可以正常写入，但无法对字段进行查询等操作strict：严格模式，文档不能写入，报错 然后写入一个文档: request123456PUT my_index/_doc/1&#123; "username": "lili", "desc": "this is my index", "age": 20&#125; 在mapping设置中，”dynamic”: false，表示在写入文档时，如果写入字段不存在也不会报错。这里的desc字段就是不存在的字段。 查询文档request12345678GET my_index/_search&#123; "query": &#123; "match": &#123; "username": "lili" &#125; &#125;&#125; request12345678GET my_index/_search&#123; "query": &#123; "match": &#123; "desc": "this is my index" &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 1, "relation" : "eq" &#125;, "max_score" : 0.2876821, "hits" : [ &#123; "_index" : "my_index", "_type" : "_doc", "_id" : "1", "_score" : 0.2876821, "_source" : &#123; "username" : "lili", "desc" : "this is my index", "age" : "20" &#125; &#125; ] &#125;&#125; 123456789101112131415161718&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 0, "relation" : "eq" &#125;, "max_score" : null, "hits" : [ ] &#125;&#125; 对比两个结果可以看出能通过mapping中设置的字段查询到 copy_to作用是将该字段的值复制到目标字段，实现类似（6.0版本之前的）_all的作用。不会出现在_source中，只能用来搜索。 request123456789101112131415161718PUT my_index2&#123; "mappings": &#123; "properties": &#123; "first_name": &#123; "type": "text", "copy_to": "full_name" &#125;, "last_name": &#123; "type": "text", "copy_to": "full_name" &#125;, "full_name": &#123; "type": "text" &#125; &#125; &#125;&#125; PUT：request12345PUT my_index2/_doc/1&#123; "first_name": "David", "last_name": "john"&#125; 查询：request1234567891011GET my_index2/_search&#123; "query": &#123; "match": &#123; "full_name": &#123; "query": "David john", "operator": "and" &#125; &#125; &#125;&#125; 返回结果: 1234567891011121314151617181920212223242526272829&#123; "took" : 316, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 1, "relation" : "eq" &#125;, "max_score" : 0.5753642, "hits" : [ &#123; "_index" : "my_index2", "_type" : "_doc", "_id" : "1", "_score" : 0.5753642, "_source" : &#123; "first_name" : "David", "last_name" : "john" &#125; &#125; ] &#125;&#125; 可以通过full_name来查询first_name，lastname两个字段，并且不区分大小写，但是一旦有一个字段的值匹配不上，就会返回为空 Indexindex参数作用是控制当前字段是否被索引，默认为true，false表示不记录，即不可被搜索。 request123456789101112131415PUT my_index3&#123; "mappings": &#123; "properties": &#123; "cookie": &#123; "type": "text", "index": false &#125;, "content": &#123; "type": "text", "index": true &#125; &#125; &#125;&#125; request12345PUT my_index3/_doc/1&#123; "cookie": "efdfsdiadsasd", "content": "this is a cookie"&#125; 查询测试：request12345678910111213141516GET my_index3/_search&#123; "query": &#123; "match": &#123; "cookie": "efdfsdiadsasd" &#125; &#125;&#125;GET my_index3/_search&#123; "query": &#123; "match": &#123; "content": "this is a cookie" &#125; &#125; cookie字段不可被查询12345678910111213141516171819202122232425262728293031323334&#123; "error": &#123; "root_cause": [ &#123; "type": "query_shard_exception", "reason": "failed to create query: &#123;\n \"match\" : &#123;\n \"cookie\" : &#123;\n \"query\" : \"efdfsdiadsasd\",\n \"operator\" : \"OR\",\n \"prefix_length\" : 0,\n \"max_expansions\" : 50,\n \"fuzzy_transpositions\" : true,\n \"lenient\" : false,\n \"zero_terms_query\" : \"NONE\",\n \"auto_generate_synonyms_phrase_query\" : true,\n \"boost\" : 1.0\n &#125;\n &#125;\n&#125;", "index_uuid": "5iLoJa4vRmiWA23sZ8-4TQ", "index": "my_index3" &#125; ], "type": "search_phase_execution_exception", "reason": "all shards failed", "phase": "query", "grouped": true, "failed_shards": [ &#123; "shard": 0, "index": "my_index3", "node": "IWeH0fFvQD604ZiJ9OAdRw", "reason": &#123; "type": "query_shard_exception", "reason": "failed to create query: &#123;\n \"match\" : &#123;\n \"cookie\" : &#123;\n \"query\" : \"efdfsdiadsasd\",\n \"operator\" : \"OR\",\n \"prefix_length\" : 0,\n \"max_expansions\" : 50,\n \"fuzzy_transpositions\" : true,\n \"lenient\" : false,\n \"zero_terms_query\" : \"NONE\",\n \"auto_generate_synonyms_phrase_query\" : true,\n \"boost\" : 1.0\n &#125;\n &#125;\n&#125;", "index_uuid": "5iLoJa4vRmiWA23sZ8-4TQ", "index": "my_index3", "caused_by": &#123; "type": "illegal_argument_exception", "reason": "Cannot search on field [cookie] since it is not indexed." &#125; &#125; &#125; ] &#125;, "status": 400&#125; index_options index_options的作用是用于控制倒排索引记录的内容，有如下四种配置： docs：只记录doc id freqs：记录doc id 和term frequencies positions：记录doc id、 term frequencies和term position offsets：记录doc id、 term frequencies、term position、character offsets text类型的默认配置为positions，其他默认为docs。 记录的内容越多，占据的空间越大。 index_options设定： request1234567891011PUT my_index4&#123; "mappings": &#123; "properties": &#123; "text": &#123; "type": "text", "index_options": "offsets" &#125; &#125; &#125;&#125; PUT:request1234PUT my_index4/_doc/1&#123; "text": "Quick brown fox"&#125; request12345678910111213GET my_index4/_search&#123; "query": &#123; "match": &#123; "text": "brown fox" &#125; &#125;, "highlight": &#123; "fields": &#123; "text": &#123;&#125; &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233&#123; "took" : 68, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 1, "relation" : "eq" &#125;, "max_score" : 0.5753642, "hits" : [ &#123; "_index" : "my_index4", "_type" : "_doc", "_id" : "1", "_score" : 0.5753642, "_source" : &#123; "text" : "Quick brown fox" &#125;, "highlight" : &#123; "text" : [ "Quick &lt;em&gt;brown&lt;/em&gt; &lt;em&gt;fox&lt;/em&gt;" ] &#125; &#125; ] &#125;&#125; brown fox会被高亮显示 null_value这个参数的作用是当字段遇到null值的时候的处理策略，默认为null，即空值，此时es会忽略该值。可以通过这个参数设置某个字段的默认值 request123456789101112131415161718192021222324252627282930PUT my_index5&#123; "mappings": &#123; "properties": &#123; "status_code": &#123; "type": "keyword", "null_value": "NULL" &#125; &#125; &#125;&#125;PUT my_index5/_doc/1&#123; "status_code": null&#125;PUT my_index5/_doc/2&#123; "status_code": [] &#125;GET my_index5/_search&#123; "query": &#123; "term": &#123; "status_code": "NULL" &#125; &#125;&#125; 12345678910111213141516171819202122232425262728&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 1, "successful" : 1, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : &#123; "value" : 1, "relation" : "eq" &#125;, "max_score" : 0.2876821, "hits" : [ &#123; "_index" : "my_index5", "_type" : "_doc", "_id" : "1", "_score" : 0.2876821, "_source" : &#123; "status_code" : null &#125; &#125; ] &#125;&#125; 用术语null替换显式null值。 空数组不包含显式null，因此不会用null_value替换。 对NULL的查询返回文档1，而不是文档2。 null_value需要与字段具有相同的数据类型。例如，长字段不能有字符串null_value。null_value只影响数据的索引方式，它不修改_source文档。 更多详见Mapping parameters 数据类型核心数据类型 字符串型：text、keyword（不会分词） 数值型：long、integer、short、byte、double、float、half_float等 日期类型：date 布尔类型：boolean 二进制类型：binary 范围类型：integer_range、float_range、long_range、double_range、date_range 复杂数据类型 数组类型：array 对象类型：object 嵌套类型：nested object 地理位置数据类型：geo_point、geo_shape 专用类型：ip（记录ip地址）、completion（实现自动补全）、token_count（记录分词数）、murmur3（记录字符串hash值） 多字段特性 多字段特性（multi-fields），表示允许对同一字段采用不同的配置，比如分词。 常见例子是对人名实现拼音搜索，只需要在人名中新增一个字段pinyin即可。但是这种方式不是十分优雅，multi-fields可以在不改变整体结构的前提下，增加一个子字段： request123456789101112131415161718192021222324PUT my_index6&#123; "mappings": &#123; "properties": &#123; "username": &#123; "type": "text", "fields": &#123; "pinyin": &#123; "type": "text", "analyzer": "pinyin" &#125; &#125; &#125; &#125; &#125;&#125;GET my_index6&#123; "query": &#123; "match": &#123; "username.pinyin": "pinyin" &#125; &#125;&#125; Dynamic mappingElasticsearch最重要的特性之一是，它试图摆脱您的阻碍，让您尽可能快地开始研究您的数据。要为文档建立索引，您不需要首先创建索引、定义映射类型和字段——您只需要为文档建立索引，索引、类型和字段就会自动出现: 默认情况下，当在文档中发现以前没有看到的字段时，Elasticsearch将把新字段添加到类型映射中。通过将动态参数设置为false(忽略新字段)或strict(遇到未知字段时抛出异常)，可以在文档和对象级别禁用此行为 字段映射规则 JSON类型 ES类型 null 忽略 true or false boolean floating point number float integer long object object array 取决于数组中的第一个非空值。 string 要么是一个日期字段(如果值通过了日期检测)，要么是一个双字段或长字段(如果值通过了数值检测)，要么是一个带有关键字子字段的文本字段。 request123456789101112131415DELETE test_indexPUT /test_index/_doc/1&#123; "username":"alfred", "age":1.2&#125;GET test_index/_search&#123; "query": &#123; "match": &#123; "username.keyword": "alfred" &#125; &#125;&#125; 当你索引一个包含新字段的文档——一个之前没有的字段——Elasticsearch将使用动态映射猜测字段类型，这类型来自于JSON的基本数据类型，使用以下规则： JSON type Field type Boolean: true or false &quot;boolean&quot; Whole number: 123 &quot;long&quot; Floating point: 123.45 &quot;double&quot; String, valid date: &quot;2014-09-15&quot; &quot;date&quot; String: &quot;foo bar&quot; &quot;string&quot; 注意这意味着，如果你索引一个带引号的数字——&quot;123&quot;，它将被映射为&quot;string&quot;类型，而不是&quot;long&quot;类型。然而，如果字段已经被映射为&quot;long&quot;类型，Elasticsearch将尝试转换字符串为long，并在转换失败时会抛出异常。 日期自动识别日期的自动识别可以自行配置日期的格式，默认情况下是：1["strict_date_opeional_time", "yyyy/MM/dd HH:mm:ss Z||yyyy/MM/dd Z"] strict_date_opeional_time 是ISO 标准的日期格式，完整的格式如下：1YYYY-MM-DDhh:mm:ssTZD(eg:1997-07-16y19:20:30+01:00) dynamic_date_formats：可以自定义日期类型date_detection：可以关闭日期自动识别机制（默认开启）首先创建一个日期自动识别的索引：request1234567891011121314DELETE my_indexPUT my_index&#123; "mappings": &#123; "dynamic_date_formats": ["MM/dd/yyyy"] &#125;&#125;PUT my_index/_doc/1&#123; "create_time": "09/21/2016"&#125;GET my_index/_mapping 123456789101112131415&#123; "my_index" : &#123; "mappings" : &#123; "dynamic_date_formats" : [ "MM/dd/yyyy" ], "properties" : &#123; "create_time" : &#123; "type" : "date", "format" : "MM/dd/yyyy" &#125; &#125; &#125; &#125;&#125; 关闭日期自动识别可以如下： request1234567891011PUT my_index1&#123; "mappings": &#123; "date_detection": false &#125;&#125;PUT my_index1/_doc/1 &#123; "create": "2015/09/02"&#125; 自定义时间类型: request1234567891011PUT my_index2&#123; "mappings": &#123; "dynamic_date_formats": ["MM/dd/yyyy"] &#125;&#125;PUT my_index2/_doc/1&#123; "create_date": "09/25/2015"&#125; 数字自动识别字符串为数字的时候，默认不会自动识别为整型，因为字符串中出现数字是完全合理的。numeric_detection 可以开启字符串中数字的自动识别 request123456789101112131415DELETE my_index3PUT my_index3&#123; "mappings": &#123; "numeric_detection": true &#125;&#125;PUT my_index3/_doc/1&#123; "my_float": "1.0", "my_integer": "1" &#125;GET my_index3/_mapping 123456789101112131415&#123; "my_index3" : &#123; "mappings" : &#123; "numeric_detection" : true, "properties" : &#123; "my_float" : &#123; "type" : "float" &#125;, "my_integer" : &#123; "type" : "long" &#125; &#125; &#125; &#125;&#125; Dynamic Template允许根据es自动识别的数据类型、字段名等动态设定字段类型，可以实现如下效果: 所有字符串都设定为keyword类型，即默认不分词 所有以message开头字段都设定为text类型，即分词 所有以long_开头的字段都设定为long类型 所有自动匹配为double类型的都设定为float类型，以节省空间 request12345678910111213141516171819202122PUT test_index&#123; "mappings": &#123; "dynamic_templates": [ &#123; "strings": &#123; "match_mapping_type": "string", "mapping": &#123; "type": "keyword" &#125; &#125; &#125; ] &#125;&#125;PUT test_index/_doc/1&#123; "name": "alfred"&#125;GET test_index/_mapping 匹配规则一般有如下几个参数： match_mapping_type: 匹配es自动识别的字段类型，如boolean,long,string等 match,unmatch：匹配字段名 path_match,path_unmatch: 匹配路径 设置以message开头的字段都设置为text类型 （顺序由上而下）request123456789101112131415161718192021222324PUT test_index&#123; "mappings": &#123; "dynamic_templates": [ &#123; "message_as_text": &#123; "match_mapping_type": "string", "match": "message*", "mapping": &#123; "type": "text" &#125; &#125; &#125;, &#123; "strings_as_keywords": &#123; "match_mapping_type": "string", "mapping": &#123; "type": "keyword" &#125; &#125; &#125; ] &#125;&#125;]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[elasticsearch入门]]></title>
    <url>%2F2019%2F03%2F08%2F2019-03-08-elasticsearch%2F</url>
    <content type="text"><![CDATA[入门介绍安装 ElasticSearch需要的jdk版本至少是1.8的，所以安装之前先查看jdk版本号 2.下载ElasticSearch123wget https://github.com/elastic/elasticsearch/archive/v6.5.0.tar.gztar -zxvf elasticsearch-6.5.0.tar.gzcd elasticsearch-6.5.0 简单本地集群环境搭建 vim config/elasticsearch.yml 1cluster.name: my-application 注释打开 启动三个集群命令123./bin/elasticsearch -Ehttp.port=7200 -Epath.data=node3./bin/elasticsearch -Ehttp.port=8200 -Epath.data=node2./bin/elasticsearch 集群状态查看 1234567pengshiliang@pengshiliang-OptiPlex-3020:~$ curl 127.0.0.1:9200/_cat/nodes?vip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name127.0.0.1 30 98 2 2.03 0.96 0.53 mdi - dRA_DV4127.0.0.1 30 98 2 2.03 0.96 0.53 mdi - j8_g2SD127.0.0.1 31 98 3 2.03 0.96 0.53 mdi * 3cYY9cLpengshiliang@pengshiliang-OptiPlex-3020:~$ curl 127.0.0.1:9200/_cluster/stats&#123;"_nodes":&#123;"total":3,"successful":3,"failed":0&#125;,"cluster_name":"my-application","cluster_uuid":"5nD6JB_MRyiin3n7QTCoDg","timestamp":1552028850410,"status":"green","indices":&#123;"count":0,"shards":&#123;&#125;,"docs":&#123;"count":0,"deleted":0&#125;,"store":&#123;"size_in_bytes":0&#125;,"fielddata":&#123;"memory_size_in_bytes":0,"evictions":0&#125;,"query_cache":&#123;"memory_size_in_bytes":0,"total_count":0,"hit_count":0,"miss_count":0,"cache_size":0,"cache_count":0,"evictions":0&#125;,"completion":&#123;"size_in_bytes":0&#125;,"segments":&#123;"count":0,"memory_in_bytes":0,"terms_memory_in_bytes":0,"stored_fields_memory_in_bytes":0,"term_vectors_memory_in_bytes":0,"norms_memory_in_bytes":0,"points_memory_in_bytes":0,"doc_values_memory_in_bytes":0,"index_writer_memory_in_bytes":0,"version_map_memory_in_bytes":0,"fixed_bit_set_memory_in_bytes":0,"max_unsafe_auto_id_timestamp":-9223372036854775808,"file_sizes":&#123;&#125;&#125;&#125;,"nodes":&#123;"count":&#123;"total":3,"data":3,"coordinating_only":0,"master":3,"ingest":3&#125;,"versions":["6.5.0"],"os":&#123;"available_processors":12,"allocated_processors":12,"names":[&#123;"name":"Linux","count":3&#125;],"mem":&#123;"total_in_bytes":24839368704,"free_in_bytes":437612544,"used_in_bytes":24401756160,"free_percent":2,"used_percent":98&#125;&#125;,"process":&#123;"cpu":&#123;"percent":0&#125;,"open_file_descriptors":&#123;"min":305,"max":306,"avg":305&#125;&#125;,"jvm":&#123;"max_uptime_in_millis":74396,"versions":[&#123;"version":"1.8.0_171","vm_name":"Java HotSpot(TM) 64-Bit Server VM","vm_version":"25.171-b11","vm_vendor":"Oracle Corporation","count":3&#125;],"mem":&#123;"heap_used_in_bytes":972703928,"heap_max_in_bytes":3116630016&#125;,"threads":143&#125;,"fs":&#123;"total_in_bytes":483753484288,"free_in_bytes":438342832128,"available_in_bytes":413745967104&#125;,"plugins":[],"network_types":&#123;"transport_types":&#123;"security4":3&#125;,"http_types":&#123;"security4":3&#125;&#125;&#125;&#125; 多机部署12network.host: your ip #（主机地址）对外发布的网络地址 discovery.zen.ping.unicast.hosts: ["$ip"] $ip一定要包含该集群中其他机器的ip Elasticsearch 常用术语Document 文档数据Index 索引Type 索引中的数据类型Field 字段，文档属性Query DSL查询语法 CRUDCreaterequest123456POST /accounts/person/1&#123; "name": "Bob", "job": "developer", "sex": "male"&#125; 这条语句表述的含义是在index为accounts的person类型下创建一条id为1的数据Result：1234567891011121314&#123; "_index" : "accounts", "_type" : "person", "_id" : "1", "_version" : 1, "result" : "created", "_shards" : &#123; "total" : 2, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 0, "_primary_term" : 1&#125; GETrequest1GET /accounts/person/1 Result：123456789101112&#123; "_index" : "accounts", "_type" : "person", "_id" : "1", "_version" : 1, "found" : true, "_source" : &#123; "name" : "Bob", "job" : "developer", "sex" : "male" &#125;&#125; Updaterequest123456POST /accounts/person/1/_update&#123; "doc": &#123; "name": "John" &#125;&#125; Result:1234567891011121314&#123; "_index" : "accounts", "_type" : "person", "_id" : "1", "_version" : 2, "result" : "updated", "_shards" : &#123; "total" : 2, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 1, "_primary_term" : 2&#125; Deleterequest1DELETE /accounts/person/1 Result: 1234567891011121314&#123; "_index" : "accounts", "_type" : "person", "_id" : "1", "_version" : 5, "result" : "deleted", "_shards" : &#123; "total" : 2, "successful" : 1, "failed" : 0 &#125;, "_seq_no" : 4, "_primary_term" : 2&#125; 查询语法Query String后面接?q形式request1GET /accounts/person/_search?q=John Query Dslrequest12345678GET /accounts/person/_search&#123; "query": &#123; "match": &#123; "name": "John" &#125; &#125;&#125; 详细参考query-dsl ElasticSearch初步介绍正排/倒排索引正排索引： 文档ID 文档内容 1 elasticsearch是最流行的搜索引擎 2 php是世界最好的语言 3 搜索引擎是如何诞生的 倒排索引： 文档内容 文档ID elasticsearch 1 流行 1 搜索引擎 1,3 php 2 世界 2 最好 2 语言 2 如何 3 诞生 3 查询包含搜索引擎的文档： 通过倒排索引获得含有“搜索引擎”的文档ID是1,3 通过正排索引查看1,3的内容 返回结果 倒排索引基本概念倒排索引(Inverted Index)：倒排索引是实现“单词-文档矩阵”的一种具体存储形式，通过倒排索引，可以根据单词快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：“单词词典”和“倒排文件”。 单词词典(Lexicon)：搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。 倒排列表(PostingList)：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。 倒排文件(Inverted File)：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即被称之为倒排文件，倒排文件是存储倒排索引的物理文件。 倒排索引的组成倒排索引是搜索引擎的核心，主要包含两个部分： 单词词典（Trem Dictionary）：记录的是所有的文档分词后的结果 倒排列表（Posting List）：记录了单词对应文档的集合，由倒排索引项（Posting）组成。 单词字典的实现一般采用B+Tree的方式，来保证高效 倒排索引项（Posting）主要包含如下的信息： 文档ID，用于获取原始文档的信息 单词频率（TF，Term Frequency），记录该单词在该文档中出现的次数，用于后续相关性算分。 位置（Position），记录单词在文档中的分词位置（多个），用于做词语搜索。 偏移（Offset），记录单词在文档的开始和结束位置，用于高亮显示 倒排列表： “elasticsearch是最流行的搜索引擎”可分为3个词语，搜索引擎在第二个位置，并且字符位置是18-22之间 es存储的是一个json格式的文档，其中包含多个字段，每个字段都会有自己的倒排索引，类似这种1234&#123; "username": "huangtoufa", "job": "programmer"&#125; job和username都有自己的倒排索引 分词介绍分词是指将文本转换成一系列单词( term or token )的过程,也可以叫做文本分析,在es里面称为Analysis ·分词器是es中专门处理分词的组件,英文为Analyzer ,它的组成如下 - Character Filters -针对原始文本进行处理,比如去除html特殊标记符 - Tokenizer -将原始文本按照一定规则切分为单词 - Token Filters -针对tokenizer处理的单词就行再加工,比如转小写、删除或新增等处理 分词调用顺序： analyze_api es提供了一个测试分词的api接口,方便验证分词效果, endpoint是_analyze -可以直接指定analyzer进行测试 -可以直接指定索引中的字段进行测试 -可以自定义分词器进行测试 关键词解释： analyzer：分词器text：分词文本token：分词结果start_offset：开始偏移位置end_offset：结束偏移位置position：分词位置 当没有定义analyzer的时候会使用默认分词器”analyzer”:”standard” 指定field分词： 自定义分词器：tokenizer指名要用哪个分词器，filter指明的是token filter： 自带分词器es自带如下的分词器 - Standard Simple - Whitespace - Stop - Keyword - Pattern - Language 中文分词·难点 -中文分词指的是将一个汉字序列切分成一个一个单独的词。在英文中,单词之间是以空格作为自然分界符,汉语中词没有一个形式上的分界符。 -上下文不同,分词结果迥异,比如交叉歧义问题,比如下面两种分词都合理 -乒乓球拍/卖完了 -乒乓球/拍卖/完了 ·常用分词系统 -IK -实现中英文单词的切分,支持ik smart, ik maxword等模式 -可自定义词库,支持热更新分词词典, - https://github.com/medcl/elasticsearch-analysis-ik - jieba -python中最流行的分词系统,支持分词和词性标注 -支持繁体分词、自定义词典、并行分词等 - https://github.com/sing1ee/elasticsearch-jieba-plugin·基于自然语言处理的分词系统 - Hanlp -由一系列模型与算法组成的Java工具包,目标是普及自然语言处理在生产环境中的应用 - https://github.com/hankcs/HanLP -THULAC -THU Lexical Analyzer for Chinese ,由清华大学自然语言处理与社会人文计算实验室研制推出的一套中文词法分析工具包,具有中文分词和词性标注功能 - https://github.com/microbun/elasticsearch-thulac-plugin 自定义分词CharacterFilter： 当自带的分词无法满足需求时,可以自定义分词 通过自定义Character Filters, Tokenizer和Token Filter实现. Character Filters 在Tokenizer之前对原始文本进行处理,比如增加、删除或替换字符等 自带的如下: HTML Strip去除html标签和转换html实体 Mapping进行字符替换操作 Pattern Replace进行正则匹配替换 会影响后续tokenizer解析的postion和offset信息 Character Filters测试时可以采用如下api : Tokenizer：Tokenizer 将原始文本按照一定规则切分为单词( term or token ) 自带的如下: standard按照单词进行分割 letter按照非字符类进行分割 whitespace按照空格进行分割 UAX URL Email按照standard分割,但不会分割邮箱和url NGram和Edge NGram连词分割 Path Hierarchy按照文件路径进行切割 api: request12345POST _analyze&#123; "tokenizer": "path_hierarchy", "text": "one/two/three"&#125; Result:12345678910111213141516171819202122232425&#123; "tokens" : [ &#123; "token" : "one", "start_offset" : 0, "end_offset" : 3, "type" : "word", "position" : 0 &#125;, &#123; "token" : "one/two", "start_offset" : 0, "end_offset" : 7, "type" : "word", "position" : 0 &#125;, &#123; "token" : "one/two/three", "start_offset" : 0, "end_offset" : 13, "type" : "word", "position" : 0 &#125; ]&#125; TokenFilter:Token Filters 对于tokenizer输出的单词( term )进行增加、删除、修改等操作 自带的如下: lowercase将所有term转换为小写 stop删除stop words NGram和Edge NGram连词分割 Synonym添加近义词的term api: request1234567891011121314POST _analyze&#123; "tokenizer": "standard", "text": "a Hello, world!", "filter": [ "stop", "lowercase", &#123; "type": "ngram", "min_gram": 4, "max_gram": 4 &#125; ]&#125; Result: 1234567891011121314151617181920212223242526272829303132&#123; "tokens" : [ &#123; "token" : "hell", "start_offset" : 2, "end_offset" : 7, "type" : "&lt;ALPHANUM&gt;", "position" : 1 &#125;, &#123; "token" : "ello", "start_offset" : 2, "end_offset" : 7, "type" : "&lt;ALPHANUM&gt;", "position" : 1 &#125;, &#123; "token" : "worl", "start_offset" : 9, "end_offset" : 14, "type" : "&lt;ALPHANUM&gt;", "position" : 2 &#125;, &#123; "token" : "orld", "start_offset" : 9, "end_offset" : 14, "type" : "&lt;ALPHANUM&gt;", "position" : 2 &#125; ]&#125; Custorm：自定义分词需要在索引的配置中设定,如下所示: 创建自定义分词器： request1234567891011121314151617181920PUT test_index&#123; "settings": &#123; "analysis": &#123; "analyzer": &#123; "my_custom_analyzer": &#123; "type": "custom", "tokenizer": "standard", "char_filter": [ "html_strip" ], "filter": [ "lowercase", "asciifolding" ] &#125; &#125; &#125; &#125;&#125; request1GET test_index 123456789101112131415161718192021222324252627282930313233&#123; "test_index" : &#123; "aliases" : &#123; &#125;, "mappings" : &#123; &#125;, "settings" : &#123; "index" : &#123; "number_of_shards" : "5", "provided_name" : "test_index", "creation_date" : "1552462361614", "analysis" : &#123; "analyzer" : &#123; "my_custom_analyzer" : &#123; "filter" : [ "lowercase", "asciifolding" ], "char_filter" : [ "html_strip" ], "type" : "custom", "tokenizer" : "standard" &#125; &#125; &#125;, "number_of_replicas" : "1", "uuid" : "novqTjprQE24bJPdtxydCA", "version" : &#123; "created" : "6050099" &#125; &#125; &#125; &#125;&#125; 自定义分词验证： request12345POST test_index/_analyze&#123; "analyzer": "my_custom_analyzer", "text": "&lt;a&gt;This is a &lt;b&gt;Text&lt;/b&gt;&lt;/a&gt;"&#125; 分词结果：1234567891011121314151617181920212223242526272829303132&#123; "tokens" : [ &#123; "token" : "this", "start_offset" : 3, "end_offset" : 7, "type" : "&lt;ALPHANUM&gt;", "position" : 0 &#125;, &#123; "token" : "is", "start_offset" : 8, "end_offset" : 10, "type" : "&lt;ALPHANUM&gt;", "position" : 1 &#125;, &#123; "token" : "a", "start_offset" : 11, "end_offset" : 12, "type" : "&lt;ALPHANUM&gt;", "position" : 2 &#125;, &#123; "token" : "text", "start_offset" : 16, "end_offset" : 28, "type" : "&lt;ALPHANUM&gt;", "position" : 3 &#125; ]&#125; 分词使用说明分词会在如下两个时机使用: 创建或更新文档时(Index Time ) ,会对相应的文档进行分词处理 查询时( Search Time ) ,会对查询语句进行分词 索引时分词索引时分词是通过配置Index Mapping中每个字段的analyzer属性实现的如下：不指定分词时,使用默认standard 查询时分词查询时分词的指定方式有如下几种: 查询的时候通过analyzer指定分词器 通过index mapping设置search_analyzer实现 实例1：我们做一个查询，我们试图通过搜索 message2 这个关键词来搜索这个文档request1234567891011121314151617181920212223GET test_index1/doc/1POST test_index1/doc/1&#123; "message": "this Is a Message"&#125;POST test_index1/doc/2&#123; "message": "this Is a Message2"&#125;POST test_index1/_search&#123; "query": &#123; "match": &#123; "message": &#123; "query": "message2", "analyzer": "standard" &#125; &#125; &#125;&#125; 返回结果：12345678910111213141516171819202122232425&#123; "took" : 1, "timed_out" : false, "_shards" : &#123; "total" : 5, "successful" : 5, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.2876821, "hits" : [ &#123; "_index" : "test_index1", "_type" : "doc", "_id" : "2", "_score" : 0.2876821, "_source" : &#123; "message" : "this Is a Message2" &#125; &#125; ] &#125;&#125; 查询时使用自定义分词器request1234567891011121314151617181920212223242526272829303132333435363738394041424344DELETE test_index1PUT test_index1&#123; "settings": &#123; "analysis": &#123; "analyzer": &#123; "my_custom_analyzer": &#123; "type": "custom", "tokenizer": "standard", "char_filter": [ "html_strip" ], "filter": [ "lowercase", "asciifolding" ] &#125; &#125; &#125; &#125;&#125;POST test_index1/doc/1&#123; "message": "&lt;a&gt;this Is a &lt;b&gt;Message&lt;/b&gt;&lt;/a&gt;"&#125;POST test_index1/doc/2&#123; "message": "&lt;a&gt;this Is a &lt;b&gt;Message2&lt;/b&gt;&lt;/a&gt;"&#125;POST test_index1/_search&#123; "query": &#123; "match": &#123; "message": &#123; "query": "Message2", "analyzer": "my_custom_analyzer" &#125; &#125; &#125;&#125; 分词建议 明确字段是否需要分词,不需要分词的字段就将type设置为keyword ,可以节省空间和提高写性能 善用_analyze API ,查看文档的具体分词结果 动手测试 分词使用分析创建自定义分词 request12345678910111213141516171819202122DELETE test_indexPUT test_index&#123; "settings": &#123; "analysis": &#123; "analyzer": &#123; "my_custom_analyzer": &#123; "type": "custom", "tokenizer": "standard", "char_filter": [ "html_strip" ], "filter": [ "lowercase", "asciifolding" ] &#125; &#125; &#125; &#125;&#125; 插入数据： request1234POST test_index/doc/1&#123; "message": "&lt;a&gt;This is a &lt;b&gt;Text&lt;/b&gt;&lt;/a&gt;"&#125; 分词检索：request1234567891011POST test_index/_search&#123; "query": &#123; "match": &#123; "message": &#123; "query": "&lt;div&gt;this is&lt;/div&gt;", "analyzer": "my_custom_analyzer" &#125; &#125; &#125;&#125; 返回结果： 12345678910111213141516171819202122232425&#123; "took" : 0, "timed_out" : false, "_shards" : &#123; "total" : 5, "successful" : 5, "skipped" : 0, "failed" : 0 &#125;, "hits" : &#123; "total" : 1, "max_score" : 0.5753642, "hits" : [ &#123; "_index" : "test_index", "_type" : "doc", "_id" : "1", "_score" : 0.5753642, "_source" : &#123; "message" : "&lt;a&gt;This is a &lt;b&gt;Text&lt;/b&gt;&lt;/a&gt;" &#125; &#125; ] &#125;&#125; 为什么会返回这条记录，我们使用分词分析来分析原因：request12345POST test_index/_analyze&#123; "analyzer": "my_custom_analyzer", "text": "&lt;a&gt;This is a &lt;b&gt;Text&lt;/b&gt;&lt;/a&gt;"&#125; Result: 1234567891011121314151617181920212223242526272829303132&#123; "tokens" : [ &#123; "token" : "this", "start_offset" : 3, "end_offset" : 7, "type" : "&lt;ALPHANUM&gt;", "position" : 0 &#125;, &#123; "token" : "is", "start_offset" : 8, "end_offset" : 10, "type" : "&lt;ALPHANUM&gt;", "position" : 1 &#125;, &#123; "token" : "a", "start_offset" : 11, "end_offset" : 12, "type" : "&lt;ALPHANUM&gt;", "position" : 2 &#125;, &#123; "token" : "text", "start_offset" : 16, "end_offset" : 28, "type" : "&lt;ALPHANUM&gt;", "position" : 3 &#125; ]&#125; 由上面的结果看一看出我们自定义的分词将&lt;a&gt;This is a &lt;b&gt;Text&lt;/b&gt;&lt;/a&gt; 分成了this,is,a,text分成这种结果的原因是分词使用了如下图的分词器 我们由前面的分词器的解释可了解到lowercase将元文本规范化为小写，asciifolding 类型的词元过滤器，将不在前127个ASCII字符（“基本拉丁文”Unicode块）中的字母，数字和符号Unicode字符转换为ASCII等效项（如果存在）。html strip将文本的html标签进行了过滤，standard见上面的介绍，所以最终自定义分词分成了this,is,a,text这样的结果，而上面query里面的&lt;div&gt;this is&lt;div&gt;首先html标签被过滤掉，所以不管什么标签都可以满足条件，其次this is用_analyze分析会被拆成this,is也符合分词匹配结果，如果query里面的this is变为thisis就不符合当前匹配结果了]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Kubenetets]]></title>
    <url>%2F2019%2F03%2F06%2F2019-03-09-kubenetets%2F</url>
    <content type="text"><![CDATA[集群快速搭建minikube安装12345wget https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64sudo mv minikube-linux-amd64 /usr/local/bin/minikuberm -f minikube-linux-amd64cd /usr/local/bin/sudo chmod a+x minikube kubectl安装12345wget https://storage.googleapis.com/kubernetes-release/release/v1.13.4/bin/linux/amd64/kubectlsudo mv kubectl /usr/local/bin/kubectlrm -f kubectlcd /usr/local/bin/sudo chmod a+x kubectl 使用12minikube start //创建k8s集群minikube ssh //进入虚拟机内 start过程中从从k8s.gcr.io拉取镜像失败报错信息:1234567891011121314151617181920212223Using Kubernetes version: v1.13.4[preflight] Running pre-flight checks [WARNING Service-Docker]: docker service is not enabled, please run 'systemctl enable docker.service' [WARNING Swap]: running with swap on is not supported. Please disable swap[preflight] Pulling images required for setting up a Kubernetes cluster[preflight] This might take a minute or two, depending on the speed of your internet connection[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'error execution phase preflight: [preflight] Some fatal errors occurred: [ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-apiserver:v1.13.4: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-controller-manager:v1.13.4: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-scheduler:v1.13.4: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-proxy:v1.13.4: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/pause:3.1: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/etcd:3.2.24: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1 [ERROR ImagePull]: failed to pull image k8s.gcr.io/coredns:1.2.6: output: Error response from daemon: Get https://k8s.gcr.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers), error: exit status 1[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` docker.io仓库对google的容器做了镜像，可以通过下列命令下拉取相关镜像： 1234567docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.11.4docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.11.4docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.11.4docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.11.4docker pull mirrorgooglecontainers/pause:3.1docker pull mirrorgooglecontainers/etcd-amd64:3.2.24docker pull coredns/coredns:1.2.6 版本信息需要根据实际情况进行相应的修改。通过docker tag命令来修改镜像的标签 12345678docker tag docker.io/mirrorgooglecontainers/kube-proxy-amd64:v1.11.3 k8s.gcr.io/kube-proxy-amd64:v1.11.4docker tag docker.io/mirrorgooglecontainers/kube-scheduler-amd64:v1.11.3 k8s.gcr.io/kube-scheduler-amd64:v1.11.4docker tag docker.io/mirrorgooglecontainers/kube-apiserver-amd64:v1.11.3 k8s.gcr.io/kube-apiserver-amd64:v1.11.4docker tag docker.io/mirrorgooglecontainers/kube-controller-manager-amd64:v1.11.3 k8s.gcr.io/kube-controller-manager-amd64:v1.11.4docker tag docker.io/mirrorgooglecontainers/etcd-amd64:3.2.18 k8s.gcr.io/etcd-amd64:3.2.24docker tag docker.io/mirrorgooglecontainers/pause:3.1 k8s.gcr.io/pause:3.1docker tag docker.io/coredns/coredns:1.2.6 k8s.gcr.io/coredns:1.2.6 pod创建nginx pod基本命令:123kubectl create -f &lt;podfile.yml&gt; //创建kubectl delete -f &lt;podfile.yml&gt; //删除kubectl get pods //查看pod信息 k8s 最小单位,创建pod 创建pod_nginx.yml文件,内容如下 123456789101112apiVersion: v1kind: Podmetadata: name: nginx labels: app: nginxspec: containers: - name: nginx image: nginx ports: - containerPort: 80 执行1kubectl create -f pod_nginx.yml 查看nginx pod详细信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748kubectl describe pods nginxName: nginxNamespace: defaultPriority: 0PriorityClassName: &lt;none&gt;Node: minikube/10.0.2.15Start Time: Sat, 09 Mar 2019 20:46:25 +0800Labels: app=nginxAnnotations: &lt;none&gt;Status: RunningIP: 172.17.0.4Containers: nginx: Container ID: docker://b3c9a2e399a35712373de92b619b0bb79bc5075718ec04f614e70e92ac998b16 Image: nginx Image ID: docker-pullable://nginx@sha256:98efe605f61725fd817ea69521b0eeb32bef007af0e3d0aeb6258c6e6fe7fc1a Port: 80/TCP Host Port: 0/TCP State: Running Started: Sat, 09 Mar 2019 20:47:20 +0800 Ready: True Restart Count: 0 Environment: &lt;none&gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-q8wk4 (ro)Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled TrueVolumes: default-token-q8wk4: Type: Secret (a volume populated by a Secret) SecretName: default-token-q8wk4 Optional: falseQoS Class: BestEffortNode-Selectors: &lt;none&gt;Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300sEvents: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 8m16s default-scheduler Successfully assigned default/nginx to minikube Normal Pulling 8m15s kubelet, minikube pulling image "nginx" Normal Pulled 7m21s kubelet, minikube Successfully pulled image "nginx" Normal Created 7m21s kubelet, minikube Created container Normal Started 7m21s kubelet, minikube Started container 端口映射1kubectl port-forward nginx 8080:80 打开浏览器输入127.0.0.1:8080即可看到nginx 欢迎页 Replication Controller（RC）应用托管在K8S后，K8S需要保证应用能够持续运行，这是RC的工作内容 主要功能确保pod数量：RC用来管理正常运行Pod数量，一个RC可以由一个或多个Pod组成，在RC被创建后，系统会根据定义好的副本数来创建Pod数量。在运行过程中，如果Pod数量小于定义的，就会重启停止的或重新分配Pod，反之则杀死多余的。 确保pod健康：当pod不健康，运行出错或者无法提供服务时，RC也会杀死不健康的pod，重新创建新的。 弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过RC动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取RC关联pod的整体资源使用情况，做到自动伸缩。 滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。 横向扩展yml文件实例(rc_nginx.yml) 12345678910111213141516171819apiVersion: v1kind: ReplicationController metadata: name: nginxspec: replicas: 3 selector: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 执行:1kubectl create -f rc_nginx.yml 通过ReplicationController方式可以自动化维持pods数目，以方便治理某个pod宕机不可用情况 eg:删除一个pod 删掉一个后status立马变为ContainerCreating去重新创建一个pod 扩展升级 ReplicaSet“升级版”的RC。RS也是用于保证与label selector匹配的pod数量维持在期望状态。 区别：1234561、RC只支持基于等式的selector（env=dev或environment!=qa），但RS还支持新的，基于集合的selector（version in (v1.0, v2.0)或env notin (dev, qa)），这对复杂的运维管理很方便。 2、升级方式 RS不能使用kubectlrolling-update进行升级 kubectl rolling-update专用于rc RS升级使用deployment或者kubectl replace命令 yml文件实例(rs_nginx.yml) 12345678910111213141516171819202122apiVersion: apps/v1kind: ReplicaSetmetadata: name: nginx labels: tier: frontendspec: replicas: 3 selector: matchLabels: tier: frontend template: metadata: name: nginx labels: tier: frontend spec: containers: - name: nginx image: nginx ports: - containerPort: 80 执行:1kubectl create -f rs_nginx.yml 扩展 kubectl scale rs nginx –replicas=2kubectl scale rs nginx –replicas=4 Deploymentsdeployment 是用来管理无状态应用的，面向的集群的管理，而不是面向的是一个不可变的个体 Deployment 为Pod 和 ReplicaSet 之上，提供了一个声明式定义（declarative）方法，用来替代以前的ReplicationController 来方便的管理应用。 你只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 Deployment 来 创建 ReplicaSet 或者删除已有的 Deployment 并创建一个新的来替换。也就是说Deployment是可以管理多个ReplicaSet的 典型的应用场景包括： 定义Deployment来创建Pod和ReplicaSet,使用Deployment来创建ReplicaSet。ReplicaSet在后台创建pod。检查启动状态，看它是成功还是失败。 然后，通过更新Deployment的PodTemplateSpec字段来声明Pod的新状态。这会创建一个新的ReplicaSet，Deployment会按照控制的速率将pod从旧的ReplicaSet移动到新d的ReplicaSet中。 如果当前状态不稳定，回滚到之前的Deployment revision。每次回滚都会更新Deployment的revision。 扩容Deployment以满足更高的负载。 暂停Deployment来应用PodTemplateSpec的多个修复，然后恢复上线。 根据Deployment 的状态判断上线是否hang住了。 清除旧的不必要的 ReplicaSet。 创建yml文件实例(deployment_nginx.yml) 123456789101112131415161718192021apiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.12.2 ports: - containerPort: 80 执行:1kubectl create -f deployment_nginx.yml 查看deployment信息 12kubectl get deploymentkubectl get deployment -o wide update nginx to 1.13123kubectl set image '&lt;resource&gt; &lt;name&gt;' '&lt;resource&gt;' 执行1kubectl set image deployment nginx-deployment nginx=nginx:1.13 rollout查看history1kubectl rollout history deployment nginx-deployment 回退版本1kubectl rollout undo deployment nginx-deployment expose port12kubectl expose deployment nginx-deployment --type=NodePortkubectl get svc]]></content>
      <tags>
        <tag>Kubenetets</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Swarm]]></title>
    <url>%2F2019%2F03%2F06%2F2019-03-06-docker-swarm%2F</url>
    <content type="text"><![CDATA[环境准备 环境搭建主节点：192.168.205.10从节点1：192.168.205.11从节点2：192.168.205.12 1docker swarm init --advertise-addr 192.168.205.10 复制提示的命令到其它两个容器中执行 查看node信息 service 创建和水平扩展12345678910111213141516docker service COMMANDManage servicesCommands: create Create a new service inspect Display detailed information on one or more services logs Fetch the logs of a service or task ls List services ps List the tasks of one or more services rm Remove one or more services rollback Revert changes to a service's configuration scale Scale one or multiple replicated services update Update a serviceRun 'docker service COMMAND --help' for more information on a command 1docker service create --name demo busybox /bin/sh -c "while true; do sleep 3600; done" 查看容器详细信息 123docker service ls docker service ps demo //查看service存放在哪台机器docker ps //查看当前机器下的service replicated表明可以横向扩展 1docker service scale demo=5 5/5表示5个都已经ready/共5个scale swarm 分布情况 删除swarm 1docker service rm demo 在docker swarm下部署wordpress1234567891011//创建overlay网络[vagrant@swarm-manager ~]$ docker network create -d overlay demolqem7ybsxvsqupsamhs7gwuym[vagrant@swarm-manager ~]$ docker network lsNETWORK ID NAME DRIVER SCOPE81117831f35e bridge bridge locallqem7ybsxvsq demo overlay swarmf5cf7cd988bf docker_gwbridge bridge local6fca47e6833e host host localqn8r5p813ae9 ingress overlay swarm5d8be2887f8b none null local 创建mysql service 1docker service create --name mysql --env MYSQL_ROOT_PASSWORD=root --env MYSQL_DATABASE=wordpress --network demo --mount type=volume,source=mysql-data,destination=/var/lib/mysql mysql:5.7 创建wordpress service 1docker service create --name wordpress -p 80:80 --env WORDPRESS_DB_PASSWORD=root --env WORDPRESS_DB_HOST=mysql --network demo wordpress 部署成功 此时访问集群中任意一台机器的ip都可以访问到wordpress，实际上,docker在swarm中建立了一个虚拟ip来实现通信，关于通信方式可参考routingmesh Routing Mesh的两种体现 internal:Container与Container之间访问通过overlay网络(虚拟ip) ingress: 如果服务有绑定接口，此服务可通过swarm中任意节点访问 ingress 负载均衡作用： 外部访问的负载均衡 服务端口被暴漏给各个swarm节点 内部通过ipvs进行负载均衡 docker stackdocker-compose 语法梳理ENDPOINT_MODEENDPOINT_MODE: vip | dnsrr vip 通过lvs负载均衡虚拟ip的方式（默认推荐使用）dnsrr：dns负载均衡轮询策略 LABELSlables是起到帮助信息的作用 1234567version: "3"services: web: image: web deploy: labels: com.example.description: "This label will appear on the web service" modemode: global | replicated(默认) replicated可以做横向扩展，global不可以 PLACEMENTnode.role == manager 指定部署在swarm manager节点上constraints 一些限制条件 1234567891011version: '3.3'services: db: image: postgres deploy: placement: constraints: - node.role == manager - engine.labels.operatingsystem == ubuntu 14.04 preferences: - spread: node.labels.zone REPLICAS在mode：replicated下有效replicas: 6 部署6个service 12345678910version: '3'services: worker: image: dockersamples/examplevotingapp_worker networks: - frontend - backend deploy: mode: replicated replicas: 6 RESOURCES(cpu_shares, cpu_quota, cpuset, mem_limit, memswap_limit, mem_swappiness)的一些资源设置 123456789101112version: '3'services: redis: image: redis:alpine deploy: resources: limits: cpus: '0.50' memory: 50M reservations: cpus: '0.25' memory: 20M 表示redis服务被限制使用不超过50M的内存和0.50(50%)的可用处理时间(CPU)，并保留20M的内存和0.25 CPU时间(始终可用) RESTART_POLICY12345678910version: "3"services: redis: image: redis:alpine deploy: restart_policy: condition: on-failure delay: 5s max_attempts: 3 window: 120s 表示服务停止时最大尝试次数为3,重启时间间隔是5秒，重启是否成功之前需要等待120s时间 ROLLBACK_CONFIGparallelism：最多可以同时update2个replicas，每次只能更新一个delay：每次更新之间的间隔时间，order: 更新期间的操作顺序。stop-first(旧任务在启动新任务之前停止)或start-first(新任务首先启动，正在运行的任务短暂搁置)(默认stop-first)注意:只支持v3.4或更高版本。 123456789101112version: '3.4'services: vote: image: dockersamples/examplevotingapp_vote:before depends_on: - redis deploy: replicas: 2 update_config: parallelism: 2 delay: 10s order: stop-first 详情参考compose-file 通过docker stack 部署wordpresssudo mkdir -p /usr/docker-vol/mysql/data vim docker-compose.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051version: '3'services: web: image: wordpress ports: - 8080:80 environment: WORDPRESS_DB_HOST: mysql WORDPRESS_DB_PASSWORD: root networks: - my-network depends_on: - mysql deploy: mode: replicated replicas: 3 restart_policy: condition: on-failure delay: 5s max_attempts: 3 update_config: parallelism: 1 delay: 10s mysql: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: wordpress volumes: - /usr/docker-vol/mysql/data:/var/lib/mysql networks: - my-network deploy: mode: global resources: limits: cpus: "0.2" memory: 512M placement: constraints: - node.role == managervolumes: mysql-data:networks: my-network: driver: overlay 1docker stack deploy wordpress --compose-file=docker-compose.yml docker stack services wordpress 查看service准备情况 docker stack ls 列举stack docker stack ps wordpress 查看wordpress运行情况 看到如下界面配置成功 清空环境1docker stack rm wordpress]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Volume]]></title>
    <url>%2F2019%2F03%2F04%2F2019-03-04-docker-volume%2F</url>
    <content type="text"><![CDATA[基本命令123docker volume ls // 列出所有volumedocker volume rm &lt;VOLUME...&gt; // 删除一个或多个volumedocker volume rm $(docker volume ls -qf dangling=true) //删除失效的volume: Data Volumevolume是docker数据持久化的一种方式，那么怎样使用volume呢？ Dockerfile使用 可以通过mysql官方的Dockerfile看到volume的使用方式 命令模式使用启动一台mysql; 1docker run -d --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql 查看volume: 12345678910111213141516171819pengshiliang@pengshiliang-virtual-machine:~$ docker volume lsDRIVER VOLUME NAMElocal 195d16514c70f7990f190b1557fb2131a2b8942c48ef50025b7f08fc7b082dcdpengshiliang@pengshiliang-virtual-machine:~$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES20752e526d9e mysql "docker-entrypoint.s…" 14 seconds ago Up 13 seconds 3306/tcp, 33060/tcp mysql1pengshiliang@pengshiliang-virtual-machine:~$ docker volume inspect 195d16514c70f7990f190b1557fb2131a2b8942c48ef50025b7f08fc7b082dcd[ &#123; "CreatedAt": "2019-03-04T21:41:29+08:00", "Driver": "local", "Labels": null, "Mountpoint": "/var/lib/docker/volumes/195d16514c70f7990f190b1557fb2131a2b8942c48ef50025b7f08fc7b082dcd/_data", "Name": "195d16514c70f7990f190b1557fb2131a2b8942c48ef50025b7f08fc7b082dcd", "Options": &#123;&#125;, "Scope": "local" &#125;]pengshiliang@pengshiliang-virtual-machine:~$ 可以通过inspect命令查看volume的存储路径 删掉mysql container 发现volume仍然存在，也确认了docker可以通过volume持久化存储数据 还可以通过下面的实例来证实 为了避免环境影响,删掉刚才产生的volume，重新启动一台mysql valume的名称太长了,加入一个-v参数，来给volume起个别名,然后启动mysql,并指定volume存放位置 1docker run -d -v mysql:/var/lib/mysql --name mysql1 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql 进入当前container，并创建一个数据库 然后退出，把当前的mysql1容器删掉 检查volume 再去启动一台mysql2 1docker run -d -v mysql:/var/lib/mysql --name mysql2 -e MYSQL_ALLOW_EMPTY_PASSWORD=true mysql 进入到当前容器的mysql数据库查看详情 发现刚才创建的数据库还在,也证明了volume是持久化存储的方式 bind mouting命令:1docker -run -v /home/aaa:/root/aaa 通过docker bind mouting将本地和服务器(容器)上的资源绑定，改变一方都对数据同步，从而达到直接修改本地资源，服务器上的资源自动更新 准备一个目录，创建index.html文件 可以发现，当前目录下的文件是和container内部的/usr/share/nginx/html文件是同步的]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Compose]]></title>
    <url>%2F2019%2F03%2F04%2F2019-03-05-docker-compose%2F</url>
    <content type="text"><![CDATA[安装1sudo curl -L "https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose 基本命令1234567891011121314151617181920212223242526272829303132333435docker-compose up -d nginx 构建建启动nignx容器docker-compose exec nginx bash 登录到nginx容器中docker-compose down 删除所有nginx容器,镜像docker-compose ps 显示所有容器docker-compose restart nginx 重新启动nginx容器docker-compose run --no-deps --rm php-fpm php -v 在php-fpm中不启动关联容器，并容器执行php -v 执行完成后删除容器docker-compose build nginx 构建镜像 。 docker-compose build --no-cache nginx 不带缓存的构建。docker-compose logs nginx 查看nginx的日志 docker-compose logs -f nginx 查看nginx的实时日志 docker-compose config -q 验证（docker-compose.yml）文件配置，当配置正确时，不输出任何内容，当文件配置错误，输出错误信息。 docker-compose events --json nginx 以json的形式输出nginx的docker日志docker-compose pause nginx 暂停nignx容器docker-compose unpause nginx 恢复ningx容器docker-compose rm nginx 删除容器（删除前必须关闭容器）docker-compose stop nginx 停止nignx容器docker-compose start nginx 启动nignx容器]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker network]]></title>
    <url>%2F2019%2F03%2F03%2F2019-03-03-docker_network%2F</url>
    <content type="text"><![CDATA[环境说明两台vagrant 创建的 docker 虚拟机，虚拟机配置信息 1234567891011121314boxes = [ &#123; :name =&gt; "docker-node1", :eth1 =&gt; "192.168.205.10", :mem =&gt; "1024", :cpu =&gt; "1" &#125;, &#123; :name =&gt; "docker-node2", :eth1 =&gt; "192.168.205.11", :mem =&gt; "1024", :cpu =&gt; "1" &#125;] 启动两个 docker 容器 12sudo docker run -d --name test busybox /bin/sh -c "while true; do sleep 3600; done"sudo docker run -d --name test1 busybox /bin/sh -c "while true; do sleep 3600; done" 此时发现da678d729936的ip地址为172.17.0.3，cf393747710e的ip地址为172.17.0.2 执行exec da678d729936 ping 172.17.0.2```试试可不可以ping通cf393747710e的ip1234567891011121314![avatar](/img/in-post/2019-03-03/9.png)发现可以ping通，证明docker两个container之间的ip namespace是隔离开的，但是两个ip之间是可以ping通的，那么具体原理是什么呢？我们可以通过下面的实验模拟来理解一下## network namespace### 创建net namespace```bashsudo ip netns add &lt;name&gt; // 添加一个namespacesudo ip netns listsudo ip netns exec test ip a // 查看test ip info 创建两个namespace 12sudo ip netns add testsudo ip netns add test1 执行ip netns exec test ip link``` 查看ip信息12345![avatar](/img/in-post/2019-03-03/2.png)接口启动命令```bashsudo ip netns exec test ip link set dev lo up 此时lo网卡是down状态 执行ip netns exec test ip link set dev lo up``` 将lo 开启1234567![avatar](/img/in-post/2019-03-03/3.png)出现unknown原因是因为lo是单个接口，只有做link后的成对接口可以up### link namespace添加一对veth接口，执行```sudo ip link add veth-test type veth peer name veth-test1 添加 veth-test 到 test namespace 中 1sudo ip link set veth-test netns test 分别查看本地和test ip link 信息 发现本地的veth-test接口被添加到了test中，同理，添加test1 1sudo ip link set veth-test1 netns test1 ip link执行12sudo ip netns exec test ip addr add 192.168.1.1/24 dev veth-testsudo ip netns exec test1 ip addr add 192.168.1.2/24 dev veth-test1 然后启动接口，参照上面启动lo接口的命令 12sudo ip netns exec test ip link set dev veth-test upsudo ip netns exec test1 ip link set dev veth-test1 up 查看test和test1 ip 状态 发现两个接口状态都是state up，并且test和test1均已分配192.168.1.1和192.168.1.2表示接口已经启动成功,测试相互ping一下 docker networkbridge把之前docker container 中的两个容器stop和rm掉，重新启动一个test容器 1sudo docker run -d --name test busybox /bin/sh -c "while true; do sleep 3600; done" 1234// 列举出docker的网络sudo docker network ls// 查看某个docker network id 的具体信息sudo docker network inspect &lt;networkid&gt; eg: 查看bridge网络的详细信息 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[vagrant@docker-node1 labs]$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8378c2ff8198 busybox "/bin/sh -c 'while t…" 3 seconds ago Up 3 seconds test[vagrant@docker-node1 labs]$ docker network lsNETWORK ID NAME DRIVER SCOPE1fb7b167deb2 bridge bridge local2d13173ae2bf host host local6d2c375cd6cd none null local[vagrant@docker-node1 labs]$ docker network inspect 1fb7b167deb2[ &#123; "Name": "bridge", "Id": "1fb7b167deb233148d61b85c03bb68d9b8e3cbb124b60deb7be8acf88abdac21", "Created": "2019-03-03T02:04:36.334606846Z", "Scope": "local", "Driver": "bridge", "EnableIPv6": false, "IPAM": &#123; "Driver": "default", "Options": null, "Config": [ &#123; "Subnet": "172.17.0.0/16", "Gateway": "172.17.0.1" &#125; ] &#125;, "Internal": false, "Attachable": false, "Ingress": false, "ConfigFrom": &#123; "Network": "" &#125;, "ConfigOnly": false, "Containers": &#123; "8378c2ff8198bbac6647463286408de11a7814c7882e99232404ecab0e1517ad": &#123; "Name": "test", "EndpointID": "f976820b8133d11cd37602ece5f762106aba2f3735420272ad0ed3bd8b1dc58a", "MacAddress": "02:42:ac:11:00:02", "IPv4Address": "172.17.0.2/16", "IPv6Address": "" &#125; &#125;, "Options": &#123; "com.docker.network.bridge.default_bridge": "true", "com.docker.network.bridge.enable_icc": "true", "com.docker.network.bridge.enable_ip_masquerade": "true", "com.docker.network.bridge.host_binding_ipv4": "0.0.0.0", "com.docker.network.bridge.name": "docker0", "com.docker.network.driver.mtu": "1500" &#125;, "Labels": &#123;&#125; &#125;][vagrant@docker-node1 labs]$ 通过上图可以看出本地的 vethd347bdc@if11 和 容器内的 eth0@if12 是一对接口这一对veth peer 连接到了docker0的网络上面，可以通过下面的演示验证 1sudo yum install bridge-utils brctl命令说明 1234567891011121314151617181920[vagrant@docker-node1 labs]$ brctlUsage: brctl [commands]commands: addbr &lt;bridge&gt; add bridge delbr &lt;bridge&gt; delete bridge addif &lt;bridge&gt; &lt;device&gt; add interface to bridge delif &lt;bridge&gt; &lt;device&gt; delete interface from bridge hairpin &lt;bridge&gt; &lt;port&gt; &#123;on|off&#125; turn hairpin on/off setageing &lt;bridge&gt; &lt;time&gt; set ageing time setbridgeprio &lt;bridge&gt; &lt;prio&gt; set bridge priority setfd &lt;bridge&gt; &lt;time&gt; set bridge forward delay sethello &lt;bridge&gt; &lt;time&gt; set hello time setmaxage &lt;bridge&gt; &lt;time&gt; set max message age setpathcost &lt;bridge&gt; &lt;port&gt; &lt;cost&gt; set path cost setportprio &lt;bridge&gt; &lt;port&gt; &lt;prio&gt; set port priority show [ &lt;bridge&gt; ] show a list of bridges showmacs &lt;bridge&gt; show a list of mac addrs showstp &lt;bridge&gt; show bridge stp info stp &lt;bridge&gt; &#123;on|off&#125; turn stp on/off[vagrant@docker-node1 labs]$ 启动test2容器 1sudo docker run -d --name test1 busybox /bin/sh -c "while true; do sleep 3600; done" 通过show```命令可以看到如下结果：123456```bash[vagrant@docker-node1 labs]$ brctl showbridge name bridge id STP enabled interfacesdocker0 8000.02425db75bb1 no veth4de57f6 vethd347bdc 可以看到docker0和两个veth peer接口的关系 host 和 nonenone1sudo docker run -d --name test4 --network none busybox /bin/sh -c "while true; do sleep 3600; done" 这种方式创建的容器没有ip地址，只能通过exec的方式进入 host1sudo docker run -d --name test5 --network host busybox /bin/sh -c "while true; do sleep 3600; done" 进入test5容器查看ip 1234567891011121314[vagrant@docker-node1 ~]$ docker exec test5 ip a...37: veth9cb9ecd@if36: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue master docker0 link/ether ce:61:3e:72:57:f9 brd ff:ff:ff:ff:ff:ff inet6 fe80::cc61:3eff:fe72:57f9/64 scope link valid_lft forever preferred_lft forever...[vagrant@docker-node1 ~]$ ip a...37: veth9cb9ecd@if36: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP link/ether ce:61:3e:72:57:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 4 inet6 fe80::cc61:3eff:fe72:57f9/64 scope link valid_lft forever preferred_lft forever... 我们发现这种方式的docker container 共享了主机里面的ip namespace 多机器通信 Mutil-host networking with etcdsetup etcd cluster在docker-node1上 12345678910vagrant@docker-node1:~$ wget https://github.com/coreos/etcd/releases/download/v3.0.12/etcd-v3.0.12-linux-amd64.tar.gzvagrant@docker-node1:~$ tar zxvf etcd-v3.0.12-linux-amd64.tar.gzvagrant@docker-node1:~$ cd etcd-v3.0.12-linux-amd64vagrant@docker-node1:~$ nohup ./etcd --name docker-node1 --initial-advertise-peer-urls http://192.168.205.10:2380 \--listen-peer-urls http://192.168.205.10:2380 \--listen-client-urls http://192.168.205.10:2379,http://127.0.0.1:2379 \--advertise-client-urls http://192.168.205.10:2379 \--initial-cluster-token etcd-cluster \--initial-cluster docker-node1=http://192.168.205.10:2380,docker-node2=http://192.168.205.11:2380 \--initial-cluster-state new&amp; 在docker-node2上 12345678910vagrant@docker-node2:~$ wget https://github.com/coreos/etcd/releases/download/v3.0.12/etcd-v3.0.12-linux-amd64.tar.gzvagrant@docker-node2:~$ tar zxvf etcd-v3.0.12-linux-amd64.tar.gzvagrant@docker-node2:~$ cd etcd-v3.0.12-linux-amd64/vagrant@docker-node2:~$ nohup ./etcd --name docker-node2 --initial-advertise-peer-urls http://192.168.205.11:2380 \--listen-peer-urls http://192.168.205.11:2380 \--listen-client-urls http://192.168.205.11:2379,http://127.0.0.1:2379 \--advertise-client-urls http://192.168.205.11:2379 \--initial-cluster-token etcd-cluster \--initial-cluster docker-node1=http://192.168.205.10:2380,docker-node2=http://192.168.205.11:2380 \--initial-cluster-state new&amp; 检查cluster状态 1234vagrant@docker-node2:~/etcd-v3.0.12-linux-amd64$ ./etcdctl cluster-healthmember 21eca106efe4caee is healthy: got healthy result from http://192.168.205.10:2379member 8614974c83d1cc6d is healthy: got healthy result from http://192.168.205.11:2379cluster is healthy 重启docker服务在docker-node1上 12$ sudo service docker stop$ sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.205.10:2379 --cluster-advertise=192.168.205.10:2375&amp; 在docker-node2上 12$ sudo service docker stop$ sudo /usr/bin/dockerd -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock --cluster-store=etcd://192.168.205.11:2379 --cluster-advertise=192.168.205.11:2375&amp; 创建overlay network在docker-node1上创建一个demo的overlay network 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[vagrant@docker-node1 etcd-v3.0.12-linux-amd64]$ sudo docker network lsNETWORK ID NAME DRIVER SCOPE22c070951371 bridge bridge local2d13173ae2bf host host localc144a2167891 my-bridge bridge local6d2c375cd6cd none null local[vagrant@docker-node1 etcd-v3.0.12-linux-amd64]$ sudo docker network create -d overlay demo6f58ba8913c3e0df5ac9086f79e87cc62e57ac723d26dcb05edb7635f19103c8[vagrant@docker-node1 etcd-v3.0.12-linux-amd64]$ sudo docker network lsNETWORK ID NAME DRIVER SCOPE22c070951371 bridge bridge local6f58ba8913c3 demo overlay global2d13173ae2bf host host localc144a2167891 my-bridge bridge local6d2c375cd6cd none null local[vagrant@docker-node1 etcd-v3.0.12-linux-amd64]$ sudo docker network inspect demo[ &#123; &quot;Name&quot;: &quot;demo&quot;, &quot;Id&quot;: &quot;6f58ba8913c3e0df5ac9086f79e87cc62e57ac723d26dcb05edb7635f19103c8&quot;, &quot;Created&quot;: &quot;2019-03-03T13:03:20.535696601Z&quot;, &quot;Scope&quot;: &quot;global&quot;, &quot;Driver&quot;: &quot;overlay&quot;, &quot;EnableIPv6&quot;: false, &quot;IPAM&quot;: &#123; &quot;Driver&quot;: &quot;default&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Config&quot;: [ &#123; &quot;Subnet&quot;: &quot;10.0.0.0/24&quot;, &quot;Gateway&quot;: &quot;10.0.0.1&quot; &#125; ] &#125;, &quot;Internal&quot;: false, &quot;Attachable&quot;: false, &quot;Ingress&quot;: false, &quot;ConfigFrom&quot;: &#123; &quot;Network&quot;: &quot;&quot; &#125;, &quot;ConfigOnly&quot;: false, &quot;Containers&quot;: &#123;&#125;, &quot;Options&quot;: &#123;&#125;, &quot;Labels&quot;: &#123;&#125; &#125;] 我们会看到在node2上，这个demo的overlay network会被同步创建 123456vagrant@docker-node2:~$ sudo docker network lsNETWORK ID NAME DRIVER SCOPEc9947d4c3669 bridge bridge local3d430f3338a2 demo overlay globalfa5168034de1 host host localc2ca34abec2a none null local 通过查看etcd的key-value, 我们获取到，这个demo的network是通过etcd从node1同步到node2的 1234567891011[vagrant@docker-node2 etcd-v3.0.12-linux-amd64]$ ./etcdctl ls /docker/docker/network/docker/nodes[vagrant@docker-node2 etcd-v3.0.12-linux-amd64]$ ./etcdctl ls /docker/nodes/docker/nodes/192.168.205.10:2375/docker/nodes/192.168.205.11:2375[vagrant@docker-node2 etcd-v3.0.12-linux-amd64]$ ./etcdctl ls /docker/network/v1.0/network/docker/network/v1.0/network/6f58ba8913c3e0df5ac9086f79e87cc62e57ac723d26dcb05edb7635f19103c8[vagrant@docker-node2 etcd-v3.0.12-linux-amd64]$ ./etcdctl get /docker/network/v1.0/network/6f58ba8913c3e0df5ac9086f79e87cc62e57ac723d26dcb05edb7635f19103c8&#123;&quot;addrSpace&quot;:&quot;GlobalDefault&quot;,&quot;attachable&quot;:false,&quot;configFrom&quot;:&quot;&quot;,&quot;configOnly&quot;:false,&quot;created&quot;:&quot;2019-03-03T13:03:20.535696601Z&quot;,&quot;enableIPv6&quot;:false,&quot;generic&quot;:&#123;&quot;com.docker.network.enable_ipv6&quot;:false,&quot;com.docker.network.generic&quot;:&#123;&#125;&#125;,&quot;id&quot;:&quot;6f58ba8913c3e0df5ac9086f79e87cc62e57ac723d26dcb05edb7635f19103c8&quot;,&quot;inDelete&quot;:false,&quot;ingress&quot;:false,&quot;internal&quot;:false,&quot;ipamOptions&quot;:&#123;&#125;,&quot;ipamType&quot;:&quot;default&quot;,&quot;ipamV4Config&quot;:&quot;[&#123;\&quot;PreferredPool\&quot;:\&quot;\&quot;,\&quot;SubPool\&quot;:\&quot;\&quot;,\&quot;Gateway\&quot;:\&quot;\&quot;,\&quot;AuxAddresses\&quot;:null&#125;]&quot;,&quot;ipamV4Info&quot;:&quot;[&#123;\&quot;IPAMData\&quot;:\&quot;&#123;\\\&quot;AddressSpace\\\&quot;:\\\&quot;GlobalDefault\\\&quot;,\\\&quot;Gateway\\\&quot;:\\\&quot;10.0.0.1/24\\\&quot;,\\\&quot;Pool\\\&quot;:\\\&quot;10.0.0.0/24\\\&quot;&#125;\&quot;,\&quot;PoolID\&quot;:\&quot;GlobalDefault/10.0.0.0/24\&quot;&#125;]&quot;,&quot;labels&quot;:&#123;&#125;,&quot;loadBalancerIP&quot;:&quot;&quot;,&quot;loadBalancerMode&quot;:&quot;NAT&quot;,&quot;name&quot;:&quot;demo&quot;,&quot;networkType&quot;:&quot;overlay&quot;,&quot;persist&quot;:true,&quot;postIPv6&quot;:false,&quot;scope&quot;:&quot;global&quot;&#125;[vagrant@docker-node2 etcd-v3.0.12-linux-amd64]$ 在node1中执行 1sudo docker run -d --name test1 --net demo busybox /bin/sh -c "while true; do sleep 3600; done" 在node2中执行 1sudo docker run -d --name test2 --net demo busybox /bin/sh -c "while true; do sleep 3600; done" 分别查看test1,test2 ip 12345678910111213[vagrant@docker-node1 etcd-v3.0.12-linux-amd64]$ docker exec test1 ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever19: eth0@if20: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1450 qdisc noqueue link/ether 02:42:0a:00:00:02 brd ff:ff:ff:ff:ff:ff inet 10.0.0.2/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever21: eth1@if22: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue link/ether 02:42:ac:13:00:02 brd ff:ff:ff:ff:ff:ff inet 172.19.0.2/16 brd 172.19.255.255 scope global eth1 valid_lft forever preferred_lft forever 12345678910111213docker exec test2 ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever7: eth0@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1450 qdisc noqueue link/ether 02:42:0a:00:00:03 brd ff:ff:ff:ff:ff:ff inet 10.0.0.3/24 brd 10.0.0.255 scope global eth0 valid_lft forever preferred_lft forever10: eth1@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff inet 172.18.0.2/16 brd 172.18.255.255 scope global eth1 valid_lft forever preferred_lft forever 查看是否能ping通 123456789101112[vagrant@docker-node2 etcd-v3.0.12-linux-amd64]$ docker exec test2 ping 10.0.0.2PING 10.0.0.2 (10.0.0.2): 56 data bytes64 bytes from 10.0.0.2: seq=0 ttl=64 time=9.354 ms64 bytes from 10.0.0.2: seq=1 ttl=64 time=0.789 ms64 bytes from 10.0.0.2: seq=2 ttl=64 time=1.062 ms^C[vagrant@docker-node2 etcd-v3.0.12-linux-amd64]$ docker exec test2 ping test1PING test1 (10.0.0.2): 56 data bytes64 bytes from 10.0.0.2: seq=0 ttl=64 time=0.724 ms64 bytes from 10.0.0.2: seq=1 ttl=64 time=0.590 msç64 bytes from 10.0.0.2: seq=2 ttl=64 time=0.789 ms64 bytes from 10.0.0.2: seq=3 ttl=64 time=0.651 ms]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Docker Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker network port]]></title>
    <url>%2F2019%2F03%2F03%2F2019-03-03-docker-port%2F</url>
    <content type="text"><![CDATA[端口映射1docker run --name web -d nginx 由上图可以看到我们在虚拟机内部访问container的ip的方式可以访问到nginx欢迎页，但是访问本地地址映射不到,可以通过端口映射来解决这个问题 删除刚才的nginx container,重新启动 1234docker stop webdocker rm webdocker run --name web -d -p 80:80 nginxdocker ps 映射成功 我的vagrant ip 映射配置 映射流程 图中的192.168.205.10:80为我本机的ip私有地址，外网不能访问，如果我们是在一个云主机上创建的web服务，云主机就可以分配一个public的ip就可以作为外网的出口ip来提供服务]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Docker Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker network link]]></title>
    <url>%2F2019%2F03%2F03%2F2019-03-03-docker-link%2F</url>
    <content type="text"><![CDATA[docker linkdocker link由于docker container 之中的 ip在为创建之前是未知的，不利于服务与服务之间的配置连接，所以docker 提供了一种办法来解决这个问题，可以通过 docker name 之间的link来解决 创建test2并link到test1 1docker run -d --name test2 --link test1 busybox /bin/sh -c "while true; do sleep 3600; done" 进入到test2容器 12docker exec -it test2 /bin/shping test1 这种方式的优点是：假如test1有一个数据库，我们可以在test2容器中通过-u -P -h test1```来访问了123456789&gt; 由于是test2 去link test1 所以，在test1容器中，ping test2是不可用的## network 创建删除掉test2容器并重新创建test2```bashdocker run -d --name test2 busybox /bin/sh -c &quot;while true; do sleep 3600; done&quot; 创建bridge12docker network create -d bridge my-bridgedocker network ls 创建test3并指定network到my-bridge 如果不指定network默认连接是docker0 1docker run -d --name test3 --network my-bridge busybox /bin/sh -c "while true; do sleep 3600; done" 查看test3 container network信息 1docker network inspect &lt;my-bridge id&gt; bridge连接1docker network connect my-bridge test2 12docker network inspect bridgedocker network inspect my-bridge 我们可以看到bridge和my-bridge的container中都包含了test2 进入到test2容器中1docker exec -it test2 /bin/sh 可以发现在test2容器中可以ping通test3但是不能ping test1, 实际上docker在用户自己创建的bridge中做了一层link，所以test2和test3容器可以相互ping 通对方 把test1也加入到my-bridge中1docker network connect my-bridge test1 此时test1也可以ping通了]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Docker Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vagrant基本命令]]></title>
    <url>%2F2019%2F03%2F02%2F2019-03-02-vagrant%2F</url>
    <content type="text"><![CDATA[vagrant 使用init centoscentos7 box 下载地址centos7 添加vagrant box到box list 1vagrant box add centos7 Vagrant-CentOS-7.box 初始化一个虚拟机使用刚才添加的vagrant box 123mkdir centoscd centosvim Vagrantfile 添加下面内容到Vagrantfile中1234567891011121314151617181920212223242526272829303132333435363738394041424344# -*- mode: ruby -*-# vi: set ft=ruby :Vagrant.require_version "&gt;= 1.6.0"boxes = [ &#123; :name =&gt; "docker-node1", :eth1 =&gt; "192.168.205.10", :mem =&gt; "1024", :cpu =&gt; "1" &#125;, &#123; :name =&gt; "docker-node2", :eth1 =&gt; "192.168.205.11", :mem =&gt; "1024", :cpu =&gt; "1" &#125;]Vagrant.configure(2) do |config| config.vm.box = "centos7" boxes.each do |opts| config.vm.define opts[:name] do |config| config.vm.hostname = opts[:name] config.vm.provider "vmware_fusion" do |v| v.vmx["memsize"] = opts[:mem] v.vmx["numvcpus"] = opts[:cpu] end config.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--memory", opts[:mem]] v.customize ["modifyvm", :id, "--cpus", opts[:cpu]] end config.vm.network :private_network, ip: opts[:eth1] end end config.vm.provision "shell", privileged: true, path: "./setup.sh"end install docker的setup.sh文件 在当前目录创建setup.sh文件并添加如下内容 123456789101112131415#/bin/sh# install some toolssudo yum install -y git vim gcc glibc-static telnet bridge-utils# install dockercurl -fsSL get.docker.com -o get-docker.shsh get-docker.sh# start docker servicesudo groupadd dockersudo usermod -aG docker vagrantsudo systemctl start dockerrm -rf get-docker.sh 启动安装 1vagrant up vagrant 报unknown filesystem type ‘vboxsf’ 解决方案12vagrant plugin install vagrant-vbguestvagrant destroy &amp;&amp; vagrant up init ubuntu使用清华源 ubuntu18的box，终端运行如下命令 123vagrant box add \https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/bionic/current/bionic-server-cloudimg-amd64-vagrant.box \--name ubuntu/bionic Vagrantfile这样写：123...config.vm.box = "ubuntu/bionic"... 接着就是up && vagrant ssh```了1234567## 基本命令### 列出所有Box```bashvagrant box list 添加一个Box1vagrant box add [options] &lt;name, url, or path 可以从https://app.vagrantup.com/boxes/search下载各种Vagrant映像文件1vagrant box add ubuntu/trusty64 通过指定的URL添加远程box1vagrant box add https://atlas.hashicorp.com/ubuntu/boxes/trusty64 添加一个本地box1vagrant box add &#123;box_name&#125; &#123;file_path&#125; 初始化一个新VM1vagrant init ubuntu/trustry64 此命令会在当前目录创建一个名为Vagrantfile的配置文件，内容大致如下： 123Vagrant.configure("2") do |config| config.vm.box = "ubuntu/trusty64"end 初始化一个新VM1vagrant up 启用SSH登陆VM1vagrant ssh &lt;node_name&gt; 如果需要从虚拟机中退出，直接在虚拟机中的命令行输入exit命令即可 查看VM当前的状态进入Vagrantfile配置文件所在的目录，执行以下命令: 1vagrant status 关闭VM1vagrant halt 销毁VM1vagrant destory [name|id]]]></content>
      <tags>
        <tag>Vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dockerfile 语法梳理]]></title>
    <url>%2F2019%2F03%2F02%2F2019-03-02-dockerfile%2F</url>
    <content type="text"><![CDATA[Dockerfile语法梳理FROMfrom 后面接base image eg:123FROM scratchFROM centosFROM ubuntu 尽量使用官方的image 作为base image LABEL123LABEL maintainer="username@gmail.com" LABEL version="1.0" LABEL description="this is description" MetaData 不可少 RUN执行命令并创建新的IMAGE LAYER 为了美观，复杂的RUN用反斜杠换行，避免无用分层，合并多条命令成一行。 最佳实践12RUN yum update &amp;&amp; yum install -y vim \python-dev 123RUN apt-get update &amp;&amp; apt-get install -y perl \pwgen --no-install-recommends &amp;&amp; rm -rf \/var/lib/apt/lists/* #清理cache 1RUN /bin/bash -c 'source $HOME/.bashrc;echo #HOME' WORKDIR123WORKDIR test # 如果没有会自动创建test文件夹WORKDIR demoRUN pwd # 打印/test/demo 尽量使用WORKDIR,不要使用RUN cd,尽量使用绝对路径 ADD and COPY123456ADD hello /ADD test.tar.gz / # 添加到根目录并解压缩WORKDIR /rootADD hello test / # /root/test/helloWORKDIR /rootCOPY hello test / 大部分情况COPY优于，ADD有额外的解压功能，添加远程文件或目录用curl或wget ENV123ENV MYSQL_VERSION 5.6 #常量RUN apt-get install -y mysql-server= "$&#123;MYSQL_VERSION&#125;" \&amp;&amp; rm -rf /var/lib/apt/lists/* CMD &amp; ENTRYPOINTCMD:设置容器启动后默认执行的命令和参数如果docker run指定了其它的命令，则忽略CMD命令定义多个CMD,只有最后一个会执行 12docker run &lt;image&gt;docker run -it &lt;image&gt; /bin/bash //此命令会忽略CMD中的命令 ENTRYPOINT:设置容器启动时运行的命令让容器已应用程序或者服务的方式执行不会被忽略，一定会执行 SHELL &amp; EXECSHELL: 123RUN apt-get install -y vimCMD echo "hello docker"ENTRYPOINT echo "hello docker" EXEC: 123RUN ["apt-get", "install", "y", "vim"]CMD ["/bin/echo", "hello docker"]ENTRYPOINT ["/bin/echo", "hello docker"] EXEC方式需要指明运行环境，eg: 123FROM centosENV name wordENTRYPOINT ["/bin/bash", "c", "echo hello $name"] 更多详见扩展阅读 Dockerfile实战123mkdir flask-hello-wordcd flask-hello-wordvim app.py app.py内容 1234567from flask import Flaskapp = Flask(__name__)@app.route('/')def hello(): return "hello docker"if __name__ == '__main__': app.run(host="0.0.0.0", port=5000) 编写Dockerfile 1234567FROM python:2.7LABEL maintainer="peng.shiliang&lt;1390509500@qq.com&gt;"RUN pip install flaskCOPY app.py /app/ # app后面必须接/，否则会当作文件WORKDIR /appEXPOSE 5000 # 端口映射,保证远程能够访问CMD ["python", "app.py"] 执行12docker build -t pengshiliang/flask-hello-word .docker push pengshiliang/flask-hello-word:latest 运行flask-hello-word123docker run -d --name=demo pengshiliang/flask-hello-word //--name 便于docker container 操作docker exec -it demo ip a //查看docker容器ipcurl &lt;demo ip&gt; //输出hello docker]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Dockerfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门]]></title>
    <url>%2F2019%2F03%2F02%2F2019-03-02-docker%2F</url>
    <content type="text"><![CDATA[赋予docker权限12345vagrant@ubuntu-bionic:~$ sudo groupadd dockergroupadd: group 'docker' already existsvagrant@ubuntu-bionic:~$ sudo gpasswd -a vagrant dockerAdding user vagrant to group dockervagrant@ubuntu-bionic:~$ sudo service docker restart 退出vagrant在重新进入 docker基本命令123456789101112// 列举所有镜像docker image ls// 查看image build 历史docker history &lt;image id&gt;// 运行一个imagedocker run &lt;image id&gt;// 列举所有正在运行的容器docker container ls// 列举所有的容器docker container ls -a// 交互式运行运行（常驻运行）docker run -it &lt;image&gt; docker image 命令12docker images (docker image ls缩写)docker rmi &lt;image id&gt; (docker image rm &lt;image id&gt;缩写)//移除一个镜像 docker container命令123456docker ps -a (docker container ls -a缩写)docker rm &lt;image id&gt; (docker container rm &lt;image id&gt;缩写) //删除一个容器docker ps -aq //列举所有容器iddocker ps -f "status=exited" -q //列举所有已退出的容器docker rm $(docker ps -aq)docker rm $(docker ps -f "status=exited" -q) build一个hello word image生成hello-word程序123mkdir hello-wordcd hello-wordvim hello.c hello.c内容12345#include&lt;stdio.h&gt;int main()&#123; printf("hello word\n");&#125; 123sudo apt-get install gccsudo apt-get install build-essentialgcc -static hello.c -o hello 编写Dockerfile执行Dockerfile```12345```dockerfileFROM scratchADD hello /CMD ["/hello"] build命令1docker build -t &lt;tag&gt; &lt;dir&gt; eg:1docker build -t pengshiliang/hello-word . 1docker run pengshiliang/hello-word 出现hello word 即为正常build 发布1docker login 1docker push pengshiliang/hello-word:latest Container 通过image创建 在Image layer之上建立一个Cotainer layer 类面向对象：类和实例 image复制存储和分发，container负责运行app]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dva快速入门]]></title>
    <url>%2F2019%2F02%2F24%2F2019-02-03-dva-quick-start%2F</url>
    <content type="text"><![CDATA[安装初始化项目123npm install -g dva-cli# 或yarn global add dva-cli 12345dva -vdva-cli version 0.10.0dva version 2.4.1roadhog version 2.4.9@local 12dva new dva-quickstartyarn install 目录说明 src文件夹内容：1234567891011121314151617src/├── assets│ └── yay.jpg├── components│ └── Example.js├── index.css├── index.js├── models│ └── example.js├── router.js├── routes│ ├── IndexPage.css│ └── IndexPage.js├── services│ └── example.js└── utils └── request.js 入口文件index.js默认内容harmony1234567891011121314151617import dva from 'dva';import './index.css';// 1. Initializeconst app = dva();// 2. Plugins// app.use(&#123;&#125;);// 3. Model// app.model(require('./models/example').default);// 4. Routerapp.router(require('./router').default);// 5. Startapp.start('#root'); 路由文件默认内容：harmony123456789101112131415import React from 'react';import &#123; Router, Route, Switch &#125; from 'dva/router';import IndexPage from './routes/IndexPage';function RouterConfig(&#123; history &#125;) &#123; return ( &lt;Router history=&#123;history&#125;&gt; &lt;Switch&gt; &lt;Route path="/" exact component=&#123;IndexPage&#125; /&gt; &lt;/Switch&gt; &lt;/Router&gt; );&#125;export default RouterConfig; 执行yarn start 即可看到页面效果 计数器项目Router切换 初始化项目的路由默认为HashRouter，路由链接不太友好更换为HashRouter替换index.js文件内容harmony1234567891011121314151617181920import dva from 'dva';import &#123; createBrowserHistory as createHistory &#125; from 'history';import './index.css';// 1. Initializeconst app = dva(&#123; history: createHistory()&#125;);// 2. Plugins// app.use(&#123;&#125;);// 3. Model// app.model(require('./models/example').default);// 4. Routerapp.router(require('./router').default);// 5. Startapp.start('#root'); 再次访问http://localhost:8000,路由正常显示 编写Counter组件新建 src/components/Counter.js harmony1234567891011import React from 'react'const Counter = (&#123;count&#125;) =&gt; &#123; return ( &lt;div&gt; &lt;h1&gt;1&lt;/h1&gt; &lt;button&gt;+&lt;/button&gt; &lt;/div&gt; );&#125;;export default Counter 新建 src/routes/CounterPage.js harmony12345678910111213import React from 'react'import Counter from '../components/Counter'export const CounterPage = (props) =&gt; &#123; return ( &lt;div&gt; &lt;p&gt;counter&lt;/p&gt; &lt;Counter/&gt; &lt;/div&gt; )&#125;;export default CounterPage 配置路由在src/router.js中配置路由harmony123import CounterPage from './routes/CounterPage';&lt;Route path="/counter" exact component=&#123;CounterPage&#125; /&gt; 页面效果 定义model新建 src/models/counter.js, copy models下面的Example.js内容到counter.js中，然后修改state和namespace内容 harmony1234567891011121314151617181920212223242526export default &#123; namespace: 'counter', state: &#123; count: 2 &#125;, subscriptions: &#123; setup(&#123; dispatch, history &#125;) &#123; // eslint-disable-line &#125;, &#125;, effects: &#123; *fetch(&#123; payload &#125;, &#123; call, put &#125;) &#123; // eslint-disable-line yield put(&#123; type: 'save' &#125;); &#125;, &#125;, reducers: &#123; save(state, action) &#123; return &#123; ...state, ...action.payload &#125;; &#125;, &#125;,&#125;; dva中namespace作用类似于redux项目中combineReducers中的key，用来使各个组件中的state划分更清晰 引入到入口文件index.js文件中harmony1app.model(require('./models/counter').default); model中的API介绍:参照Dva API介绍可了解到: namespacemodel 的命名空间，同时也是他在全局 state 上的属性，只能用字符串，不支持通过 . 的方式创建多层命名空间。 state初始值，优先级低于传给 dva() 的 opts.initialState。 比如：harmony1234567const app = dva(&#123; initialState: &#123; count: 1 &#125;,&#125;);app.model(&#123; namespace: 'count', state: 0,&#125;); 此时，在 app.start() 后 state.count 为 1 。 reducers以 key/value 格式定义 reducer。用于处理同步操作，唯一可以修改 state 的地方。由 action 触发。格式为 (state, action) =&gt; newState 或 [(state, action) =&gt; newState, enhancer]。详见:https://github.com/dvajs/dva/blob/master/packages/dva-core/test/reducers.test.js effects以 key/value 格式定义 effect。用于处理异步操作和业务逻辑，不直接修改 state。由 action 触发，可以触发 action，可以和服务器交互，可以获取全局 state 的数据等等。格式为(action, effects) =&gt; void或[(action, effects) =&gt; void, { type }].type 类型有： takeEvery takeLatest throttle watcher 详见：https://github.com/dvajs/dva/blob/master/packages/dva-core/test/effects.test.js subscriptions以 key/value 格式定义 subscription。subscription 是订阅，用于订阅一个数据源，然后根据需要 dispatch 相应的 action。在 app.start() 时被执行，数据源可以是当前的时间、服务器的 websocket 连接、keyboard 输入、geolocation 变化、history 路由变化等等。格式为({ dispatch, history }, done) =&gt; unlistenFunction。 注意：如果要使用 app.unmodel()，subscription 必须返回 unlisten 方法，用于取消数据订阅。 打开redux控制台: 可看到state.counter.count counter对应model的namespace,count对应state对象中的count connect起来修改src/components/Counter.js的内容 harmony1234567891011121314151617import React from 'react'import &#123;connect&#125; from "dva";const Counter = (props) =&gt; &#123; return ( &lt;div&gt; &lt;h1&gt;&#123;props.counter.count&#125;&lt;/h1&gt; &lt;button&gt;+&lt;/button&gt; &lt;/div&gt; );&#125;;const mapStateToProps = (state) =&gt; &#123; // 取出models下的命名空间counter return &#123; counter: state.counter &#125;&#125;;export default connect(mapStateToProps)(Counter) 这一步做的主要是把models/counter和当前组件通过mapStateToProps连接然后在无状态Counter组件中通过props来接收 可以看到如果在models中的state定义的对象如果结构很长的话,Counter组件中的props链式对象会写的很长，当然我们可以通过es6中的对象析构来优化代码 优化后的代码: harmony1234567891011121314151617181920import React, &#123;Fragment&#125; from 'react'import &#123;connect&#125; from "dva";const Counter = (&#123;count&#125;) =&gt; &#123; return ( &lt;Fragment&gt; &lt;h1&gt;&#123;count&#125;&lt;/h1&gt; &lt;button&gt;+&lt;/button&gt; &lt;/Fragment&gt; );&#125;;const mapStateToProps = (state) =&gt; &#123; // 取出models下的命名空间counter const &#123; count &#125; = state.counter; return &#123; count &#125;&#125;;export default connect(mapStateToProps)(Counter) 重新访问http://localhost:8000/counter,依然正常显示 定义propTypes(数据类型检查)harmony1234import PropTypes from 'prop-types'Counter.propTypes = &#123; count: PropTypes.number&#125;; dispatch修改Counter组件代码，给button增加一个点击事件harmony12345678const Counter = (&#123;count, dispatch&#125;) =&gt; &#123; return ( &lt;Fragment&gt; &lt;h1&gt;&#123;count&#125;&lt;/h1&gt; &lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/add"&#125;)&#125;&#125;&gt;+&lt;/button&gt; &lt;/Fragment&gt; );&#125;; type中必须以namespace/action 的形式传递，否则在reducer中会捕获不到 按钮点击后会dispatch一个action{type: “counter/add”}到reducer中控制台效果： 编写reducers修改src/models/counter.js,修改reducers部分代码harmony12345678reducers: &#123; add(state, action) &#123; console.log(action); return &#123; count: state.count+1 &#125; &#125; &#125; 修改src/components/Counter.js,增加Dispatch传递的参数harmony1&lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/add", names: "psl"&#125;)&#125;&#125;&gt;+&lt;/button&gt; 页面效果：有时候，当项目非常复杂的时候，为了便于管理reducers中的函数，reducers中的函数也可以这么写 harmony12345678reducers: &#123; 'add'(state, action) &#123; console.log(action); return &#123; count: state.count+1 &#125; &#125; &#125; 增加type层级harmony1&lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/add/num", names: "psl"&#125;)&#125;&#125;&gt;+&lt;/button&gt; harmony12345678reducers: &#123; 'add/num'(state, action) &#123; console.log(action); return &#123; count: state.count+1 &#125; &#125; &#125; 页面效果： 异步动作修改effectsdva中的异步动作要放到effects中来触发,放到effects中可以使用call,put等方法,也就是redux-saga中的一些方法修改src/components/Counter.js,新增加一个button harmony1&lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/asyncAdd"&#125;)&#125;&#125;&gt;asyncAdd+&lt;/button&gt; 修改src/models/counter.js中的effectsharmony12345effects: &#123; *asyncAdd(&#123; payload &#125;, &#123; call, put &#125;) &#123; // eslint-disable-line yield put(&#123; type: 'add/num' &#125;); &#125;, &#125;, yield put({ type: ‘add/num’ }) 会触发reducers中的add方法，由于是同命名空间下，所以不用加入namespace层级 查看redux控制台效果 effects中asyncAdd方法中的payload可以接收dispatch过来的额外的参数例如: harmony1&lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/asyncAdd", payload: "payload"&#125;)&#125;&#125;&gt;asyncAdd+&lt;/button&gt; harmony123456effects: &#123; *asyncAdd(&#123; payload &#125;, &#123; call, put &#125;) &#123; // eslint-disable-line console.log(payload); yield put(&#123; type: 'add/num' &#125;); &#125;, &#125;, 查看redux控制台效果 延时函数修改src/models/counter.js中的effects harmony1234567import &#123;delay&#125; from 'dva/saga'effects: &#123; *asyncAdd(&#123; payload &#125;, &#123; call, put &#125;) &#123; // eslint-disable-line yield call(delay, 1000); yield put(&#123; type: 'add/num' &#125;); &#125;, &#125;, selectselect 用于取state中的数据引入select: harmony12345678effects: &#123; *asyncAdd(&#123; payload &#125;, &#123; call, put, select &#125;) &#123; // eslint-disable-line const counter = yield select(state =&gt; state.counter); console.log(counter); yield call(delay, 1000); yield put(&#123; type: 'add/num' &#125;); &#125;, &#125;, 查看控制台效果 几种不同的写法:harmony12345// const counter = yield select(state =&gt; state.counter);// const counter = yield select((&#123;counter&#125;) =&gt; counter);// const counter = yield select(_ =&gt; _.counter);const &#123; counter &#125; = yield select(_ =&gt; _);console.log(counter); 路由跳转withRouter修改src/components/Counter.js harmony12345678910111213141516171819202122232425262728import React, &#123;Fragment&#125; from 'react'import &#123;connect&#125; from "dva";import PropTypes from 'prop-types'import &#123;withRouter&#125; from 'dva/router'const Counter = (&#123;count, dispatch, history&#125;) =&gt; &#123; return ( &lt;Fragment&gt; &lt;h1&gt;&#123;count&#125;&lt;/h1&gt; &lt;button onClick=&#123;() =&gt; &#123;history.push("/")&#125;&#125;&gt;go home&lt;/button&gt; &lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/add/num", names: "psl"&#125;)&#125;&#125;&gt;+&lt;/button&gt; &lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/asyncAdd", payload: "payload"&#125;)&#125;&#125;&gt;asyncAdd+&lt;/button&gt; &lt;/Fragment&gt; );&#125;;Counter.propTypes = &#123; count: PropTypes.number&#125;;const mapStateToProps = (state) =&gt; &#123; // 取出models下的命名空间counter const &#123; count &#125; = state.counter; return &#123; count &#125;&#125;;export default connect(mapStateToProps)(withRouter(Counter)) 在effects中的路由跳转修改src/models/counter.js 引入routerRedux:harmony1import &#123;routerRedux&#125; from 'dva/router' 在effects中增加redirect方法:harmony123*redirect(&#123; _ &#125;, &#123; call, put &#125;) &#123; yield put(routerRedux.push("/"));&#125; 修改src/components/Counter.js中的Counter组件 harmony1234567891011const Counter = (&#123;count, dispatch, history&#125;) =&gt; &#123; return ( &lt;Fragment&gt; &lt;h1&gt;&#123;count&#125;&lt;/h1&gt; &lt;button onClick=&#123;() =&gt; &#123;history.push("/")&#125;&#125;&gt;go home&lt;/button&gt; &lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/redirect"&#125;)&#125;&#125;&gt;go home by effects&lt;/button&gt; &lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/add/num", names: "psl"&#125;)&#125;&#125;&gt;+&lt;/button&gt; &lt;button onClick=&#123;() =&gt; &#123;dispatch(&#123;type: "counter/asyncAdd", payload: "payload"&#125;)&#125;&#125;&gt;asyncAdd+&lt;/button&gt; &lt;/Fragment&gt; );&#125;; 带参数的跳转修改src/models/counter.js 引入query-string:harmony1import &#123;queryString&#125; from 'query-string' 修改effects中的redirectharmony123456789*redirect(&#123; _ &#125;, &#123; call, put &#125;) &#123; // yield put(routerRedux.push("/")); yield put(routerRedux.push(&#123; pathname: '/', search: queryString.stringify(&#123; from: "psl" &#125;) &#125;));&#125; 点击按钮后跳转到http://localhost:8000/?from=psl subscriptionsdispatch监听窗口改变触发add/num方法:harmony1234567subscriptions: &#123; setup(&#123; dispatch, history &#125;) &#123; // eslint-disable-line window.onresize = () =&gt; &#123; dispatch(&#123;type: 'add/num'&#125;); &#125; &#125;,&#125;, setup可以为多个，可以同时订阅多个监听事件 historyharmony12345setupHistory(&#123; dispatch, history &#125;) &#123; // eslint-disable-line history.listen((location) =&gt; &#123; console.log(location) &#125;)&#125;, 控制台输出： 可以发现location中包含pathname,search,hash,state等参数，我们可以通过析构对象来做一些特殊事情 例如：harmony1234567setupHistory(&#123; dispatch, history &#125;) &#123; // eslint-disable-line history.listen((&#123;pathname&#125;) =&gt; &#123; if (pathname === "/counter") &#123; dispatch(&#123;type: 'add/num'&#125;); &#125; &#125;)&#125;,]]></content>
      <tags>
        <tag>react</tag>
        <tag>redux</tag>
        <tag>Dva</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql锁]]></title>
    <url>%2F2019%2F02%2F24%2F2019-02-24-mysql(1)%2F</url>
    <content type="text"><![CDATA[实验环境事物隔离场景repeatable-read 表语句准备12345678910CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 先假设一个没有堵塞的场景： SessionA SessionB SessionC T1 begin;select * from t where d=5 for update;result:(5,5,5) T2 update t set d=5 where id=0; T3 select * from t where d=5 for update;result:(0,0,5)(5,5,5) T4 insert into t values(1,1,5); T5 select * from t where d=5 for update;result:(0,0,5)(1,1,5)(5,5,5) T6 commit; 可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。 Q1 只返回 id=5 这一行； 在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行； 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。 其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 Mysql如何解决幻读本片需要用到的两种锁LOCK IN SHARE MODE是读锁(只是不让别人写)，FOR UPDATE是写锁(还不让别人加读锁) InnoDB行锁InnoDB行锁是通过索引上的索引项来实现的，InnoDB这种行锁实现特点意味者：只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表锁！如select * from t where d=5 for update;会锁住d=5索引覆盖范围的相关行，如果没有索引则会锁住所有行 间隙锁 (Gap Lock)行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。这样，当你执行 select * from t where d=5 for update 的时候，就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。 行锁和间隙锁比较行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。 读锁 写锁 读锁 兼容 冲突 写锁 冲突 冲突 也就是说，跟行锁有冲突关系的是“另外一个行锁”。但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。 SessionA SessionB begin;select * from t where c=7 lock in share mode; begin;select * from t where c=7 for update; 这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。 间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。 看下面的实例 SessionA SessionB begin;select * from t where id=9 for update; begin;select * from t where id=9 for update; insert into t values(9,9,9);result:(blocked) insert into t values(9,9,9);result:(Deadlock) 上面的场景形成死锁了。我们按语句执行顺序来分析一下： session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10); session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功； session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待； session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。 至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。 mysql锁类型锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。 MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 &lt;=5.7.24，8.0 系列 &lt;=8.0.13。 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。原则 2：查找过程中访问到的对象才会加锁。优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。一个特殊场景：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 等值查询间隙锁 SessionA SessionB SessionC begin;update t set d=d+1 where id=7; insert into t values(8,8,8); result:(blocked) update t set d=d+1 where id=10;result:(ok) 由于表 t 中没有 id=7 的记录，所以用我们上面提到的加锁规则判断一下的话： 根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10]； 同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10)。 所以，session B 要往这个间隙里面插入 id=8 的记录会被锁住，但是 session C 修改 id=10 这行是可以的。 非唯一索引等值锁 SessionA SessionB SessionC begin;select id from t where c=5 lock in share mode(读锁); update t set d=d+1 where id=5; result:(ok) insert into t values(7,7,7);result:(blocked) 看到这个例子，你是不是有一种“该锁的不锁，不该锁的乱锁”的感觉？我们来分析一下吧。 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5] 加上 next-key lock。 要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10] 加 next-key lock。 但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。 根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。 但 session C 要插入一个 (7,7,7) 的记录，就会被 session A 的间隙锁 (5,10) 锁住。 需要注意，在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。 这个例子说明，锁是加在索引上的；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c=5 lock in share mode。 主键索引范围锁 SessionA SessionB SessionC begin;select * from t where id &gt;=10 and id&lt;11 for update; insert into t values(7,7,7); result:(ok)insert into t values(13,13,13);result:(blocked) update t set d=d+1 where id=15;result:(blocked) 开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁。 范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。 所以，session A 这时候锁的范围就是主键索引上，行锁 id=10 和 next-key lock(10,15]。 非唯一索引范围锁 SessionA SessionB SessionC begin;select * from t where c&gt;10 and c&lt;11 for update; insert into t values(8,8,8); result:(blocked) update t set d=d+1 where id=15;result:(blocked) 这次 session A 用字段 c 来判断，加锁规则跟主键索引范围锁唯一的不同是：在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10] 这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁，因此最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。 唯一索引范围锁特殊场景 SessionA SessionB SessionC begin;select * from t where id &gt;10 and id&lt;=15 for update; update t set d=d+1 where id=20; result:(blocked) insert into t values(16,16,16);result:(blocked) session A 是一个范围查询，按照原则 1 的话，应该是索引 id 上只加 (10,15] 这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20] 这个 next-key lock也会被锁上。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis cluster 故障转移]]></title>
    <url>%2F2019%2F01%2F25%2F2019-01-25-redis-cluster-out%2F</url>
    <content type="text"><![CDATA[故障发现通过ping/pong消息实现故障发现，不依赖sentinel 主观下线定义：某个节点认为另外一个节点不可用“偏见” 主观下线流程： 客观下线定义：当半数以上持有槽的主节点都标记某节点主观下线 客观下线流程： 故障恢复资格检查 每个从节点检查与故障节点的断线时间 超过cluster-node-timeout*cluster-slave-validity-factor取消资格 cluster-slave-validity-factor：默认为10准备选举时间选举投票替换主节点 当前从节点复制变为主节点。(slaveof no one) 执行clusterDelSlot撤销故障主节点负责的槽，并执行clusterAddSlot把这些槽分配给自己 向群广播自己的pong消息，表明已替换了故障从节点 redis cluster 开发常见问题集群完整性cluster-require-full-coverage默认为yes问题： 集群中16384个槽全部可用，保证完整性 节点故障转移或正在转移大多数业务无法容忍，建议设置为no 当其中一台机器发生故障，此时集群状态不可用，不可以set ket,不建议设置为yes 宽带消耗官方建议：1000个节点 消息频率 节点发现和节点最后通信时间超过cluster-node-timeout/2时会发送ping消息 消息数据量 slots数据组(2k)和整个集群1/10的状态数据(10个节点状态数据约1k) 节点部署机器规模 分布机器越多且每台机器划分的节点越均匀，整体的可用带宽越高例子：200个节点，20个物理机器（每台10个节点） cluster-node-timeout=15000 ping/pong带宽约25MB cluster-node-timeout=20000 ping/pong带低于15MB 优化 避免多业务使用多集群，大业务可以多集群 cluster-node-timeout 带宽和故障转移速度的均衡 尽量均匀分配多个机器，保证带宽 PUB/SUB广播问题：publish在集群每个节点广播：加重带宽解决：单独走一套redis sentinel 数据倾斜数据倾斜：内存不均匀 节点和槽分配不均匀 不同槽对应键值数差异大 可能存在has_tag cluster countkeysinslot {slot}获取槽对应键值个数 包含bigkey 例如大字符串，几百万元素的hash,set等 从节点，redis-cli –bigkeys 优化数据结构，拆分key 内存相关配置不一致 hash-max-ziplist-value, set-max-intset-entries等 请求倾斜：key热点重要的key或者bigkey优化： 避免big_key 热键不要使用hash_tag（避免落在一个节点） 当一致性不高时可以使用本地缓存+MQ 读写分离只读连接：集群模式的从节点不接受任何读写请求 重定向到负责槽的主节点 readonly命令可以读：连接级的命令读写分离：更加复杂 复制延迟，从节点故障，读取过期数据 修改客户端：cluster slaves {nodeid} 数据迁移官方工具：redis-trib.rb import 只能从单机迁移到集群 不支持在线迁移，source需要停写 不支持断点续传 单线程迁移，影响速度在线迁移： 唯品会：redis-migrate-tool 豌豆荚：redis-port 集群VS单机集群限制 key批量操作限制 key事物和lua支持有限，操作的key必须在同一个节点 key是数据分区的最小粒度：不支持bigkey分区 不支持多个数据库：集群模式下只有一个db0 复制只支持一层，不支持树形 Redis Cluster: 满足容量和性能的扩展性：很多业务不需要 很多场景Redis Sentinel足够好]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis cluster 客户端路由]]></title>
    <url>%2F2019%2F01%2F24%2F2019-01-24-redis-cluster-route%2F</url>
    <content type="text"><![CDATA[MOVED重定向 槽命中：直接返回 算出key的slot值1&gt;127.0.0.1&gt; 6379 cluster keyslot hello 返回结果：1(integer) 866 槽不命中：moved异常算出key的slot值1&gt;127.0.0.1&gt; 6379 cluster keyslot php 返回结果：1(integer) 9244 看一个小例子:12345678910111213141516171819redis-cli -c -p 7000 //集群模式127.0.0.1:7000&gt; cluster keyslot hello(integer) 866127.0.0.1:7000&gt; set hello wordOK127.0.0.1:7000&gt; cluster keyslot php(integer) 9244127.0.0.1:7000&gt; set php best-&gt; Redirected to slot [9244] located at 127.0.0.1:7001OK127.0.0.1:7001&gt; get php&quot;best&quot;127.0.0.1:7001&gt; redis-cli -p 7000127.0.0.1:7000&gt; cluster keyslot php(integer) 9244127.0.0.1:7000&gt; set php best(error) MOVED 9244 127.0.0.1:7001127.0.0.1:7000&gt; ASK重定向 在集群缩容扩容的时候，要对槽进行迁移，槽迁移过程中要遍历进行migrate,迁移时间比较长，此时在此过程中访问一个key,但是key已经迁移到目标节点，就需要一个新的方案来解决这个问题，redis cluster 对这个问题已经有解决方案 我们来看它的一个实现演示： moved &amp; ask 两者都是客户端重定向 moved:槽已确定迁移 ask:槽还在迁移中 smart客户端基本原理追求性能： 从集群中选一个可运行的节点，使用cluster slots 初始化槽和节点映射 将cluster slots结果映射到本地，为每个节点创建redisPool 执行命令 基本流程： 关于redis cluster 客户端使用可参考redis-go-cluster 批量操作优化批量操作怎么实现?meget meset必须在一个槽 串行mget 串行IO 并行IO hash_tag 四种方案优缺点对比方案优点缺点网络IO串行mget编程简单，少量keys满足需求大量keys请求延迟严重O(keys)串行IO编程简单，少量节点满足需求大量node延迟严重O(nodes)并行IO利用并行特性，延迟取决于最慢的节点编程复杂，超市定位问题难O(max(node))hash_tag性能最高读写增加tag维护成本，tag分布易出现数据倾斜O(1))]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis cluster 伸缩]]></title>
    <url>%2F2019%2F01%2F23%2F2019-01-23-redis-cluster-operator%2F</url>
    <content type="text"><![CDATA[集群伸缩原理 集群伸缩=槽和数据在节点之间的移动 扩容集群准备新节点新节点： 集群模式 配置和其它节点统一 启动后仍是孤儿节点 加入集群12cluster meet 127.0.0.1 6385cluster meet 127.0.0.1 6386 加入后的效果 加入集群的作用： 为它迁移槽和数据实现扩容 作为从节点负责故障转移 1redis-cli --cluster add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id &lt;arg&gt; 建议使用redis-trib.rb能够避免新节点已经加入了其它集群，造成故障 迁移槽和数据槽迁移计划: 迁移数据： 对目标节点发送: cluster setslot{slot} importing {sourceNodeId}命令，让目标节点准备导入槽的数据。 对源节点发送: cluster setslot{slot} migrating {targetNodeId}命令，让源节点准备迁出槽的数据。 源节点循环执行: cluster getkeysinslot{slot}{count}命令，每次获取count个属于槽的键。 在源节点执行: migrate {targetIP}{targetPort} key 0 {timeout}命令把指定key迁移。 重复执行3-4直到槽下所有数据节点均迁移到目标节点。 向集群内所有主节点发送cluster setslot{slot} node {targetNodeId}命令，通知槽分配给目标节点。 数据迁移伪python代码:123456789101112131415161718def move_slot(source,target,slot): #目标节点准备导入槽slot target.cluster("setslot",slot,"importing",source.nodeID) #目标节点准备全出槽slot target.cluster("setslot",slot,"migrating",source.nodeID) while True: #批量从源节点获取键 keys = source.cluster("getkeysinslot",slot,pipeline_size) if keys.length ==0: #键列表为空时，退出循环 break #批量迁移键到目标节点 source.call("migrate",target.host,target.port,"",timeout,"keys") #向集群所有主节点通知槽slot被分配给目标节点 for node in nodes: if node.flag =="slave": continue node.cluster("setslot",slot,"node",target.nodeID) pipline迁移 3.0.6 版本pipline数据迁移会有丢失数据bug，在3.2.8已解决 扩容演示环境准备当前集群是三主三从结构，此时我们加入两个新节点7006,7007。7007是7006的从节点，我们需要从7001,7002节点把一部分数据迁移给7006。配置准备:12sed 's/7000/7006/g' redis-7000.conf &gt; redis-7006.confsed 's/7000/7007/g' redis-7000.conf &gt; redis-7007.conf meet:12redis-cli -p 7000 cluster meet 127.0.0.1 7006redis-cli -p 7000 cluster meet 127.0.0.1 7007 replicate:1redis-cli -p 7007 cluster replicate d57d27051ce9db7752f894394b621368f9e0a058 此时7007已经属于7006的从节点 迁移数据： 由于槽数量比较多，所以这里使用redis-trib来迁移1redis-cli --cluster reshard 127.0.0.1 7000 此时给我们提示出了当前集群的信息，由于我们现在是4个主节点，所以需要分成四等份来支持向master写入数据 槽迁移后的信息： 收缩集群下线迁移槽 忘记节点1redis-cli&gt;cluster forget &#123;downNodeId&#125; 关闭节点收缩集群演示例：下线7006，7007 迁移槽：迁移过程命令： redis-cli –cluster reshard –cluster-from {7006nodeid} –cluster-to 7000{7000nodeid} –cluster-slots {slot num} 127.0.0.1:7006 redis-cli –cluster reshard –cluster-from {7006nodeid} –cluster-to 7001{7001nodeid} –cluster-slots {slot num} 127.0.0.1:7006 redis-cli –cluster reshard –cluster-from {7006nodeid} –cluster-to 7002{7002nodeid} –cluster-slots {slot num} 127.0.0.1:7006 迁移到7000示例：1redis-cli --cluster reshard --cluster-from d57d27051ce9db7752f894394b621368f9e0a058 --cluster-to 092fd7c3cf19693eddec5c0fae9894d681023ce5 --cluster-slots 1365 127.0.0.1:7006 之后选择yes即可 可观察出0-1364的槽节点以迁移完毕，重复上述步骤，迁移剩余的槽 迁移后： 忘记节点：1redis-cli --cluster del-node 127.0.0.1:7000 d57d27051ce9db7752f894394b621368f9e0a058 需要先下线从节点在下线主节点，否则会发生故障转移 完成缩容]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis cluster]]></title>
    <url>%2F2019%2F01%2F20%2F2019-01-20-redis-cluster%2F</url>
    <content type="text"><![CDATA[呼唤集群当系统应用需要有更大容量和QPS的支撑，此时就需要采用的集群的方式，也可以简单理解为加机器 数据分区: 分布方式顺序分布 哈希分布 节点取余 一致性hash 虚拟槽分区 节点取余 客户端分片: 哈希+取余 节点伸缩: 数据节点关系变化，导致数据迁移 迁移数量和添加节点数量相关：建议翻倍扩容 一致性hash 一致性hash扩容 客户端分片：哈希+顺时针（优化取余） 节点伸缩：只影响临近节点，但是还是有数据迁移 翻倍伸缩：保证最小迁移数据和负载均衡 虚拟槽分布 预设虚拟槽：每个槽映射一个数据子集，一般比节点数大 良好的hash函数：如crc16 服务端管理节点，槽，数据：例如redis cluster 对比分布方式特点典型产品哈希分布数据分散度高key,value分布业务无关无法顺序访问支持批量操作一致性hash memcacheredis cluster其它缓存产品顺序分布数据分散度易倾斜key,value业务相关可顺序访问支持批量操作BigTableHBase Redis Cluster架构 节点 meet 指派槽 复制 特性： 复制 分片 高可用 安装原生安装1: 配置开启节点: 1234567port&#123;$port&#125;daemonize yesdir &quot;$&#123;redis-src&#125;/data/&quot;dbfilename &quot;dump-&#123;$port&#125;.rdb&quot;logfile &quot;&#123;$port&#125;.log&quot;cluster-enabled &quot;yescluster-config-file nodes-&#123;$port&#125;.conf 批量生成配置文件: 执行：123456redis-server redis-7000.confredis-server redis-7001.confredis-server redis-7002.confredis-server redis-7003.confredis-server redis-7004.confredis-server redis-7005.conf 2: meet cluster meet ip port 12345redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7001redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7002redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7003redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7004redis-cli -h 127.0.0.1 -p 7000 cluster meet 127.0.0.1 7005 先进行7000和7001的握手 发现7000和7001已经完成握手，继续meet其他的节点 此时执行nodes```和```cluster info```均发现6个节点相互关联，证明已经握手成功1234567891011121314153: 指派槽**cluster addslots slot [slot...]**由于一共要分配16384个槽，所以需要借助脚本去分配槽```bashstart=$1end=$2port=$3for slot in `seq $&#123;start&#125; $&#123;end&#125;`do echo &quot;slot:$&#123;slot&#125;&quot; redis-cli -p $&#123;port&#125; cluster addslots $&#123;slot&#125;done 我们要配置的是三主三从，所以要把16384三等分10-5461 7000 5462-10922 7001 10923-16383 7002 执行以下命令:123sh addslots.sh 0 5461 7000sh addslots.sh 5462 10922 7001sh addslots.sh 10923 16383 7002 查看槽分配状态 此时发现16384个槽确实已经分配完毕，槽分配完毕 4: 主从 cluster replicate node-id 给7003分配到master7000主节点上：123redis-cli -p 7003 cluster replicate 6d4942b15eb5e02bb6193453443ccb827c13c6dfredis-cli -p 7004 cluster replicate 916f84dee5fbef724ddf2f90fddf51fd654113f1redis-cli -p 7005 cluster replicate fee14c1f872fc4c7d451f84a616cf735d220538b 主从分配结果： 官方工具由于原生安装过程比较麻烦，又容易出错，所以正常的生产环境使用官方工具安装，但是掌握原生安装的方式更容易让我们理解集群分配的原理 ruby环境准备 下载编译安装ruby 安装rubygem redis 安装redis-trib.rb 1: 配置开启节点: 1234567port&#123;$port&#125;daemonize yesdir &quot;$&#123;redis-src&#125;/data/&quot;dbfilename &quot;dump-&#123;$port&#125;.rdb&quot;logfile &quot;&#123;$port&#125;.log&quot;cluster-enabled &quot;yescluster-config-file nodes-&#123;$port&#125;.conf 执行：123456redis-server redis-7000.confredis-server redis-7001.confredis-server redis-7002.confredis-server redis-7003.confredis-server redis-7004.confredis-server redis-7005.conf 2: 集群创建 12//1 表示1个主节点分配1个从节点redis-cli --cluster create --cluster-replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 上图分别展示了槽分配，主从和节点信息，符合预期执行yes即可 分配成功信息： 集群验证： 当然如果维护上百台集群显然也不是最好的方式，可以借助或构建云平台来管理集群]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵]]></title>
    <url>%2F2019%2F01%2F19%2F2018-01-11-redis-sentinel%2F</url>
    <content type="text"><![CDATA[Redis Sentinel基本架构 多个sentinel发现并确认master有问题 选举出一个sentinel作为领导 选出一个salve作为master 通知其余slave成为新的master的slave 通知客户端主从变化 等待master复活成为新的master的slave 安装与配置 配置开启主从节点 配置开启sentinel监控master节点 Redis主节点启动redis-7000.conf```123### redis配置:主节点: port 7000daemonize yespidfile /var/run/redis/7000.pidlogfile 7000.logdir “${redis-src}/data/“1从节点: port 7001daemonize yespidfile /var/run/redis/7001.pidlogfile 7001.logdir “${redis-src}/data/“slaveof 127.0.0.1 70001234567```port 7002daemonize yespidfile /var/run/redis/7002.pidlogfile 7002.logdir &quot;$&#123;redis-src&#125;/data/&quot;slaveof 127.0.0.1 7000 sentinel配置:1234567port $&#123;port&#125;dir &quot;$&#123;redis-src&#125;/data/&quot;logfile $&#123;port&#125;.logsentinel monitor mymaster 127.0.0.1 7000 2 #监控主节点的名字 2对应当两个sentinel发现主节点有问题就发生故障转移sentinel down-after-millisenconds mymaster 30000 #ping30秒后不通认为有问题sentinel parallel-sync mymaster 1sentinel failover-timeout mymaster 180000 安装演示配置redis 单机演示实际为能相互ping通的多台机器 1：创建master节点配置 2：创建7000,7001节点配置 3：查看主从状态 到此为止主从的配置搭建完毕了 配置sentinel 通过官方提供的配置模板导入sentinel配置 配置信息： 查看Sentinel监控状态： 到此我们可以发现Sentinel已经检测到了matser节点的主从信息，由于我们只启动一个Sentinel所以Sentinel发现的数目为1 再去看看redis-sentinel-26379.conf的变化: 发现他已经把7000的两个slave节点的信息配置自动写入到了配置文件中 生成另外两个Sentinel配置 查看sentinel状态 发现26380的Sentinel并没有发现其他节点 查看原因：123cat /var/log/redis/26379.logcat /var/log/redis/26380.logcat /var/log/redis/26381.log 我们发现三个节点的pid都是一样的，所以需要配置pid编辑26379,26380,26381.conf 去掉配置文件自动生成的myid,并加入123pidfile &quot;/var/run/redis/redis-sentinel-26379.pid&quot;pidfile &quot;/var/run/redis/redis-sentinel-26380.pid&quot;pidfile &quot;/var/run/redis/redis-sentinel-26381.pid&quot; 状态已正常 go客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package mainimport ( "fmt" "github.com/gomodule/redigo/redis" "github.com/letsfire/redigo" "github.com/letsfire/redigo/mode" "github.com/letsfire/redigo/mode/sentinel" "strconv" "time" "log")func main()&#123; var ( i int sentinelMode mode.IMode ) sentinelMode = sentinel.New( sentinel.Addrs([]string&#123;"127.0.0.1:26379", "127.0.0.1:26380", "127.0.0.1:26381"&#125;), sentinel.PoolOpts( mode.MaxActive(20), // 最大连接数，默认0无限制 mode.MaxIdle(0), // 最多保持空闲连接数，默认2*runtime.GOMAXPROCS(0) mode.Wait(false), // 连接耗尽时是否等待，默认false mode.IdleTimeout(0), // 空闲连接超时时间，默认0不超时 mode.MaxConnLifetime(0), // 连接的生命周期，默认0不失效 mode.TestOnBorrow(nil), // 空间连接取出后检测是否健康，默认nil ), sentinel.DialOpts( redis.DialReadTimeout(time.Second), // 读取超时，默认time.Second redis.DialWriteTimeout(time.Second), // 写入超时，默认time.Second redis.DialConnectTimeout(time.Second), // 连接超时，默认500*time.Millisecond redis.DialPassword(""), // 鉴权密码，默认空 redis.DialDatabase(0), // 数据库号，默认0 redis.DialKeepAlive(time.Minute*5), // 默认5*time.Minute redis.DialNetDial(nil), // 自定义dial，默认nil redis.DialUseTLS(false), // 是否用TLS，默认false redis.DialTLSSkipVerify(false), // 服务器证书校验，默认false redis.DialTLSConfig(nil), // 默认nil，详见tls.Config ), // 连接哨兵配置，用法于sentinel.DialOpts()一致 // 默认未配置的情况则直接使用sentinel.DialOpts()的配置 // sentinel.SentinelDialOpts() ) var instance = redigo.New(sentinelMode) for &#123; res, err := instance.String(func(c redis.Conn) (res interface&#123;&#125;, err error) &#123; return c.Do("set", "test" + strconv.Itoa(i), i) &#125;) if err != nil &#123; log.Println(err) &#125; else &#123; fmt.Println(res) &#125; i++ time.Sleep(1 * time.Second) &#125;&#125; 执行以下命令，并模拟7000端口宕机1go run client.go 执行结果： 日志分析查看7001.log 从日志中发现选举7002为master,执行redis-cli -p 7002 info replication验证下 看看sentinel日志的变化 故障转移三个定时任务 每10秒每个sentinel对master和slave执行info 发现slave节点 确定主从关系 每2秒每个sentinel通过master节点的channel节点交换信息(pub/sub) 通过sentinel和:hello频道交互 交互对节点的看法和自身的信息 每1秒每个Sentinel对其它Sentinel和Redis执行ping 失败判定依据，心跳检测 主观下线和客观下线 主观下线：每个sentinel节点对Redis节点失败的偏见 客观下线：所有sentinel节点对Redis节点失败达成共识（quorum:建议节点数/2+1） 领导者选举 原因：只有一个sentinel节点完成故障转移 选举：通过sentinel is-master-down-by-addr命令都希望成为领导者 每个主观下线的Sentinel节点向其他Sentinel节点发送命令，要求它设置为领导者 收到命令的Sentinel节点如果没有同意通过其他Sentinel节点发送的命令，那么该同意将被拒绝 如果该Sentinel节点发现通过的票数已经超过Sentinel集合半数且超过quorum，那么它将成为领导者 如果此过程中有多个Sentinel节点成为领导者，那么将等待一段时间重新选举 故障转移 从slave节点选出一个”合适的”节点作为新的master节点 对上面的slave节点执行slaveof no one 命令让其成为master节点 向剩余的slave节点发送命令，让他们成为新master节点的slave节点，复制规则和parallel-syncs参数有关 更新原来的master节点并配置为slave,并保持对其”关注”，当其恢复后，命令他去复制新的master节点 选择”合适的”slave节点 选择slave-priority(slave节点优先级)最高的slave节点。如果存在则返回，不存在则继续 选择复制偏移量最大的slave节点(复制的最完整)如果存在则返回，不存在则继续 选择runid最小的slave节点]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang etcd api]]></title>
    <url>%2F2019%2F01%2F05%2F2019-01-05-golang-etcd%2F</url>
    <content type="text"><![CDATA[ETCDETCD是用于共享配置和服务发现的分布式，一致性的KV存储系统。ETCD是CoreOS公司发起的一个开源项目，授权协议为Apache。 核心特性： 将数据存储在集群中的高可用kv存储 允许应用实时监控kv变化 能够容忍单点故障，能够应对网络分区 复杂特性： 底层存储是按照key有序排列的，可以顺序遍历 因为key有序，所以etcd天然支持按目录结果高效遍历 支持复杂事物，提供if…then…else的事物能力 基于租约机制实现key的TTL过期 客户端连接实例123456789101112131415var ( config clientv3.Config client *clientv3.Client err error )config = clientv3.Config&#123; Endpoints: []string&#123;"127.0.0.1:2379"&#125;, // 集群列表 DialTimeout: 5 * time.Second,&#125;if client, err = clientv3.New(config); err != nil &#123; log.Printf("clientv3.New error:", err) return&#125; api介绍kv操作 123456789101112type KV interface &#123; Put(ctx context.Context, key, val string, opts ...OpOption) (*PutResponse, error) Get(ctx context.Context, key string, opts ...OpOption) (*GetResponse, error) Delete(ctx context.Context, key string, opts ...OpOption) (*DeleteResponse, error) Compact(ctx context.Context, rev int64, opts ...CompactOption) (*CompactResponse, error) Do(ctx context.Context, op Op) (OpResponse, error) Txn(ctx context.Context) Txn&#125; 关于租约123456789101112131415type Lease interface &#123; Grant(ctx context.Context, ttl int64) (*LeaseGrantResponse, error) Revoke(ctx context.Context, id LeaseID) (*LeaseRevokeResponse, error) TimeToLive(ctx context.Context, id LeaseID, opts ...LeaseOption) (*LeaseTimeToLiveResponse, error) KeepAlive(ctx context.Context, id LeaseID) (&lt;-chan *LeaseKeepAliveResponse, error) KeepAliveOnce(ctx context.Context, id LeaseID) (*LeaseKeepAliveResponse, error) Close() error&#125; 创建、更新key1234567891011121314 var( kv clientv3.KV putResp *clientv3.PutResponse ) kv = clientv3.NewKV(client)if putResp, err = kv.Put(context.TODO(), "/cron/jobs/job1", "bye", clientv3.WithPrevKV()); err != nil &#123; log.Printf("kv.Put error:", err)&#125; else &#123; fmt.Println("Revision:", putResp.Header.Revision) if putResp.PrevKv != nil &#123; fmt.Println("value:", string(putResp.PrevKv.Value)) &#125;&#125; SessionA执行创建key脚本再次执行创建key脚本 clientv3.WithPrevKV()作用是可以获取put之前key的值；操作示例第一次创建hello的key,第二次创建bye的key 输出结果： 删除key123456789101112131415var( kv clientv3.KV delResp *clientv3.DeleteResponse kvPair *mvccpb.KeyValue) if delResp, err = kv.Delete(context.TODO(), "/cron/jobs/job1", clientv3.WithPrevKV()); err != nil &#123; log.Printf("kv.delete error:", err) return &#125;//被删除之前的value是什么if len(delResp.PrevKvs) != 0 &#123; for _, kvPair = range delResp.PrevKvs &#123; fmt.Println("删除了", string(kvPair.Key), string(kvPair.Value)) &#125;&#125; 输出结果 查询key123456789101112131415 var( kv clientv3.KV getResp *clientv3.GetResponse ) if getResp, err = kv.Get(context.TODO(), "/cron/jobs/job1"); err != nil &#123; log.Printf("kv.Put error:", err)&#125; else &#123; //fmt.Println(getResp.Kvs, getResp.Count)&#125;if getResp, err = kv.Get(context.TODO(), "/cron/jobs/job1", clientv3.WithCountOnly()); err != nil &#123; log.Printf("kv.Put error:", err)&#125; else &#123; fmt.Println(getResp.Kvs, getResp.Count)&#125; 输出结果 加入clientv3.WithCountOnly()输出结果 clientv3.WithCountOnly() 只输出count值 watch key简单demo： 主要工作是开一个新的协程去模拟kv的删除更新操作,用main协程去监听key的put,delete操作，并在5秒后取消监听 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677 var ( config clientv3.Config client *clientv3.Client err error kv clientv3.KV watcher clientv3.Watcher getResp *clientv3.GetResponse watchStartRevision int64 watchRespChan &lt;-chan clientv3.WatchResponse watchResp clientv3.WatchResponse event *clientv3.Event)// 客户端配置config = clientv3.Config&#123; Endpoints: []string&#123;"127.0.0.1:2379"&#125;, DialTimeout: 5 * time.Second,&#125;// 建立连接if client, err = clientv3.New(config); err != nil &#123; fmt.Println(err) return&#125;// KVkv = clientv3.NewKV(client)// 模拟etcd中KV的变化go func() &#123; for &#123; kv.Put(context.TODO(), "/cron/jobs/job3", "i am job3") kv.Delete(context.TODO(), "/cron/jobs/job3") time.Sleep(1 * time.Second) &#125;&#125;()// 先GET到当前的值，并监听后续变化if getResp, err = kv.Get(context.TODO(), "/cron/jobs/job3"); err != nil &#123; fmt.Println(err) return&#125;// 现在key是存在的if len(getResp.Kvs) != 0 &#123; fmt.Println("当前值:", string(getResp.Kvs[0].Value))&#125;// 当前etcd集群事务ID, 单调递增的watchStartRevision = getResp.Header.Revision + 1// 创建一个watcherwatcher = clientv3.NewWatcher(client)// 启动监听fmt.Println("从该版本向后监听:", watchStartRevision)ctx, cancelFunc := context.WithCancel(context.TODO())time.AfterFunc(5 * time.Second, func() &#123; cancelFunc()&#125;)watchRespChan = watcher.Watch(ctx, "/cron/jobs/job3", clientv3.WithRev(watchStartRevision))// 处理kv变化事件for watchResp = range watchRespChan &#123; for _, event = range watchResp.Events &#123; switch event.Type &#123; case mvccpb.PUT: fmt.Println("修改为:", string(event.Kv.Value), "Revision:", event.Kv.CreateRevision, event.Kv.ModRevision) case mvccpb.DELETE: fmt.Println("删除了", "Revision:", event.Kv.ModRevision) &#125; &#125;&#125; 打印结果: 申请租约简单demo： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253 var ( config clientv3.Config client *clientv3.Client err error lease clientv3.Lease leaseResp *clientv3.LeaseGrantResponse leaseId clientv3.LeaseID kv clientv3.KV putResp *clientv3.PutResponse getResp *clientv3.GetResponse)config = clientv3.Config&#123; Endpoints: []string&#123;"127.0.0.1:2379"&#125;, // 集群列表 DialTimeout: 5 * time.Second,&#125;if client, err = clientv3.New(config); err != nil &#123; log.Printf("clientv3.New error:", err) return&#125;//申请一个4秒生周期的租约lease = clientv3.NewLease(client)if leaseResp, err = lease.Grant(context.TODO(), 4); err != nil &#123; log.Printf("lease.Grant error:", err)&#125;//拿到租约idleaseId = leaseResp.ID//put一个keykv = clientv3.NewKV(client)if putResp, err = kv.Put(context.TODO(), "/cron/jobs/job2", "bye", clientv3.WithLease(leaseId)); err != nil &#123; log.Printf("kv.Put error:", err) return&#125;fmt.Println("写入成功：", putResp.Header.Revision)//循环检测租约是否过期for &#123; if getResp, err = kv.Get(context.TODO(), "/cron/jobs/job2"); err != nil &#123; log.Printf("kv.Put error:", err) return &#125; if getResp.Count == 0 &#123; fmt.Println("kv过期了") break &#125; fmt.Println("还未过期：", getResp.Kvs) time.Sleep(5 * time.Second)&#125; 打印结果: 租约续约123456789101112131415161718192021222324 var ( keepRespChan &lt;-chan *clientv3.LeaseKeepAliveResponse keepResp *clientv3.LeaseKeepAliveResponse ) //租约续租if keepRespChan, err = lease.KeepAlive(context.TODO(), leaseId); err != nil &#123; fmt.Println(err) return&#125;//消费keepRespChango func() &#123; for &#123; select &#123; case keepResp = &lt;-keepRespChan: if keepRespChan == nil &#123; fmt.Println("租约已经失效了") goto END &#125; else &#123; // 每秒会续租一次, 所以就会受到一次应答 fmt.Println("收到自动续租应答:", keepResp.ID) &#125; &#125; &#125; END:&#125;() 打印结果: op操作1234567891011121314151617181920212223242526272829303132333435363738 var ( config clientv3.Config client *clientv3.Client err error kv clientv3.KV op clientv3.Op opResp clientv3.OpResponse)// 客户端配置config = clientv3.Config&#123; Endpoints: []string&#123;"127.0.0.1:2379"&#125;, DialTimeout: 5 * time.Second,&#125;// 建立连接if client, err = clientv3.New(config); err != nil &#123; fmt.Println(err) return&#125;// KVkv = clientv3.NewKV(client)op = clientv3.OpPut("/cron/jobs/job4", "opPut")if opResp, err = kv.Do(context.TODO(), op); err != nil &#123; log.Printf("clientv3.OpPut error:", err)&#125;fmt.Println("写入Revision：", opResp.Put().Header.Revision)op = clientv3.OpGet("/cron/jobs/job4")if opResp, err = kv.Do(context.TODO(), op); err != nil &#123; log.Printf("clientv3.OpGet error:", err)&#125;fmt.Println("读取Revision：", opResp.Get().Kvs[0].ModRevision)fmt.Println("读取Value：", string(opResp.Get().Kvs[0].Value)) 打印结果: 分布式锁上锁 12345678910111213141516 lease = clientv3.NewLease(client)//申请一个5秒生周期的租约if leaseResp, err = lease.Grant(context.TODO(), 5); err != nil &#123; log.Printf("lease.Grant error:", err)&#125;//拿到租约idleaseId = leaseResp.ID// 准备一个用于取消自动续租的contextctx, cancelFunc = context.WithCancel(context.TODO())// 5秒后会取消自动续租if keepRespChan, err = lease.KeepAlive(ctx, leaseId); err != nil &#123; fmt.Println(err) return&#125; 抢锁 123456789101112131415161718192021 // 创建事务txn = kv.Txn(context.TODO())// 定义事务// 如果key不存在txn.If(clientv3.Compare(clientv3.CreateRevision("/cron/lock/job5"), "=", 0)). Then(clientv3.OpPut("/cron/lock/job5", "xxx", clientv3.WithLease(leaseId))). Else(clientv3.OpGet("/cron/lock/job5")) // 否则抢锁失败// 提交事务if txnResp, err = txn.Commit(); err != nil &#123; fmt.Println(err) return // 没有问题&#125;// 判断是否抢到了锁if !txnResp.Succeeded &#123; fmt.Println("锁被占用:", string(txnResp.Responses[0].GetResponseRange().Kvs[0].Value)) return&#125; 处理业务 12fmt.Println("处理任务")time.Sleep(5 * time.Second) 释放锁 1234 // defer 会把租约释放掉, 关联的KV就被删除了// 确保函数退出后, 自动续租会停止defer cancelFunc()defer lease.Revoke(context.TODO(), leaseId) 完整Demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899 var ( config clientv3.Config client *clientv3.Client err error lease clientv3.Lease leaseResp *clientv3.LeaseGrantResponse leaseId clientv3.LeaseID kv clientv3.KV keepRespChan &lt;-chan *clientv3.LeaseKeepAliveResponse keepResp *clientv3.LeaseKeepAliveResponse ctx context.Context cancelFunc context.CancelFunc txn clientv3.Txn txnResp *clientv3.TxnResponse)// 客户端配置config = clientv3.Config&#123; Endpoints: []string&#123;"127.0.0.1:2379"&#125;, DialTimeout: 5 * time.Second,&#125;// 建立连接if client, err = clientv3.New(config); err != nil &#123; fmt.Println(err) return&#125;// KVkv = clientv3.NewKV(client)// 1, 上锁 (创建租约, 自动续租, 拿着租约去抢占一个key)lease = clientv3.NewLease(client)//申请一个5秒生周期的租约if leaseResp, err = lease.Grant(context.TODO(), 5); err != nil &#123; log.Printf("lease.Grant error:", err)&#125;//拿到租约idleaseId = leaseResp.ID// 准备一个用于取消自动续租的contextctx, cancelFunc = context.WithCancel(context.TODO())// defer 会把租约释放掉, 关联的KV就被删除了// 确保函数退出后, 自动续租会停止defer cancelFunc()defer lease.Revoke(context.TODO(), leaseId)// 5秒后会取消自动续租if keepRespChan, err = lease.KeepAlive(ctx, leaseId); err != nil &#123; fmt.Println(err) return&#125;//处理续约应答的协程go func() &#123; for &#123; select &#123; case keepResp = &lt;-keepRespChan: if keepRespChan == nil &#123; fmt.Println("租约已经失效了") goto END &#125; else &#123; // 每秒会续租一次, 所以就会受到一次应答 fmt.Println("收到自动续租应答:", keepResp.ID) &#125; &#125; &#125;END:&#125;()// if 不存在key， then 设置它, else 抢锁失败kv = clientv3.NewKV(client)// 创建事务txn = kv.Txn(context.TODO())// 定义事务// 如果key不存在txn.If(clientv3.Compare(clientv3.CreateRevision("/cron/lock/job5"), "=", 0)). Then(clientv3.OpPut("/cron/lock/job5", "xxx", clientv3.WithLease(leaseId))). Else(clientv3.OpGet("/cron/lock/job5")) // 否则抢锁失败// 提交事务if txnResp, err = txn.Commit(); err != nil &#123; fmt.Println(err) return // 没有问题&#125;// 判断是否抢到了锁if !txnResp.Succeeded &#123; fmt.Println("锁被占用:", string(txnResp.Responses[0].GetResponseRange().Kvs[0].Value)) return&#125;// 2, 处理业务fmt.Println("处理任务")time.Sleep(5 * time.Second) SessionASessionBgo run main.gogo run main.go SesionA先执行main.go先获得一个锁，随后执行SessionB main.go,会提示锁被占用 参考 《Go Etcd Docs》]]></content>
      <tags>
        <tag>golang</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang 调度多个cron]]></title>
    <url>%2F2019%2F01%2F01%2F2019-01-01-golang-cron%2F</url>
    <content type="text"><![CDATA[类库引用 下载cron包到$Gopath下1pengshiliang@pengshiliang-virtual-machine:go get github.com/gorhill/cronexpr 导入1import "github.com/gorhill/cronexpr" 一个简单的cron实例1234567891011121314151617181920212223242526var ( expr *cronexpr.Expression err error now time.Time nextTime time.Time )// golang可支持到秒粒度, 年配置(2018-2099)// 哪一分钟（0-59），哪小时（0-23），哪天（1-31），哪月（1-12），星期几（0-6）// 每隔5秒钟执行1次if expr, err = cronexpr.Parse("*/5 * * * * * *"); err != nil &#123; fmt.Println(err) return&#125;// 当前时间now = time.Now()// 下次调度时间nextTime = expr.Next(now)// 等待这个定时器超时time.AfterFunc(nextTime.Sub(now), func() &#123; fmt.Printf("当前时间：%+v 调度时间:%+v\n", now, nextTime)&#125;)time.Sleep(5 * time.Second) 输出结果：12pengshiliang@pengshiliang-virtual-machine:~/code/go/src/cron$ go run sim.go 当前时间：2019-01-01 19:57:30.179548305 +0800 CST m=+0.000772719 调度时间:2019-01-01 19:57:35 +0800 CST 多任务版12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758type CronJob struct &#123; expr *cronexpr.Expression nextTime time.Time&#125;var ( expr *cronexpr.Expression now time.Time cronJob *CronJob cronSchedule map[string]*CronJob)func main() &#123; cronSchedule = make(map[string]*CronJob) //当前时间 now = time.Now() //添加任务job1到cronSchedule中 expr = cronexpr.MustParse("*/5 * * * * * *") cronJob = &amp;CronJob&#123; expr: expr, nextTime:expr.Next(now), &#125; cronSchedule["job1"] = cronJob //添加任务job2到cronSchedule中 expr = cronexpr.MustParse("*/5 * * * * * *") cronJob = &amp;CronJob&#123; expr: expr, nextTime:expr.Next(now), &#125; cronSchedule["job2"] = cronJob // 启动一个调度协程 go func() &#123; var ( jobName string cronJob *CronJob now time.Time ) // 定时检查一下任务调度表 for &#123; now = time.Now() for jobName, cronJob = range cronSchedule &#123; // 判断是否过期 if cronJob.nextTime.Before(now) || cronJob.nextTime.Equal(now) &#123; // 启动一个协程, 执行这个任务 go func(jobName string) &#123; fmt.Printf("当前执行时间:%+v执行任务%s\n", now, jobName) &#125;(jobName) // 计算下一次调度时间 cronJob.nextTime = cronJob.expr.Next(now) fmt.Println(jobName, "下次执行时间:", cronJob.nextTime) &#125; &#125; &#125; &#125;() //防止main协程退出 time.Sleep(100 * time.Second)&#125; 输出结果:123456789101112131415161718pengshiliang@pengshiliang-virtual-machine:~/code/go/src/cron/demo$ go run test1.gojob2 下次执行时间: 2019-01-01 20:04:45 +0800 CSTjob1 下次执行时间: 2019-01-01 20:04:45 +0800 CST当前执行时间:2019-01-01 20:04:40.000827793 +0800 CST m=+0.107461981执行任务job2当前执行时间:2019-01-01 20:04:40.00104295 +0800 CST m=+0.107677140执行任务job1job1 下次执行时间: 2019-01-01 20:04:50 +0800 CSTjob2 下次执行时间: 2019-01-01 20:04:50 +0800 CST当前执行时间:2019-01-01 20:04:45.000103213 +0800 CST m=+5.106737398执行任务job1当前执行时间:2019-01-01 20:04:45.000204198 +0800 CST m=+5.106838391执行任务job2当前执行时间:2019-01-01 20:04:50.000000023 +0800 CST m=+10.106634228执行任务job1job1 下次执行时间: 2019-01-01 20:04:55 +0800 CSTjob2 下次执行时间: 2019-01-01 20:04:55 +0800 CST当前执行时间:2019-01-01 20:04:50.001381032 +0800 CST m=+10.108015219执行任务job2job1 下次执行时间: 2019-01-01 20:05:00 +0800 CSTjob2 下次执行时间: 2019-01-01 20:05:00 +0800 CST当前执行时间:2019-01-01 20:04:55.000000033 +0800 CST m=+15.106634234执行任务job1当前执行时间:2019-01-01 20:04:55.001663389 +0800 CST m=+15.108297584执行任务job2... cronexpr.MustParse()和cronexpr.Parse()区别,cronexpr.Parse()会多返回一个error变量，如果确定接收到的cron表达式正确的话可以选择用MustParse]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>golang</tag>
        <tag>cron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello 2019]]></title>
    <url>%2F2018%2F12%2F31%2F2018-12-31-hello-2019%2F</url>
    <content type="text"><![CDATA[“Yeah It’s on. ” 前言Psl 的 Blog 就这么开通了。 跳过废话，直接看技术实现 2019 年，Psl 总算有个地方可以好好写点东西了。 之前一直就有开个博客的想法，但是一直没有开。以前自己学过的知识都是记录在自己的笔记中，但是久而久之却发现一个问题，那就是如果记录的笔记规划不好的话就会丢失，在遇到问题翻以前的记录时也并不好找，不过偶然间在github发现了GitHub Pages这个有意思的东东，可以很快的搭建出一个博客，还省了弄域名的功夫，觉得不错就花了几个小时的时间搞了下 正文接下来说说搭建这个博客的技术细节。 实现依赖工具 GitHub Pages + Jekyll 快速 Building Blog 的技术方案，非常轻松时尚。 其优点非常明显： Markdown 带来的优雅写作体验 非常熟悉的 Git workflow ，Git Commit 即 Blog Post 利用 GitHub Pages 的域名和免费无限空间，不用自己折腾主机 如果需要自定义域名，也只需要简单改改 DNS 加个 CNAME 就好了 Jekyll 的自定制非常容易，基本就是个模版引擎 进入主题我直接 Download 了 Hux的博客主题 的进行修改，简单粗暴，不过遇到了很多坑😂，好在都填完了。。。 简要说明一下步骤： 一 ：安装Ruby 二 ：安装RubyGems 三：用RubyGems安装Jekyll 四：cd到博客文件夹，开启服务器 五：访问 http://localhost:4000/ 六：提交代码到远程GitHub上 本地调试环境需要 gem install jekyll，结果 rubygem 的源居然被墙了，后来上网查资料告诉要切话我们的大淘宝镜像，但是切换过程中又出现404错误后来查资料才发现淘宝的源已经停止维护，又换成了OSChina的源 https://gems.ruby-china.org/ 后记回顾这个博客的诞生，纯粹是出于个人兴趣。希望自己可以利用闲暇时间写点什么 如果你恰好逛到了这里，希望你也能喜欢这个博客主题。 —— Psl 后记于 2018.12]]></content>
      <tags>
        <tag>生活</tag>
        <tag>Meta</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql语句查询性能分析]]></title>
    <url>%2F2018%2F12%2F01%2F2018-12-01-mysql-per-analysis%2F</url>
    <content type="text"><![CDATA[前言一般情况下，如果谈起查询性能优化，多数人的第一感知都是想到一些复杂的语句，想到查询需要返回大量的数据。但有些情况下，“查一行”，也会执行得特别慢。今天，就来探讨这个问题，看看什么情况下，会出现这个现象。 当然，如果 MySQL 数据库本身就有很大的压力，导致数据库服务器 CPU 占用率很高或 ioutil（IO 利用率）很高，这种情况下所有语句的执行都有可能变慢，不属于今天的探讨范围。 正题首先，先做一个测试表在插入1万条数据12345678910111213141516171819CREATE TABLE `t1` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=10000)do insert into t1 values(i,i); set i=i+1; end while;end;;delimiter ;call idata(); 几种场景类型分析第一类：查询长时间不返回执行下面的sql1mysql&gt; select * from t1 where id=1; 查询长时间不返回 一般碰到这种情况的话，大概率是表 t1 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。 然后再根据状态去分析产生的原因，以及能否复现 等MDL锁 如下图所示，就是使用 show processlist 命令查看 Waiting for table metadata lock 的示意图。这个状态表示的是，现在有一个线程正在表 t1 上请求或者持有 MDL 写锁，把 select 语句堵住了。 不过，在 MySQL 5.7 版本下复现这个场景，也很容易。 SessionASessionBlock table t1 writeselect * from t1 where id=1; session A 通过 lock table 命令持有表 t1 的 MDL 写锁，而 session B 的查询需要获取 MDL 读锁。所以，session B 进入等待状态。 这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。 但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失) 查看是否支持performance_schema1select * from information_schema.engines where engine ='performance_schema'; 是否开启performance_schema1show variables like 'performance_schema'; 通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。 等FLUSH 另一种场景我在表t1上执行这样一条sql1mysql&gt; select * from information_schema.processlist where id=1; 查出来这个线程的状态是 Waiting for table flush 这个状态表示的是，现在有一个线程正要对表 t1 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个： 12flush tables t1 with read lock;flush tables with read lock; 这两个 flush 语句，如果指定表 t1 的话，代表的是只关闭表 t1；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。 但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。 所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。 复现一下这种情况: SessionASessionBSessionCselect sleep(1) from t1flush table t1select * from t1 where id=1;在 session A 中，我故意每行都调用一次 sleep(1)，这样这个语句默认要执行 1 万秒，在这期间表 t 一直是被 session A“打开”着。然后，session B 的 flush tables t 命令再要去关闭表 t，就需要等 session A 的查询结束。这样，session C 要再次查询的话，就会被 flush 命令堵住了。 下面是show processlist 结果 等行锁 现在，经过了表级锁的考验，我们的 select 语句终于来到引擎里了。 1mysql&gt; select * from t1 where id=1 lock in share mode; 由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。 行锁操作复现: SessionASessionBbegin;update t1 set c=c+1 where id=1;select * from t1 where id=1 lock in share mode;下面是show processlist 结果 显然，session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。 这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。 查询方法：1mysql&gt; select * from t1 sys.innodb_lock_waits where locked_table=&apos;`test`.`t1`&apos;\G 可以看到，这个信息很全，9957 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 9957 或 KILL 9957。 不过，这里不应该显示“KILL QUERY 9957”。这个命令表示停止 9957 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。 实际上，KILL 9957 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。 第二类：查询慢经过了重重封“锁”，再来看看一些查询慢的例子 1mysql&gt; select * from t1 where c=9000 limit 1; 由于字段 c 上没有索引，这个语句只能走 id 主键顺序扫描，因此需要扫描 5 千行。 通过slow_log 看一下12set global slow_query_log=ON;set long_query_time=0; #我们让所有查询都加入到slow_log中 1show variables like '%slow%'; slow_log结果 Rows_examined 显示扫描了 9000 行。你可能会说，不是很慢呀，6 毫秒就返回了，我们线上一般都配置超过 1 秒才算慢查询。但你要记住：坏查询不一定是慢查询。我们这个例子里面只有 1 万行记录，数据量大起来的话，执行时间就线性涨上去了。 扫描行数多，所以执行慢，这个很好理解。 但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。 看下面的例子 SessionASessionBstart transaction with consistent snapshot;update t1 set c=c+1 where id=1;//执行100万次select from t1 where id = 1;select from t1 where id = 1 lock in share mode;先看看执行一次的结果 由此可推出SessionB执行100万次后结果select * from t1 where id = 1 lock in share mode; idc110000011 row in set (0.00 sec) 此时，session A 先用 start transaction with consistent snapshot 命令启动了一个事务，之后 session B 才开始执行 update 语句。 session B 更新完 100 万次，生成了 100 万个回滚日志 (undo log)。 带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。 小结今天列举了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。在实际使用中，碰到的场景会更复杂。但大同小异。 参考 《极客时间林晓斌Mysql专场》]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redux 学习(一)]]></title>
    <url>%2F2018%2F11%2F24%2F2018-11-24-redux-first%2F</url>
    <content type="text"><![CDATA[Reudx由官网可看出：A JavaScript library for building user interfaces， React是一个非常简单的视图型框架 Redux是一个流行的JavaScript框架，为应用程序提供一个可预测的状态容器。Redux基于简化版本的Flux框架，Flux是Facebook开发的一个框架。在标准的MVC框架中，数据可以在UI组件和存储之间双向流动，而Redux严格限制了数据只能在一个方向上流动 在Redux中，所有的数据（比如state）被保存在一个被称为store的容器中 → 在一个应用程序中只能有一个。store本质上是一个状态树，保存了所有对象的状态。任何UI组件都可以直接从store访问特定对象的状态。要通过本地或远程组件更改状态，需要分发一个action。分发在这里意味着将可执行信息发送到store。当一个store接收到一个action，它将把这个action代理给相关的reducer。reducer是一个纯函数，它可以查看之前的状态，执行一个action并且返回一个新的状态。 Redux=Reducer+Flux Redux的工作流程 Store创建创建reducer12345678const defaultState = &#123; inputValue: &quot;123&quot;, list: [1,2]&#125;;export default (state = defaultState, action) =&gt; &#123; return state&#125; 创建Store并引入reducer123456import &#123;createStore&#125; from &quot;redux&quot;;import reducer from &quot;./reducer&quot;;const store = createStore(reducer);export default store; ReduxTools使用 使用方式详见redux-devtools-extension Action 和 Reduceraction 传递给reducer:123456const action = &#123; type: &apos;change_input_value&apos;, value: e.target.value &#125;;//传给storestore.dispatch(action); store变化订阅 1store.subscribe(this.handleStoreChange) reducer修改state:12345if (action.type === &apos;change_input_value&apos;) &#123; const newState = JSON.parse(JSON.stringify(state)); newState.inputValue = action.value; return newState&#125; 发送异步请求react发送异步请求一般都是在componentDidMount中发送的，选择原因可总结为如下几点： constructor() constructor()中获取数据的话，如果时间太长，或者出错，组件就渲染不出来，整个页面都没法渲染了。 constructor是作组件state初绐化工作，并不是设计来作加载数据的。 componentWillMount() 如果使用SSR（服务端渲染）,componentWillMount会执行2次，一次在服务端，一次在客户端。而componentDidMount不会。 constructor可以完成state初始化，componentWillMount使用的很少，目前16版本加入了UNSAFE来标识componentWillMount，新的生命周期static getDerivedStateFromProps() 也会替代这个。 React16之后采用了Fiber架构，只有componentDidMount声明周期函数是确定被执行一次的，类似ComponentWillMount的生命周期钩子都有可能执行多次，所以不加以在这些生命周期中做有副作用的操作，比如请求数据之类。 render() 无限render componentDidMount() 确保已经render过一次。提醒我们正确地设置初始状态，这样就不会得到导致错误的”undefined”状态。 componentDidMount方法中的代码，是在组件已经完全挂载到网页上才会调用被执行，所以可以保证数据的加载。此外，在这方法中调用setState方法，会触发重渲染。所以，官方设计这个方法就是用来加载外部数据用的，或处理其他的副作用代码。 123456789axios.get(&quot;/list.json&quot;).then((res) =&gt; &#123; const data = res.data; const action = &#123; type: &apos;init_axios_data&apos;, data &#125;; //传给store store.dispatch(action);&#125;); 12345if (action.type === &apos;init_axios_data&apos;) &#123; const newState = JSON.parse(JSON.stringify(state)); newState.list = action.data; return newState&#125; Redux-thunk什么是Redux-thunk中间件原生的redux的store的dispatch方法只能接收一个对象，Redux Thunk对dispatch方法做了一个升级它允许我们写一个返回function而非action对象的action creators。Redux Thunk可以用来延迟dispatch一个action或者只在某些特定场景下才dispatch。内部函数接受store的dispatch方法和getState方法作为参数。 使用：123456789import &#123; createStore, applyMiddleware &#125; from &apos;redux&apos;;import thunk from &apos;redux-thunk&apos;;import rootReducer from &apos;./reducers/index&apos;;// Note: this API requires redux@&gt;=3.1.0const store = createStore( rootReducer, applyMiddleware(thunk)); 兼容redux-devtools-extension123456const composeEnhancers = window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__ ? window.__REDUX_DEVTOOLS_EXTENSION_COMPOSE__(&#123;&#125;) : compose;const enhancer = composeEnhancers( applyMiddleware(thunk),);const store = createStore(reducer, enhancer); 分离componentDidMount代码 1234import &#123;getTodoList&#125; from &quot;../store/actions&quot;componentDidMount() &#123; store.dispatch(getTodoList())&#125; 创建actions：1234567891011121314import axios from &quot;axios&quot;export const getTodoList = () =&gt; &#123; return (dispatch) =&gt; &#123; axios.get(&quot;/list.json&quot;).then((res) =&gt; &#123; const data = res.data; const action = &#123; type: &apos;init_axios_data&apos;, data &#125;; dispatch(action); &#125;); &#125;&#125;;]]></content>
      <tags>
        <tag>react</tag>
        <tag>redux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React 学习(一)]]></title>
    <url>%2F2018%2F11%2F22%2F2018-11-22-react-first%2F</url>
    <content type="text"><![CDATA[JSX语法简单的jsx示例: 12345678import React, &#123;Component&#125; from &apos;react&apos;class JSX extends Component&#123; render() &#123; return &lt;div&gt;jsx语法&lt;/div&gt; &#125;&#125;export default JSX jsx语法中 return后面不能有双引号或单引号，并且必须被包含在一个大的根节点中 典型错误示例:1234567891011121314import React, &#123;Component&#125; from &apos;react&apos;class JSX extends Component&#123; render() &#123; return ( &lt;div&gt;jsx语法&lt;/div&gt; &lt;ul&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;/ul&gt; ) &#125;&#125;export default JSX 如何解决： 外层引入一个div标签或者Fragment占位符 12345678910111213141516import React, &#123;Component, Fragment&#125; from &apos;react&apos;class JSX extends Component&#123; render() &#123; return ( &lt;Fragment&gt; &lt;div&gt;jsx语法&lt;/div&gt; &lt;ul&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;/ul&gt; &lt;/Fragment&gt; ) &#125;&#125;export default JSX 推荐使用Fragment， 推荐使用Fragment占位符不生成任何虚拟dom节点 React中的响应式设计思想和事件绑定事件绑定看一个小例子，给input框赋值一个默认值，并能够根据输入改变默认值12345678910111213141516171819202122232425262728293031import React, &#123;Component, Fragment&#125; from &apos;react&apos;class TodoList extends Component&#123; constructor(props) &#123; super(props) this.state = &#123; inputValue: &quot;hello!!!!!&quot;, list: [], &#125; &#125; render() &#123; return ( &lt;Fragment&gt; &lt;div&gt; &lt;input value=&#123;this.state.inputValue&#125; onChange=&#123;this.handleInputChange.bind(this)&#125; /&gt; &lt;button&gt;提交&lt;/button&gt; &lt;/div&gt; &lt;ul&gt; &lt;li&gt;学英语&lt;/li&gt; &lt;li&gt;learn react&lt;/li&gt; &lt;/ul&gt; &lt;/Fragment&gt; ) &#125; handleInputChange(e) &#123; this.state.inputValue = e.target.value; &#125;&#125;export default TodoList 代码分析：首先程序初始化的时候inputValue为”hello!!!!!”,render函数执行的时候把input的内容渲染成数据里面inputValue的值然后给input绑定了一个onchange事件，同时用es6的bind方法传递react的this对象到handleInputChange中，在handleInputChange去改变state中inputValue的值为手动输入的对象 实现一个todolisttodolist新增功能利用在React中state数据变化dom也会变化的特性： 12345678910111213141516171819202122232425262728293031323334353637383940414243import React, &#123;Component, Fragment&#125; from &apos;react&apos;class TodoList extends Component&#123; constructor(props) &#123; super(props); this.state = &#123; inputValue: &quot;&quot;, list: [], &#125; &#125; render() &#123; return ( &lt;Fragment&gt; &lt;div&gt; &lt;input value=&#123;this.state.inputValue&#125; onChange=&#123;this.handleInputChange.bind(this)&#125; /&gt; &lt;button onClick=&#123;this.handleButtonClick.bind(this)&#125;&gt;提交&lt;/button&gt; &lt;/div&gt; &lt;ul&gt; &#123; this.state.list.map((item, index) =&gt; &#123; return &lt;li&gt;&#123;item&#125;&lt;/li&gt; &#125;) &#125; &lt;/ul&gt; &lt;/Fragment&gt; ) &#125; handleInputChange(e) &#123; this.setState(&#123; inputValue: e.target.value, &#125;); &#125; handleButtonClick(e) &#123; this.setState(&#123; list: [...this.state.list, this.state.inputValue], inputValue: &quot;&quot;, &#125;); &#125;&#125;export default TodoList Warning: Each child in an array or iterator should have a unique “key” prop. 错误问题es5的map方法中必须指定一个key值否则会报错 1234567&lt;ul&gt; &#123; this.state.list.map((item, index) =&gt; &#123; return &lt;li key=&#123;index&#125;&gt;&#123;item&#125;&lt;/li&gt; &#125;) &#125;&lt;/ul&gt; todolist删除功能12345678910111213141516171819&lt;ul&gt; &#123; this.state.list.map((item, index) =&gt; &#123; return &lt;li key=&#123;index&#125; onClick=&#123;this.handleDelete.bind(this, index)&#125; &gt;&#123;item&#125;&lt;/li&gt; &#125;) &#125;&lt;/ul&gt;handleDelete (index) &#123; //immutable //state不允许我们做任何的改变，对react性能优化有影响 const list = [...this.state.list]; list.splice(index, 1) this.setState(&#123; list: list &#125;) &#125; 在handleDelete方法中，不推荐使用this.state.list.splice(index, 1),原因见注释 label属性123456&lt;label htmlFor=&quot;insertArea&quot;&gt;输入内容&lt;/label&gt;&lt;input id=&quot;insertArea&quot; value=&#123;this.state.inputValue&#125; onChange=&#123;this.handleInputChange.bind(this)&#125;/&gt; 组件拆分我们把li标签中的内容注释掉并提取出来封装为一个组件123456789101112131415161718import ToDoItem from &quot;./ToDoItem&quot;;&lt;ul&gt; &#123; this.state.list.map((item, index) =&gt; &#123; return ( &lt;Fragment&gt; &lt;ToDoItem/&gt; &#123; /*&lt;li key=&#123;index&#125; onClick=&#123;this.handleDelete.bind(this, index)&#125; &gt;&#123;item&#125;&lt;/li&gt;*/ &#125; &lt;/Fragment&gt; ); &#125;) &#125; &lt;/ul&gt; 12345678import React, &#123;Component, Fragment&#125; from &apos;react&apos;class ToDoItem extends Component&#123; render() &#123; return &lt;li&gt;item&lt;/li&gt; &#125;&#125;export default ToDoItem 此时点击提交按钮每次新增的都是一个固定的item值，这也不是我们想要的 组件动态传值我们可以利用组件传值解决上面的问题，代码做如下修改传递数据:1234&lt;ToDoItem content=&#123;item&#125; index=&#123;index&#125;/&gt; 在ToDoItem中接收：1return &lt;li&gt;&#123;this.props.content&#125;&lt;/li&gt; 传递方法:123456&lt;ToDoItem content=&#123;item&#125; index=&#123;index&#125; //把todolist这个组件的this对象强制传递给todoitem,这样在todoitem中才能调用todolist的handleDelete方法成功 deleteItem=&#123;this.handleDelete.bind(this)&#125;/&gt; 在ToDoItem中接收：1234567891011121314151617class ToDoItem extends Component&#123; constructor(props) &#123; super(props); //通过bind去修改this指向，保证在handleClick可以使用this.props,并且在组件创建的时候 //通过第一个执行的方法constructor去改变handleClick的this指向 this.handleClick = this.handleClick.bind(this); &#125; render() &#123; return &lt;li onClick=&#123;this.handleClick&#125; &gt;&#123;this.props.content&#125;&lt;/li&gt; &#125; handleClick() &#123; this.props.deleteItem(this.props.index) &#125;&#125; 单向数据流：子组件不能修改父组件传递的数据值，如果要修改只能通过父组件向子组件传递方法来修改 代码优化TodoList 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class TodoList extends Component&#123; constructor(props) &#123; super(props); this.state = &#123; inputValue: &quot;&quot;, list: [], &#125;; this.handleInputChange = this.handleInputChange.bind(this); this.handleButtonClick = this.handleButtonClick.bind(this); this.handleDelete = this.handleDelete.bind(this); &#125; render() &#123; return ( &lt;Fragment&gt; &lt;div&gt; &lt;label htmlFor=&quot;insertArea&quot;&gt;输入内容&lt;/label&gt; &lt;input id=&quot;insertArea&quot; value=&#123;this.state.inputValue&#125; onChange=&#123;this.handleInputChange&#125; /&gt; &lt;button onClick=&#123;this.handleButtonClick&#125;&gt;提交&lt;/button&gt; &lt;/div&gt; &lt;ul&gt; &#123;this.getToDoItem()&#125; &lt;/ul&gt; &lt;/Fragment&gt; ) &#125; handleInputChange(e) &#123; const value = e.target.value; this.setState(() =&gt; (&#123; inputValue: value, &#125;)); &#125; handleButtonClick(index) &#123; this.setState((prevState) =&gt; (&#123; list: [...prevState.list, prevState.inputValue], inputValue: &quot;&quot;, &#125;)); &#125; handleDelete (index) &#123; this.setState((prevState) =&gt; &#123; const list = [...this.state.list]; list.splice(index, 1); return &#123;list&#125; //等价于&#123;list: list&#125; &#125;); &#125; getToDoItem () &#123; return this.state.list.map((item, index) =&gt; &#123; return ( &lt;ToDoItem key=&#123;index&#125; content=&#123;item&#125; index=&#123;index&#125; deleteItem=&#123;this.handleDelete&#125; /&gt; ); &#125;) &#125;&#125; TodoItem1234567891011121314151617class ToDoItem extends Component&#123; constructor(props) &#123; super(props); this.handleClick = this.handleClick.bind(this); &#125; render() &#123; const &#123; content &#125; = this.props; return &lt;li onClick=&#123;this.handleClick&#125; &gt;&#123;content&#125;&lt;/li&gt; &#125; handleClick() &#123; const &#123;deleteItem, index&#125; = this.props; deleteItem(index) &#125;&#125; 总结：react特点： 声明式开发：减少DOM操作 可以与其它框架并存：flex，redux框架来解决复杂组件通信 组件化 单向数据流 视图层框架：在嵌套包含多个组件的项目中只做视图渲染开发 函数式编程：方便自动化测试]]></content>
      <tags>
        <tag>react</tag>
        <tag>Es6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React 学习(二)]]></title>
    <url>%2F2018%2F11%2F22%2F2018-11-23-react%2F</url>
    <content type="text"><![CDATA[props state render 当组件的state或props发生变化,render函数就会执行 当父组件的render函数重新执行时子组件的render也会被执行父组件: 12345678910111213141516171819202122232425262728293031323334import React, &#123;Component, Fragment&#125; from &apos;react&apos;import Child from &apos;./child&apos;class Parent extends Component&#123; constructor(props) &#123; super(props); //当组件的state或props发生变化,render函数就会执行 this.state = &#123; content: &quot;&quot;, &#125;; this.handleInputChange = this.handleInputChange.bind(this); &#125; render() &#123; console.log(&quot;render&quot;); const &#123; content &#125; = this.state; return ( &lt;Fragment&gt; &lt;div&gt;parent&lt;/div&gt; &lt;input onChange=&#123;this.handleInputChange&#125;/&gt; &lt;Child content=&#123;content&#125;/&gt; &lt;/Fragment&gt; ); &#125; handleInputChange(e) &#123; const value = e.target.value; this.setState(() =&gt; (&#123; content: value, &#125;)); &#125;&#125;export default Parent 子组件： 12345678910111213import React, &#123;Component&#125; from &apos;react&apos;class Child extends Component&#123; render() &#123; console.log(&quot;child render&quot;) const &#123; content &#125; = this.props; return ( &lt;div&gt;&#123;content&#125;&lt;/div&gt; ); &#125;&#125;export default Child 虚拟Dom12345render() &#123; //JSX-&gt;createElement-&gt;虚拟DOM（js对象）-&gt;真实的dom //return &lt;div&gt;item&lt;/div&gt;; return React.createElement(&quot;div&quot;, &#123;&#125;, &apos;item&apos;)&#125; 原理：React会在内存中维护一个虚拟DOM树，对这个树进行读或写，实际上是对虚拟DOM进行。当数据变化时，React会自动更新虚拟DOM，然后将新的虚拟DOM和旧的虚拟DOM进行对比，找到变更的部分，得出一个diff，然后将diff放到一个队列里，最终批量更新这些diff到DOM中。 优点：性能提升跨端应用得以实现 React Native ref使用修改todolist代码12345678910111213&lt;input id=&quot;insertArea&quot; value=&#123;this.state.inputValue&#125; onChange=&#123;this.handleInputChange&#125; ref=&#123;(input) =&gt; &#123;this.input = input&#125;&#125;/&gt;handleInputChange(e) &#123; //const value = e.target.value; const value = this.input.value; this.setState(() =&gt; (&#123; inputValue: value, &#125;));&#125; this.input指向了&lt;input/&gt;的dom节点 注意事项：1234567891011&lt;ul ref=&#123;(ul) =&gt; &#123;this.ul = ul&#125;&#125;&gt; &#123;this.getToDoItem()&#125;&lt;/ul&gt;handleButtonClick(index) &#123; this.setState((prevState) =&gt; (&#123; list: [...prevState.list, prevState.inputValue], inputValue: &quot;&quot;, &#125;), () =&gt; &#123; console.log(this.ul.querySelectorAll(&quot;li&quot;).length) &#125;);&#125; console.log(this.ul.querySelectorAll(“li”).length)要在setState第二个参数后使用，由于setState是异步执行所以如果不放在setState执行后调用会导致dom节点数获取不对 生命周期函数定义：在某一时刻组件会自动调用的函数 1234567891011121314151617181920212223242526//组件挂载到页面之前执行(render函数执行前)componentWillMount() &#123; console.log(&quot;componentWillUnmount&quot;)&#125;//组件挂载到页面之后执行(render函数执行后)componentDidMount() &#123; console.log(&quot;componentDidMount&quot;)&#125;//组件更新前执行shouldComponentUpdate() &#123; return true or false //当return false 时当前组件的值更新会被禁用&#125;//组件更新前shouldComponentUpdate后执行componentWillUpdate() &#123; console.log(&quot;componentWillUpdate&quot;)&#125;//当一个组件从父组件接收参数//如果这个组件第一次存在于父组件中，不会被执行//如果这个组件之前存在于父组件中，才会被执行componentWillReceiveProps() &#123; console.log(&quot;child componentWillReceiveProps&quot; )&#125;//当这个组件即将在页面中被剔除componentWillUnmount() &#123; console.log(&quot;child componentWillUnmount&quot;)&#125;]]></content>
      <tags>
        <tag>react</tag>
        <tag>Es6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis高可用]]></title>
    <url>%2F2018%2F10%2F02%2F2018-01-10-redis-slave%2F</url>
    <content type="text"><![CDATA[单机版Redis问题 机器故障需要做数据手动迁移 容量瓶颈 QPS瓶颈 引入正题前面列出的容量瓶颈和QPS瓶颈是redis分布式要解决的问题，本篇还是主要解决redis怎么实现高可用，机器故障的问题 主从复制介绍作用： 流量分流和负载均衡 提供多个数据分布 扩展redis读性能 简单总结 一个master可以有多个slave 一个slave只能有一个master 数据流向是单向的，master到slave 主从复制操作master节点: 12cp $&#123;redis_src&#125;/redis.conf redis-6379.confvim redis-6379.conf 改动项： 123456789daemonize yespidfile /var/run/redis-6379.pidlogfile &quot;6379.log&quot;logfile &quot;6379.log&quot;#save 900 1#save 300 10#save 60 10000dbfilename dump-6379.rdbdir /opt/soft/data slave节点: 12cp $&#123;redis_src&#125;/redis.conf redis-6380.confvim redis-6380.conf 改动项： 1234567891011daemonize yespidfile /var/run/redis-6380.pidlogfile &quot;6380.log&quot;logfile &quot;6380.log&quot;#save 900 1#save 300 10#save 60 10000dbfilename dump-6380.rdbdir /opt/soft/datasalveof 127.0.0.1 6379 #master节点 ip portmasterauth #主节点设置密码时需要配置 启动: 12redis-server 6379.confredis-server 6380.conf 检查主从状态： 12345redis-cli127.0.0.1:6379&gt; info replication127.0.0.1:6380&gt; info replication127.0.0.1:6379&gt; set hello world127.0.0.1:6380&gt; get hello runid和复制偏移量runidredis每次启动后都会随机生成一个runid执行： 12redis-cli -p 6379 info server |grep runredis-cli -p 6380 info server |grep run redis每次重启runid会发生变化，redis从节点每次会检测主节点runid变化来进行一次全量复制 偏移量主节点和从节点都会记录执行一条命令时数据写入的字节数，当偏移量达到一致时，数据才会同步完成 全量复制 全量复制开销 bgsave时间 RDB文件网络传输时间 从节点清空数据时间 从节点加载RDB时间 如果配置AOF开启会有AOF重写时间 部分复制 开发运维中的问题规避全量复制： 1：第一次全量复制 问题：第一次不可避免 解决：小主节点，低峰 2：节点运行ID不匹配 问题：主节点重启runid变化 解决：故障转移，例如哨兵或集群 3：复制积压缓冲区不足 问题：网络中断，部分复制无法满足 解决：增大复制缓冲区配置rel_backlog_size 规避复制风暴： 1：单主节点复制风暴 问题：主节点重启，多从节点复制 解决：更换复制拓扑(树形架构) 1：单机器复制风暴 问题：机器宕机后，大量全量复制 解决：主节点分散多机器]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化]]></title>
    <url>%2F2018%2F10%2F01%2F2019-01-08-redis%2F</url>
    <content type="text"><![CDATA[前言话不多说直奔主题… RDB主要触发机制savecli命令: save 文件策略： 如果存在老的RDB文件，新的将其替换掉 时间复杂度： O(n) 我们把客户端和服务端用一个图来表示，save时会帮我们生成一个RDB文件 由于它是同步命令，并且在单线程中执行,在数据量非常多的时候，此时执行save命令，他会将数据进行完整拷贝，可能会造成redis阻塞。 bgsave 通过在后台fork一个子进程完成复制 自动根据REDIS配置定时同步数据到RDB文件 配置SecondsChangessave9001save30010save6010000 eg:60秒中改变了10000次会发生备份RDB 触发机制-不容忽略的方式 全量复制 Debug Reload shutdown save or bgsave ?命令savebgsaveIO类型同步异步阻塞是发生在fork时复杂度O(N)O(N)优点不会消耗内存不阻塞客户端命令缺点阻塞客户端命令消耗内存### 配置12345678save 900 1save 300 10save 60 10000dbfilename dump.rdbdir ./stop-writes-on-bgsave-error yes //bgsave出现问题会停止写入rdbcompression yes //压缩模式rdbchecksum yes //对RDB进行校验和检验#### 最佳配置12345dbfilename dump-$&#123;port&#125;.rdbdir bigdiskpath //选择大的硬盘stop-writes-on-bgsave-error yes //bgsave出现问题会停止写入rdbcompression yes //压缩模式rdbchecksum yes //对RDB进行校验和检验### 小结 RDB是Redis内存到硬盘的快照，用于持久化 save通常会阻塞Redis bgsave不会阻塞Redis，但是会fork子进程 save自动配置满足其一就会被执行* 有些触发机制不容忽视### RDB问题耗时耗性能&gt; O(N)数据耗时&gt; fork耗内存&gt; Disk I/O:IO性能不可控丢失数据时间戳saveT1执行多个命令T2满足RDB自动创建条件T3再次执行多条命令T4宕机 宕机会发生数据丢失 AOF三种策略everysec always同everysec流程，只不过always会把每条命令都写入到AOF文件中 no由操作系统来决定是否刷新 比较命令alwayseverysecno优点不丢失数据每秒一次fsync丢1秒数据不用管理缺点IO开销比较大丢1秒数据不可控### AOF重写#### 作用 减少硬盘占用量 加快回复速度### 重写两种方式#### bgrewriteaof命令：bgrewriteaof重写配置配置名含义auto-aof-rewirte-min-sizeauto-aof-rewirte-percentageAOF文件重写尺寸AOF文件增长率统计统计名含义auto-current-sizeauto-base-sizeAOF当前尺寸AOF上次启动和重写的尺寸#### 自动触发时机 auto-current-size &gt; auto-aof-rewirte-min-size (auto-current-size - auto-base-size) / auto-base-size &gt; auto-aof-rewirte-percentage### AOF重写流程### 配置 appendonly yes appendfilename “appendonly-${port}.aof” appendfsync everysec dir /bigdisk no-appendfsync-on-rewrite no //aof重写失败是否允许丢失数据 auto-aof-rewrite-percentage 100 //增长率* auto-aof-rewrite-min-size 64mb //最小尺寸## RDB 和 AOF 抉择命令RDBAOF启动优先级低高体积小大恢复速度快慢数据安全性丢数据根据策略决定轻重重轻]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php swoole进程]]></title>
    <url>%2F2018%2F01%2F02%2F2018-01-02-php-swoole-process%2F</url>
    <content type="text"><![CDATA[前言最近看了下swoole的相关文档，发现了它弥补了php以前再做异步通信方面的不足，也正如官方文档所说：是一个”面向生产环境的 PHP 异步网络通信引擎”。 那为什么要使用 Swoole？主要有一下几点： 常驻内存，避免重复加载带来的性能损耗，提升海量性能 协程异步，提高对 I/O 密集型场景并发处理能力（如：微信开发、支付、登录等） 方便地开发 Http、WebSocket、TCP、UDP 等应用，可以与硬件通信 PHP 高性能微服务架构成为现实 当然今天主要介绍的还是swoole得Process模块得基础学习 进入正题Process 出现的意义在1.7.2版本时,swoole增加了一个进程管理模块，用来替代PHP的pcntl。 PHP自带的pcntl，存在很多不足，如： pcntl没有提供进程间通信的功能 pcntl不支持重定向标准输入和输出 pcntl只提供了fork这样原始的接口，容易使用错误 swoole_process提供了比pcntl更强大的功能，更易用的API，使PHP在多进程编程方面更加轻松。 Swoole\Process提供了如下特性： 基于Unix Socket和sysvmsg消息队列的进程间通信，只需调用write/read或者push/pop即可 支持重定向标准输入和输出，在子进程内echo不会打印屏幕，而是写入管道，读键盘输入可以重定向为管道读取数据 配合Event模块，创建的PHP子进程可以异步的事件驱动模式 提供了exec接口，创建的进程可以执行其他程序，与原PHP父进程之间可以方便的通信 一个简单的Process实例创建一个http.php脚本: 123456789use Swoole\Http\Server;$http = new Server("0.0.0.0", 9000);$http-&gt;set(array( 'worker_num' =&gt; 8, //worker process num));$http-&gt;on('request', function ($request, $response) &#123; $response-&gt;end("&lt;h1&gt;Hello Swoole. #".rand(1000, 9999)."&lt;/h1&gt;");&#125;);$http-&gt;start(); 创建一个process.php脚本: 123456789$process = new swoole_process('callback_function', true); //true 表示输出到管道中而不输出到屏幕中$pid = $process-&gt;start();function callback_function(swoole_process $worker)&#123; $worker-&gt;exec('/usr/local/php/bin/php', [__DIR__.'/http.php']);&#125;echo $pid . PHP_EOL;swoole_process::wait(); 在终端执行php process 后我们会得到一个 php process 的子进程id 通过ps -aux|grep process.php我们知道了process脚本的进程号 查看process 进程的详细信息：1pstree -p 3700 可以很容易发现出执行php process 输出的进程号3701是当前脚本的一个管理子进程的进程，它的下面有4个子进程和一个管理http_server(3702)的子进程[__DIR__.'/http.php']);```12345678910111213141516171819202122232425262728而http_server下面刚好有8个进程（我们在http_server中配置了8个进程,不配置默认4个进程）,这就很好解释了这颗进程树产生的原因。那么如何实现多进程呢？### 多进程实现创建一个worker.php脚本:```phpfunction add($i) &#123; $i++; return $i;&#125;//创建6个子进程for ($i = 0; $i &lt; 6; $i++) &#123; $process = new swoole_process(function (swoole_process $worker) use($i, $arr) &#123; $n = add($i); //将函数返回结果写入到管道中 $worker-&gt;write($n); &#125;, true); $pid = $process-&gt;start(); $workers[$pid] = $process;&#125;foreach ($workers as $worker) &#123; //遍历worker读取管道中的结果 var_dump($worker-&gt;read());&#125; 执行结果： 很好如预期所示 那么如果管道里传入的是一个数组呢？是否可以像golang的channel可以写入任意类型的数据呢？ 1234567891011121314151617181920212223function array_add_str($arr, $i)&#123; $arr[] = $i; return $arr;&#125;$arr = [ "hello", "world"];for ($i = 0; $i &lt; 6; $i++) &#123; $process = new swoole_process(function (swoole_process $worker) use($i, $arr) &#123; //$n = add($i); $arr = array_add_str($arr, $i); $worker-&gt;write($arr); &#125;, true); $pid = $process-&gt;start(); $workers[$pid] = $process;&#125;foreach ($workers as $worker) &#123; var_dump($worker-&gt;read());&#125; 由图可见：数组是不可以传递的，由此可推测出object等等其他复杂类型也是不可以的我们只能通过序列化反序列化的方式去实现通信传输 小结通过一些代码的演练了解了process的一些使用方式，但是在使用过程中还需要注意：Process进程在系统是非常昂贵的资源，创建进程消耗很大。另外创建的进程过多会导致进程切换开销大幅上升。 参考 《Swoole官方文档》]]></content>
      <tags>
        <tag>php</tag>
        <tag>swoole</tag>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
